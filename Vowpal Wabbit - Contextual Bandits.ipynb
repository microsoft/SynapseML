{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"200\" src=\"https://mmlspark.blob.core.windows.net/graphics/emails/vw-blue-dark-orange.svg\" />\n",
    "\n",
    "# Contextual-Bandits using Vowpal Wabbit\n",
    "\n",
    "[Azure Personalizer](https://azure.microsoft.com/en-us/products/cognitive-services/personalizer) emits logs in DSJSON-format. This example demonstrates how to perform off-policy evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/16 13:32:38 WARN Utils: Your hostname, marcozo-eu resolves to a loopback address: 127.0.1.1; using 172.22.131.99 instead (on interface eth0)\n",
      "23/01/16 13:32:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/marcozo/miniconda3/envs/synapseml/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/01/16 13:32:39 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "https://mmlspark.azureedge.net/maven added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /home/marcozo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/marcozo/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      "com.microsoft.azure#azure-storage added as a dependency\n",
      "com.microsoft.azure#synapseml_2.12 added as a dependency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/marcozo/miniconda3/envs/synapseml/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1317ef6b-13a4-4cff-af2b-208f5df7692f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in spark-list\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in local-m2-cache\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in local-m2-cache\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.microsoft.azure#azure-storage;8.6.6 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.12 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.4 in spark-list\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.2.4 in central\n",
      "\tfound com.google.guava#guava;24.1.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;1.3.9 in local-m2-cache\n",
      "\tfound org.checkerframework#checker-compat-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      "\tfound com.microsoft.azure#synapseml_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound com.microsoft.azure#synapseml-core_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound org.scalactic#scalactic_2.12;3.2.14 in central\n",
      "\tfound io.spray#spray-json_2.12;1.3.5 in central\n",
      "\tfound com.jcraft#jsch;0.1.54 in user-list\n",
      "\tfound org.apache.httpcomponents.client5#httpclient5;5.1.3 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5;5.1.3 in central\n",
      "\tfound org.apache.httpcomponents.core5#httpcore5-h2;5.1.3 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in user-list\n",
      "\tfound commons-codec#commons-codec;1.15 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpmime;4.5.13 in local-m2-cache\n",
      "\tfound com.linkedin.isolation-forest#isolation-forest_3.2.0_2.12;2.0.8 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in user-list\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.2.0 in central\n",
      "\tfound org.tukaani#xz;1.8 in local-m2-cache\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in local-m2-cache\n",
      "\tfound org.testng#testng;6.8.8 in central\n",
      "\tfound org.beanshell#bsh;2.0b4 in local-m2-cache\n",
      "\tfound com.beust#jcommander;1.27 in central\n",
      "\tfound com.microsoft.azure#synapseml-deep-learning_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound com.microsoft.azure#synapseml-opencv_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound org.openpnp#opencv;3.2.0-1 in central\n",
      "\tfound com.microsoft.azure#onnx-protobuf_2.12;0.9.1 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 in central\n",
      "\tfound com.microsoft.azure#synapseml-cognitive_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound com.microsoft.cognitiveservices.speech#client-jar-sdk;1.14.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-vw_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound com.github.vowpalwabbit#vw-jni;9.3.0 in central\n",
      "\tfound com.microsoft.azure#synapseml-lightgbm_2.12;0.10.2-114-409e395c-SNAPSHOT in local-m2-cache\n",
      "\tfound com.microsoft.ml.lightgbm#lightgbmlib;3.3.300 in central\n",
      ":: resolution report :: resolve 16032ms :: artifacts dl 20ms\n",
      "\t:: modules in use:\n",
      "\tcom.beust#jcommander;1.27 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.9.4 from central in [default]\n",
      "\tcom.github.vowpalwabbit#vw-jni;9.3.0 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;1.3.9 from local-m2-cache in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 from central in [default]\n",
      "\tcom.google.guava#guava;24.1.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.54 from user-list in [default]\n",
      "\tcom.linkedin.isolation-forest#isolation-forest_3.2.0_2.12;2.0.8 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.2.4 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;8.6.6 from central in [default]\n",
      "\tcom.microsoft.azure#onnx-protobuf_2.12;0.9.1 from central in [default]\n",
      "\tcom.microsoft.azure#synapseml-cognitive_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#synapseml-core_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#synapseml-deep-learning_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#synapseml-lightgbm_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#synapseml-opencv_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#synapseml-vw_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.azure#synapseml_2.12;0.10.2-114-409e395c-SNAPSHOT from local-m2-cache in [default]\n",
      "\tcom.microsoft.cognitiveservices.speech#client-jar-sdk;1.14.0 from central in [default]\n",
      "\tcom.microsoft.ml.lightgbm#lightgbmlib;3.3.300 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime_gpu;1.8.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.spray#spray-json_2.12;1.3.5 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.4 from spark-list in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpmime;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents.client5#httpclient5;5.1.3 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5;5.1.3 from central in [default]\n",
      "\torg.apache.httpcomponents.core5#httpcore5-h2;5.1.3 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.2.0 from central in [default]\n",
      "\torg.beanshell#bsh;2.0b4 from local-m2-cache in [default]\n",
      "\torg.checkerframework#checker-compat-qual;2.0.0 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from local-m2-cache in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from local-m2-cache in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.openpnp#opencv;3.2.0-1 from central in [default]\n",
      "\torg.scalactic#scalactic_2.12;3.2.14 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from user-list in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from local-m2-cache in [default]\n",
      "\torg.testng#testng;6.8.8 from central in [default]\n",
      "\torg.tukaani#xz;1.8 from local-m2-cache in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from user-list in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 by [com.microsoft.azure#azure-storage;8.6.6] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.12 by [org.slf4j#slf4j-api;1.7.25] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.8.1 by [org.apache.commons#commons-lang3;3.4] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   55  |   10  |   10  |   4   ||   51  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: ERRORS\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\tunknown resolver null\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1317ef6b-13a4-4cff-af2b-208f5df7692f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 51 already retrieved (0kB/13ms)\n",
      "23/01/16 13:32:56 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/16 13:32:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/01/16 13:32:56 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "23/01/16 13:32:56 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "23/01/16 13:32:56 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "23/01/16 13:32:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Bootstrap Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.apache.hadoop:hadoop-azure:3.3.1,com.microsoft.azure:azure-storage:8.6.6,com.microsoft.azure:synapseml_2.12:0.10.2-114-409e395c-SNAPSHOT\",\n",
    "    )\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "    .config(\n",
    "        \"spark.jars.excludes\",\n",
    "        \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalatest:scalatest_2.12,com.fasterxml.jackson.core:jackson-databind\",\n",
    "    )\n",
    "    .config(\"spark.yarn.user.classpath.first\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "from synapse.ml.core.platform import *\n",
    "\n",
    "from synapse.ml.core.platform import materializing_display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/16 13:34:49 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-azure-file-system.properties,hadoop-metrics2.properties\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records read: 3\n",
      "Schema: \n",
      "root\n",
      " |-- input: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"input\", T.StringType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = (\n",
    "    spark.read.format(\"text\")\n",
    "    .schema(schema)\n",
    "    .load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/decisionservice.json\")\n",
    ")\n",
    "# print dataset basic info\n",
    "print(\"records read: \" + str(df.count()))\n",
    "print(\"Schema: \")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[input: string]\n",
      "+--------------------+\n",
      "|               input|\n",
      "+--------------------+\n",
      "|{\"_label_cost\":-1...|\n",
      "|{\"_label_cost\":0,...|\n",
      "|{\"_label_cost\":-1...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use VowalWabbitFeaturizer to convert data features into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- input: string (nullable = true)\n",
      " |-- json: struct (nullable = true)\n",
      " |    |-- EventId: string (nullable = true)\n",
      " |    |-- _label_probability: float (nullable = true)\n",
      " |    |-- _labelIndex: integer (nullable = true)\n",
      " |    |-- _label_cost: float (nullable = true)\n",
      " |-- EventId: string (nullable = true)\n",
      " |-- rewards: struct (nullable = false)\n",
      " |    |-- reward: float (nullable = true)\n",
      " |-- probLog: float (nullable = true)\n",
      " |-- chosenActionIndex: integer (nullable = true)\n",
      " |-- splitId: integer (nullable = false)\n",
      "\n",
      "DataFrame[json: struct<EventId:string,_label_probability:float,_labelIndex:int,_label_cost:float>, EventId: string, rewards: struct<reward:float>, probLog: float, chosenActionIndex: int, splitId: int]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+--------------------------------+-------+---------+-----------------+-------+\n",
      "|json                                                  |EventId                         |rewards|probLog  |chosenActionIndex|splitId|\n",
      "+------------------------------------------------------+--------------------------------+-------+---------+-----------------+-------+\n",
      "|{fbe7a11d120b4df4bf23b836de8a29d1, 0.8166667, 9, 0.0} |fbe7a11d120b4df4bf23b836de8a29d1|{0.0}  |0.8166667|9                |0      |\n",
      "|{0074434d3a3a46529f65de8a59631939, 0.8166667, 9, -1.0}|0074434d3a3a46529f65de8a59631939|{-1.0} |0.8166667|9                |0      |\n",
      "|{9077f996581148978a0ebe2484260dab, 0.8166667, 9, -1.0}|9077f996581148978a0ebe2484260dab|{-1.0} |0.8166667|9                |0      |\n",
      "+------------------------------------------------------+--------------------------------+-------+---------+-----------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:==========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from synapse.ml.vw import VowpalWabbitDSJsonTransformer\n",
    "\n",
    "df_ready = (\n",
    "    VowpalWabbitDSJsonTransformer()\n",
    "    .setDsJsonColumn(\"input\")\n",
    "    .transform(df)\n",
    "    .withColumn(\"splitId\", F.lit(0))\n",
    "    .repartition(2)\n",
    ")\n",
    "df_ready.printSchema()\n",
    "\n",
    "# exclude JSON as it's too messy\n",
    "display(df_ready.drop(\"input\"))\n",
    "\n",
    "df_ready.drop(\"input\").show(5, False)  # 1, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "\n",
    "VowpalWabbits \n",
    "* trains a model for each split (=group)\n",
    "* synchronizes accross partitions after every split\n",
    "* store the 1-step ahead predictions in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/16 13:53:10 WARN VowpalWabbitGeneric: VowpalWabbit args: --cb_adf --cb_type mtr --clip_p 0.1 -q GT -q MS -q GR -q OT -q MT -q OS --dsjson --preserve_performance_counters --no_stdin)\n",
      "creating quadratic features for pairs: GT MS GR OT MT OS\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "cb_type = mtr\n",
      "Enabled reductions: gd, scorer-identity, csoaa_ldf-rank, cb_adf, shared_feature_merger\n",
      "Input label = cb\n",
      "Output pred = action_scores\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "\n",
      "finished run\n",
      "number of examples = 0\n",
      "weighted example sum = 0.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 0\n",
      "23/01/16 13:53:10 WARN VowpalWabbitGeneric: VowpalWabbit args: --cb_adf --cb_type mtr --clip_p 0.1 -q GT -q MS -q GR -q OT -q MT -q OS --dsjson --preserve_performance_counters --no_stdin)\n",
      "creating quadratic features for pairs: GT MS GR OT MT OS            (0 + 1) / 1]\n",
      "creating quadratic features for pairs: GT MS GR OT MT OS\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "cb_type = mtr\n",
      "Enabled reductions: gd, scorer-identity, csoaa_ldf-rank, cb_adf, shared_feature_merger\n",
      "Input label = cb\n",
      "Output pred = action_scores\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "0.000000 0.000000            1            1.0       9:0:0.82            0:0     1791\n",
      "using no cache\n",
      "Reading datafile = none\n",
      "num sources = 0\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "cb_type = mtr\n",
      "Enabled reductions: gd, scorer-identity, csoaa_ldf-rank, cb_adf, shared_feature_merger\n",
      "Input label = cb\n",
      "Output pred = action_scores\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "0.000000 0.000000            1            1.0      9:-1:0.82            0:0     1791\n",
      "\n",
      "finished run\n",
      "number of examples = 1\n",
      "weighted example sum = 1.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.000000\n",
      "total feature number = 1726\n",
      "0.000000 0.000000            2            2.0      9:-1:0.82        6:-2.67     1791\n",
      "\n",
      "finished run\n",
      "number of examples = 2\n",
      "weighted example sum = 2.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.000000\n",
      "total feature number = 3452\n",
      "23/01/16 13:53:11 WARN VowpalWabbitGeneric: VowpalWabbit args: --cb_adf --cb_type mtr --clip_p 0.1 -q GT -q MS -q GR -q OT -q MT -q OS --dsjson --preserve_performance_counters --quiet --no_stdin)\n"
     ]
    }
   ],
   "source": [
    "from synapse.ml.vw import VowpalWabbitGeneric\n",
    "\n",
    "model = (\n",
    "    VowpalWabbitGeneric(\n",
    "        passThroughArgs=\"--cb_adf --cb_type mtr --clip_p 0.1 -q GT -q MS -q GR -q OT -q MT -q OS --dsjson --preserve_performance_counters\"\n",
    "    )\n",
    "    .setInputCol(\"input\")\n",
    "    .setSplitCol(\"splitId\")\n",
    "    .setPredictionIdCol(\"EventId\")\n",
    "    .fit(df_ready)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EventId: string (nullable = true)\n",
      " |-- input: string (nullable = true)\n",
      " |-- json: struct (nullable = true)\n",
      " |    |-- EventId: string (nullable = true)\n",
      " |    |-- _label_probability: float (nullable = true)\n",
      " |    |-- _labelIndex: integer (nullable = true)\n",
      " |    |-- _label_cost: float (nullable = true)\n",
      " |-- rewards: struct (nullable = false)\n",
      " |    |-- reward: float (nullable = true)\n",
      " |-- probLog: float (nullable = true)\n",
      " |-- chosenActionIndex: integer (nullable = true)\n",
      " |-- splitId: integer (nullable = false)\n",
      " |-- predictions: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- action: integer (nullable = false)\n",
      " |    |    |-- score: float (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_headers_predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/16 14:01:16 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "[Stage 110:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " EventId           | fbe7a11d120b4df4bf23b836de8a29d1                                                                                                                                                                                           \n",
      " json              | {fbe7a11d120b4df4bf23b836de8a29d1, 0.8166667, 9, 0.0}                                                                                                                                                                      \n",
      " rewards           | {0.0}                                                                                                                                                                                                                      \n",
      " probLog           | 0.8166667                                                                                                                                                                                                                  \n",
      " chosenActionIndex | 9                                                                                                                                                                                                                          \n",
      " splitId           | 0                                                                                                                                                                                                                          \n",
      " predictions       | [{0, 0.0}, {1, 0.0}, {2, 0.0}, {3, 0.0}, {4, 0.0}, {5, 0.0}, {6, 0.0}, {7, 0.0}, {8, 0.0}, {9, 0.0}, {10, 0.0}, {11, 0.0}]                                                                                                 \n",
      "-RECORD 1---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " EventId           | 0074434d3a3a46529f65de8a59631939                                                                                                                                                                                           \n",
      " json              | {0074434d3a3a46529f65de8a59631939, 0.8166667, 9, -1.0}                                                                                                                                                                     \n",
      " rewards           | {-1.0}                                                                                                                                                                                                                     \n",
      " probLog           | 0.8166667                                                                                                                                                                                                                  \n",
      " chosenActionIndex | 9                                                                                                                                                                                                                          \n",
      " splitId           | 0                                                                                                                                                                                                                          \n",
      " predictions       | [{0, 0.0}, {1, 0.0}, {2, 0.0}, {3, 0.0}, {4, 0.0}, {5, 0.0}, {6, 0.0}, {7, 0.0}, {8, 0.0}, {9, 0.0}, {10, 0.0}, {11, 0.0}]                                                                                                 \n",
      "-RECORD 2---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " EventId           | 9077f996581148978a0ebe2484260dab                                                                                                                                                                                           \n",
      " json              | {9077f996581148978a0ebe2484260dab, 0.8166667, 9, -1.0}                                                                                                                                                                     \n",
      " rewards           | {-1.0}                                                                                                                                                                                                                     \n",
      " probLog           | 0.8166667                                                                                                                                                                                                                  \n",
      " chosenActionIndex | 9                                                                                                                                                                                                                          \n",
      " splitId           | 0                                                                                                                                                                                                                          \n",
      " predictions       | [{6, -2.6695356}, {5, -0.77715737}, {9, -0.39329645}, {2, -0.34390783}, {10, -0.24045363}, {1, -0.2339408}, {3, -0.18807104}, {7, -0.18605101}, {0, -0.16404954}, {4, -0.16106708}, {8, -0.049168557}, {11, -0.049168557}] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_headers_predictions.drop(\"input\").show(5, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/16 14:08:10 WARN SimpleFunctionRegistry: The function snips replaced a previously registered function.\n",
      "23/01/16 14:08:10 WARN SimpleFunctionRegistry: The function ips replaced a previously registered function.\n",
      "23/01/16 14:08:10 WARN SimpleFunctionRegistry: The function cressieread replaced a previously registered function.\n",
      "23/01/16 14:08:10 WARN SimpleFunctionRegistry: The function cressiereadinterval replaced a previously registered function.\n",
      "23/01/16 14:08:10 WARN SimpleFunctionRegistry: The function cressiereadintervalempirical replaced a previously registered function.\n",
      "23/01/16 14:08:11 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "23/01/16 14:08:11 WARN SparkConf: The configuration key 'spark.yarn.user.classpath.first' has been deprecated as of Spark 1.3 and may be removed in the future. Please use spark.{driver,executor}.userClassPathFirst instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------\n",
      " exampleCount                                        | 3                                                                     \n",
      " probPredNonZeroCount                                | 0                                                                     \n",
      " minimumImportanceWeight                             | 0.0                                                                   \n",
      " maximumImportanceWeight                             | 0.0                                                                   \n",
      " averageImportanceWeight                             | 0.0                                                                   \n",
      " averageSquaredImportanceWeight                      | 0.0                                                                   \n",
      " proportionOfMaximumImportanceWeight                 | 0.0                                                                   \n",
      " importance weight quantiles (0.25, 0.5, 0.75, 0.95) | [0.0, 0.0, 0.0, 0.0]                                                  \n",
      " reward                                              | {-1.0, 0.0, -1.0, 0.0, -0.6666666666666666, {-1.0, 0.0}, {-1.0, 0.0}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from synapse.ml.vw import VowpalWabbitCSETransformer\n",
    "\n",
    "df_predictions = model.getOneStepAheadPredictions()  # .show(5, False)\n",
    "df_headers = df_ready.drop(\"input\")\n",
    "\n",
    "df_headers_predictions = df_headers.join(df_predictions, \"EventId\")\n",
    "# df_headers_predictions.show()\n",
    "\n",
    "metrics = VowpalWabbitCSETransformer().transform(df_headers_predictions)\n",
    "\n",
    "metrics.show(100, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.select(\"reward.*\").show(100, False, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
