{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"500\"  src=\"https://azurecomcdn.azureedge.net/cvt-18f087887a905ed3ae5310bee894aa53fc03cfffadc5dc9902bfe3469d832fec/less/images/section/azure-maps.png\" />\n",
    "\n",
    "# Azure Maps Geospatial Services\n",
    "\n",
    "[Microsoft Azure Maps ](https://azure.microsoft.com/en-us/services/azure-maps/) provides developers from all industries with powerful geospatial capabilities. Those geospatial capabilities are packed with the freshest mapping data. Azure Maps is available for web, mobile (iOS and Android), Microsoft Power BI, Microsoft Power Apps and Microsoft Synapse. Azure Maps is an Open API compliant set of REST APIs. The following are only a high-level overview of the services which Azure Maps offers - Maps, Search, Routing, Traffic, Weather, Time Zones, Geolocation, Geofencing, Map Data, Creator, and Spatial Operations.\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Geocode addresses\n",
    "[**Address Geocoding**](https://docs.microsoft.com/en-us/rest/api/maps/search/post-search-address-batch) The Search Address Batch API sends batches of queries to Search Address API using just a single API call. This API geocodes text addresses or partial addresses and the geocoding search index will be queried for everything above the street level data. **Note** that the geocoder is very tolerant of typos and incomplete addresses. It will also handle everything from exact street addresses or street or intersections as well as higher level geographies such as city centers, counties, states etc.\n",
    "\n",
    "### Reverse Geocode Coordinates\n",
    "[**Reverse Geocoding**](https://docs.microsoft.com/en-us/rest/api/maps/search/post-search-address-reverse-batch) The Search Address Reverse Batch API sends batches of queries to Search Address Reverse API using just a single API call. This API takes in location coordinates and translates them into human readable street addresses. Most often this is needed in tracking applications where you receive a GPS feed from the device or asset and wish to know what address where the coordinate is located.\n",
    "\n",
    "### Get Point In Polygon\n",
    "[**Get Point in Polygon**](https://docs.microsoft.com/en-us/rest/api/maps/spatial/get-point-in-polygon) This API returns a boolean value indicating whether a point is inside a set of polygons. The set of polygons can we pre-created by using the [**Data Upload API**](https://docs.microsoft.com/en-us/rest/api/maps/data/upload-preview)  referenced by a unique udid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Sign into the [Azure Portal](https://portal.azure.com) and create an Azure Maps account by following these [instructions](https://docs.microsoft.com/en-us/azure/azure-maps/how-to-manage-account-keys#create-a-new-account).\n",
    "1. Once the Maps account is created, provision a Maps Creator Resource by following these [instructions](https://docs.microsoft.com/en-us/azure/azure-maps/how-to-manage-creator#create-creator-resource). Creator is a [geographically scoped service](https://docs.microsoft.com/en-us/azure/azure-maps/creator-geographic-scope). Pick appropriate location while provisioning the creator resource. \n",
    "1. Follow these [instructions](https://docs.microsoft.com/en-us/azure/cognitive-services/big-data/getting-started#create-an-apache-spark-cluster) to set up your Azure Databricks environment and install SynapseML.\n",
    "1. After you create a new notebook in Azure Databricks, copy the **Shared code** below and paste into a new cell in your notebook.\n",
    "1. Choose a service sample, below, and copy paste it into a second new cell in your notebook.\n",
    "1. Replace the `AZUREMAPS_API_KEY` placeholders with your own [Maps account key](https://docs.microsoft.com/en-us/azure/azure-maps/how-to-manage-authentication#view-authentication-details).\n",
    "1. Choose the run button (triangle icon) in the upper right corner of the cell, then select **Run Cell**.\n",
    "1. View results in a table below the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared code\n",
    "\n",
    "To get started, we'll need to add this code to the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# Configure more resiliant requests to stop flakiness\n",
    "retry_strategy = Retry(\n",
    "    total=3,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    method_whitelist=[\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"],\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", adapter)\n",
    "http.mount(\"http://\", adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"AZURE_SERVICE\", None) == \"Microsoft.ProjectArcadia\":\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    from notebookutils.mssparkutils.credentials import getSecret\n",
    "\n",
    "    os.environ[\"AZURE_MAPS_KEY\"] = getSecret(\"mmlspark-build-keys\", \"azuremaps-api-key\")\n",
    "    from notebookutils.visualization import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import *\n",
    "from synapse.ml.geospatial import *\n",
    "\n",
    "# An Azure Maps account key\n",
    "azureMapsKey = os.environ[\"AZURE_MAPS_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding sample\n",
    "\n",
    "The azure maps geocoder sends batches of queries to the [Search Address API](https://docs.microsoft.com/en-us/rest/api/maps/search/getsearchaddress). The API limits the batch size to 10000 queries per request.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.stages import FixedMiniBatchTransformer, FlattenBatch\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"One, Microsoft Way, Redmond\",),\n",
    "        (\"400 Broad St, Seattle\",),\n",
    "        (\"350 5th Ave, New York\",),\n",
    "        (\"Pike Pl, Seattle\",),\n",
    "        (\"Champ de Mars, 5 Avenue Anatole France, 75007 Paris\",),\n",
    "    ],\n",
    "    [\n",
    "        \"address\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def extract_location_fields(df):\n",
    "    # Use this function to select only lat/lon columns into the dataframe\n",
    "    return df.select(\n",
    "        col(\"*\"),\n",
    "        col(\"output.response.results\")\n",
    "        .getItem(0)\n",
    "        .getField(\"position\")\n",
    "        .getField(\"lat\")\n",
    "        .alias(\"Latitude\"),\n",
    "        col(\"output.response.results\")\n",
    "        .getItem(0)\n",
    "        .getField(\"position\")\n",
    "        .getField(\"lon\")\n",
    "        .alias(\"Longitude\"),\n",
    "    ).drop(\"output\")\n",
    "\n",
    "\n",
    "# Run the Azure Maps geocoder to enhance the data with location data\n",
    "geocoder = (\n",
    "    AddressGeocoder()\n",
    "    .setSubscriptionKey(azureMapsKey)\n",
    "    .setAddressCol(\"address\")\n",
    "    .setOutputCol(\"output\")\n",
    ")\n",
    "\n",
    "# Show the results of your text query in a table format\n",
    "display(\n",
    "    extract_location_fields(\n",
    "        geocoder.transform(FixedMiniBatchTransformer().setBatchSize(10).transform(df))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Geocoding sample\n",
    "\n",
    "The azure maps reverse geocoder sends batches of queries to the [Search Address Reverse API](https://docs.microsoft.com/en-us/rest/api/maps/search/get-search-address-reverse) using just a single API call. The API allows caller to batch up to 10,000 queries per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that's tied to it's column names\n",
    "df = spark.createDataFrame(\n",
    "    (\n",
    "        (\n",
    "            (48.858561, 2.294911),\n",
    "            (47.639765, -122.127896),\n",
    "            (47.621028, -122.348170),\n",
    "            (47.734012, -122.102737),\n",
    "        )\n",
    "    ),\n",
    "    StructType([StructField(\"lat\", DoubleType()), StructField(\"lon\", DoubleType())]),\n",
    ")\n",
    "\n",
    "# Run the Azure Maps geocoder to enhance the data with location data\n",
    "rev_geocoder = (\n",
    "    ReverseAddressGeocoder()\n",
    "    .setSubscriptionKey(azureMapsKey)\n",
    "    .setLatitudeCol(\"lat\")\n",
    "    .setLongitudeCol(\"lon\")\n",
    "    .setOutputCol(\"output\")\n",
    ")\n",
    "\n",
    "# Show the results of your text query in a table format\n",
    "\n",
    "display(\n",
    "    rev_geocoder.transform(FixedMiniBatchTransformer().setBatchSize(10).transform(df))\n",
    "    .select(\n",
    "        col(\"*\"),\n",
    "        col(\"output.response.addresses\")\n",
    "        .getItem(0)\n",
    "        .getField(\"address\")\n",
    "        .getField(\"freeformAddress\")\n",
    "        .alias(\"In Polygon\"),\n",
    "        col(\"output.response.addresses\")\n",
    "        .getItem(0)\n",
    "        .getField(\"address\")\n",
    "        .getField(\"country\")\n",
    "        .alias(\"Intersecting Polygons\"),\n",
    "    )\n",
    "    .drop(\"output\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Point In Polygon sample\n",
    "\n",
    "This API returns a boolean value indicating whether a point is inside a set of polygons. The polygon can be added to you creator account using the [**Data Upload API**](https://docs.microsoft.com/en-us/rest/api/maps/data/upload-preview). The API then returnrs a unique udid to reference the polygon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup geojson Polygons in your azure maps creator account\n",
    "\n",
    "Based on where the creator resource was provisioned, we need to prefix the appropriate geography code to the azure maps URL. In this example, the assumption is that the creator resource was provisioned in `East US 2` Location and hence we pick `us` as our geo prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Choose a geography, you want your data to reside in.\n",
    "# Allowed values\n",
    "# us => North American datacenters\n",
    "# eu -> European datacenters\n",
    "url_geo_prefix = \"us\"\n",
    "\n",
    "# Upload a geojson with polygons in them\n",
    "r = http.post(\n",
    "    f\"https://{url_geo_prefix}.atlas.microsoft.com/mapData/upload?api-version=1.0&dataFormat=geojson&subscription-key={azureMapsKey}\",\n",
    "    json={\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\"geometryId\": \"test_geometry\"},\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [\n",
    "                        [\n",
    "                            [-122.14290618896484, 47.67856488312544],\n",
    "                            [-122.03956604003906, 47.67856488312544],\n",
    "                            [-122.03956604003906, 47.7483271435476],\n",
    "                            [-122.14290618896484, 47.7483271435476],\n",
    "                            [-122.14290618896484, 47.67856488312544],\n",
    "                        ]\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "long_running_operation = r.headers.get(\"location\")\n",
    "time.sleep(30)  # Sometimes this may take upto 30 seconds\n",
    "print(f\"Status Code: {r.status_code}, Long Running Operation: {long_running_operation}\")\n",
    "# This Operation completes in approximately 5 ~ 15 seconds\n",
    "user_data_id_resource_url = json.loads(\n",
    "    http.get(f\"{long_running_operation}&subscription-key={azureMapsKey}\").content\n",
    ")[\"resourceLocation\"]\n",
    "user_data_id = json.loads(\n",
    "    http.get(f\"{user_data_id_resource_url}&subscription-key={azureMapsKey}\").content\n",
    ")[\"udid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the function to check if point is in polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that's tied to it's column names\n",
    "df = spark.createDataFrame(\n",
    "    (\n",
    "        (\n",
    "            (48.858561, 2.294911),\n",
    "            (47.639765, -122.127896),\n",
    "            (47.621028, -122.348170),\n",
    "            (47.734012, -122.102737),\n",
    "        )\n",
    "    ),\n",
    "    StructType([StructField(\"lat\", DoubleType()), StructField(\"lon\", DoubleType())]),\n",
    ")\n",
    "\n",
    "# Run the Azure Maps geocoder to enhance the data with location data\n",
    "check_point_in_polygon = (\n",
    "    CheckPointInPolygon()\n",
    "    .setSubscriptionKey(azureMapsKey)\n",
    "    .setGeography(url_geo_prefix)\n",
    "    .setUserDataIdentifier(user_data_id)\n",
    "    .setLatitudeCol(\"lat\")\n",
    "    .setLongitudeCol(\"lon\")\n",
    "    .setOutputCol(\"output\")\n",
    ")\n",
    "\n",
    "# Show the results of your text query in a table format\n",
    "display(\n",
    "    check_point_in_polygon.transform(df)\n",
    "    .select(\n",
    "        col(\"*\"),\n",
    "        col(\"output.result.pointInPolygons\").alias(\"In Polygon\"),\n",
    "        col(\"output.result.intersectingGeometries\").alias(\"Intersecting Polygons\"),\n",
    "    )\n",
    "    .drop(\"output\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = http.delete(\n",
    "    f\"https://{url_geo_prefix}.atlas.microsoft.com/mapData/{user_data_id}?api-version=1.0&subscription-key={azureMapsKey}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}