{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"AZURE_SERVICE\", None) == \"Microsoft.ProjectArcadia\":\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    from notebookutils.mssparkutils.credentials import getSecret\n",
    "\n",
    "    os.environ[\"VISION_API_KEY\"] = getSecret(\"mmlspark-build-keys\", \"cognitive-api-key\")\n",
    "    os.environ[\"AZURE_SEARCH_KEY\"] = getSecret(\n",
    "        \"mmlspark-build-keys\", \"azure-search-key\"\n",
    "    )\n",
    "    os.environ[\"TRANSLATOR_KEY\"] = getSecret(\"mmlspark-build-keys\", \"translator-key\")\n",
    "    from notebookutils.visualization import display\n",
    "\n",
    "\n",
    "key = os.environ[\"VISION_API_KEY\"]\n",
    "search_key = os.environ[\"AZURE_SEARCH_KEY\"]\n",
    "translator_key = os.environ[\"TRANSLATOR_KEY\"]\n",
    "\n",
    "search_service = \"mmlspark-azure-search\"\n",
    "search_index = \"form-demo-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "def blob_to_url(blob):\n",
    "    [prefix, postfix] = blob.split(\"@\")\n",
    "    container = prefix.split(\"/\")[-1]\n",
    "    split_postfix = postfix.split(\"/\")\n",
    "    account = split_postfix[0]\n",
    "    filepath = \"/\".join(split_postfix[1:])\n",
    "    return \"https://{}/{}/{}\".format(account, container, filepath)\n",
    "\n",
    "\n",
    "df2 = (\n",
    "    spark.read.format(\"binaryFile\")\n",
    "    .load(\"wasbs://ignite2021@mmlsparkdemo.blob.core.windows.net/form_subset/*\")\n",
    "    .select(\"path\")\n",
    "    .limit(10)\n",
    "    .select(udf(blob_to_url, StringType())(\"path\").alias(\"url\"))\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<embed src=\"https://mmlsparkdemo.blob.core.windows.net/ignite2021/form_svgs/Invoice11205.svg\" width=\"40%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import AnalyzeInvoices\n",
    "\n",
    "analyzed_df = (\n",
    "    AnalyzeInvoices()\n",
    "    .setSubscriptionKey(key)\n",
    "    .setLocation(\"eastus\")\n",
    "    .setImageUrlCol(\"url\")\n",
    "    .setOutputCol(\"invoices\")\n",
    "    .setErrorCol(\"errors\")\n",
    "    .setConcurrency(5)\n",
    "    .transform(df2)\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analyzed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import FormOntologyLearner\n",
    "\n",
    "organized_df = (\n",
    "    FormOntologyLearner()\n",
    "    .setInputCol(\"invoices\")\n",
    "    .setOutputCol(\"extracted\")\n",
    "    .fit(analyzed_df)\n",
    "    .transform(analyzed_df)\n",
    "    .select(\"url\", \"extracted.*\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(organized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "itemized_df = (\n",
    "    organized_df.select(\"*\", explode(col(\"Items\")).alias(\"Item\"))\n",
    "    .drop(\"Items\")\n",
    "    .select(\"Item.*\", \"*\")\n",
    "    .drop(\"Item\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(itemized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(itemized_df.where(col(\"ProductCode\") == 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import Translate\n",
    "\n",
    "translated_df = (\n",
    "    Translate()\n",
    "    .setSubscriptionKey(translator_key)\n",
    "    .setLocation(\"eastus\")\n",
    "    .setTextCol(\"Description\")\n",
    "    .setErrorCol(\"TranslationError\")\n",
    "    .setOutputCol(\"output\")\n",
    "    .setToLanguage([\"zh-Hans\", \"fr\", \"ru\", \"cy\"])\n",
    "    .setConcurrency(5)\n",
    "    .transform(itemized_df)\n",
    "    .withColumn(\"Translations\", col(\"output.translations\")[0])\n",
    "    .drop(\"output\", \"TranslationError\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(translated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, lit\n",
    "\n",
    "(\n",
    "    translated_df.withColumn(\"DocID\", monotonically_increasing_id().cast(\"string\"))\n",
    "    .withColumn(\"SearchAction\", lit(\"upload\"))\n",
    "    .writeToAzureSearch(\n",
    "        subscriptionKey=search_key,\n",
    "        actionCol=\"SearchAction\",\n",
    "        serviceName=search_service,\n",
    "        indexName=search_index,\n",
    "        keyCol=\"DocID\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://{}.search.windows.net/indexes/{}/docs/search?api-version=2019-05-06\".format(\n",
    "    search_service, search_index\n",
    ")\n",
    "requests.post(url, json={\"search\": \"door\"}, headers={\"api-key\": search_key}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": null,
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "save_output": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}