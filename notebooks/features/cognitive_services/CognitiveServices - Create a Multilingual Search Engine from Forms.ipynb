{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.environ.get(\"AZURE_SERVICE\", None) == \"Microsoft.ProjectArcadia\":\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    from notebookutils.mssparkutils.credentials import getSecret\n",
    "    os.environ['VISION_API_KEY'] = getSecret(\"mmlspark-build-keys\", \"cognitive-api-key\")\n",
    "    os.environ['AZURE_SEARCH_KEY'] = getSecret(\"mmlspark-build-keys\", \"azure-search-key\")\n",
    "    os.environ['TRANSLATOR_KEY'] = getSecret(\"mmlspark-build-keys\", \"translator-key\")\n",
    "    from notebookutils.visualization import display\n",
    "\n",
    "\n",
    "key = os.environ['VISION_API_KEY']\n",
    "search_key = os.environ['AZURE_SEARCH_KEY']\n",
    "translator_key = os.environ['TRANSLATOR_KEY']\n",
    "\n",
    "search_service = \"mmlspark-azure-search\"\n",
    "search_index = \"form-demo-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def blob_to_url(blob):\n",
    "  [prefix, postfix] = blob.split(\"@\")\n",
    "  container = prefix.split(\"/\")[-1]\n",
    "  split_postfix = postfix.split(\"/\")\n",
    "  account = split_postfix[0]\n",
    "  filepath = \"/\".join(split_postfix[1:])\n",
    "  return \"https://{}/{}/{}\".format(account, container, filepath)\n",
    "\n",
    "\n",
    "df2 = (spark.read.format(\"binaryFile\")\n",
    "       .load(\"wasbs://ignite2021@mmlsparkdemo.blob.core.windows.net/form_subset/*\")\n",
    "       .select(\"path\")\n",
    "       .limit(10)\n",
    "       .select(udf(blob_to_url, StringType())(\"path\").alias(\"url\"))\n",
    "       .cache()\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<embed src=\"https://mmlsparkdemo.blob.core.windows.net/ignite2021/form_svgs/Invoice11205.svg\" width=\"40%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import AnalyzeInvoices\n",
    "\n",
    "analyzed_df = (AnalyzeInvoices()\n",
    "  .setSubscriptionKey(key)\n",
    "  .setLocation(\"eastus\")\n",
    "  .setImageUrlCol(\"url\")\n",
    "  .setOutputCol(\"invoices\")\n",
    "  .setErrorCol(\"errors\")\n",
    "  .setConcurrency(5)\n",
    "  .transform(df2)\n",
    "  .cache())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(analyzed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import FormOntologyLearner\n",
    "\n",
    "organized_df = (FormOntologyLearner()\n",
    "  .setInputCol(\"invoices\")\n",
    "  .setOutputCol(\"extracted\")\n",
    "  .fit(analyzed_df)\n",
    "  .transform(analyzed_df)\n",
    "  .select(\"url\", \"extracted.*\")\n",
    "  .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(organized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "itemized_df = (organized_df\n",
    "        .select(\"*\", explode(col(\"Items\")).alias(\"Item\"))\n",
    "        .drop(\"Items\")\n",
    "        .select(\"Item.*\", \"*\")\n",
    "        .drop(\"Item\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(itemized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(itemized_df.where(col(\"ProductCode\") == 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import Translate\n",
    "\n",
    "translated_df = (Translate()\n",
    "    .setSubscriptionKey(translator_key)\n",
    "    .setLocation(\"eastus\")\n",
    "    .setTextCol(\"Description\")\n",
    "    .setErrorCol(\"TranslationError\")\n",
    "    .setOutputCol(\"output\")\n",
    "    .setToLanguage([\"zh-Hans\", \"fr\", \"ru\", \"cy\"])\n",
    "    .setConcurrency(5)\n",
    "    .transform(itemized_df)\n",
    "    .withColumn(\"Translations\", col(\"output.translations\")[0])\n",
    "    .drop(\"output\", \"TranslationError\")\n",
    "    .cache())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(translated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.cognitive import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, lit\n",
    "\n",
    "(translated_df\n",
    "  .withColumn(\"DocID\", monotonically_increasing_id().cast(\"string\"))\n",
    "  .withColumn(\"SearchAction\", lit(\"upload\"))\n",
    "  .writeToAzureSearch(\n",
    "    subscriptionKey=search_key,\n",
    "    actionCol=\"SearchAction\",\n",
    "    serviceName=search_service,\n",
    "    indexName=search_index,\n",
    "    keyCol=\"DocID\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://{}.search.windows.net/indexes/{}/docs/search?api-version=2019-05-06'.format(search_service, search_index)\n",
    "requests.post(url, json={\"search\": \"door\"}, headers = {\"api-key\": search_key}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": null,
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "save_output": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}