{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning - Deep Vision Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup -- reinstall horovod based on new version of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install /dbfs/FileStore/shared_uploads/serenaruan@microsoft.com/synapseml_dl-0.9.5.dev1-py3-none-any.whl --force-reinstall --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! horovodrun --check-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as T\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(path):\n",
    "  num = int(path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1])\n",
    "  return num // 81\n",
    "\n",
    "assign_label_udf = udf(assign_label, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files are already uploaded for build test machine\n",
    "train_df = spark.read.format(\"binaryFile\")\\\n",
    "          .option(\"pathGlobFilter\", \"*.jpg\")\\\n",
    "          .load(\"/tmp/17flowers/train\")\\\n",
    "          .withColumn(\"image\", col(\"path\"))\\\n",
    "          .withColumn(\"label\", assign_label_udf(col(\"path\")))\\\n",
    "          .select(\"image\", \"label\")\n",
    "\n",
    "display(train_df.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.read.format(\"binaryFile\")\\\n",
    "          .option(\"pathGlobFilter\", \"*.jpg\")\\\n",
    "          .load(\"/tmp/17flowers/test\")\\\n",
    "          .withColumn(\"image\", col(\"path\"))\\\n",
    "          .withColumn(\"label\", assign_label_udf(col(\"path\")))\\\n",
    "          .select(\"image\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _transform_row(row):\n",
    "    path = row[\"image\"].replace(\"dbfs:/\", \"/dbfs/\")\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = transform(image).numpy()\n",
    "    label = row[\"label\"]\n",
    "    return {\"image\": image, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from horovod.spark.common.store import DBFSLocalStore\n",
    "from horovod.spark.common.backend import SparkBackend\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "from synapse.ml.dl import *\n",
    "\n",
    "run_output_dir = \"/dbfs/FileStore/test/resnet50\"\n",
    "store = DBFSLocalStore(run_output_dir)\n",
    "\n",
    "backend = SparkBackend(\n",
    "    num_proc=2,\n",
    "    stdout=sys.stdout,\n",
    "    stderr=sys.stderr,\n",
    "    prefix_output_with_timestamp=True,\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "callbacks = [ModelCheckpoint(filename=\"{epoch}-{train_loss:.2f}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_vision_classifier = DeepVisionClassifier(\n",
    "    backbone=\"resnet50\",\n",
    "    store=store,\n",
    "    backend=backend,\n",
    "    callbacks=callbacks,\n",
    "    input_shapes=[[-1, 3, 224, 224]],\n",
    "    num_classes=17,\n",
    "    feature_cols=[\"image\"],\n",
    "    label_cols=[\"label\"],\n",
    "    batch_size=16,\n",
    "    epochs=epochs,\n",
    "    validation=0.1,\n",
    "    transformation_fn=_transform_row,\n",
    ")\n",
    "\n",
    "deep_vision_model = deep_vision_classifier.fit(train_df).setOutputCols([\"label_prob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_and_transform(path):\n",
    "    path = path.replace(\"dbfs:/\", \"/dbfs/\")\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = DenseVector(transform(image).numpy().reshape(-1))\n",
    "    return image\n",
    "\n",
    "read_image_and_transform_udf = udf(read_image_and_transform, VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_trans = test_df.withColumn(\"features\", read_image_and_transform_udf(\"image\"))\n",
    "argmax = udf(lambda v: float(np.argmax(v)), returnType=T.DoubleType())\n",
    "pred_df = deep_vision_model.setFeatureColumns([\"features\"]).transform(test_df_trans).withColumn(\"label_pred\", argmax(col(\"label_prob\")))\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    predictionCol=\"label_pred\", labelCol=\"label\", metricName=\"accuracy\"\n",
    ")\n",
    "print(\"Test accuracy:\", evaluator.evaluate(pred_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('synapseml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e618ed4c1ce23faf0894af85b02b5324888e2d70eeb0f2451cf171faa1cbba7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
