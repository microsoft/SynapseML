{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "## ONNX Inference on Spark\n",
                "\n",
                "In this example, we will train a LightGBM model, convert the model to ONNX format and use the converted model to infer some testing data on Spark.\n",
                "\n",
                "Maven dependencies:\n",
                "\n",
                "- com.microsoft.onnxruntime:onnxruntime:1.8.1\n",
                "- com.microsoft.ml.spark:mmlspark-core:{mmlspark_version}\n",
                "- com.microsoft.ml.spark:mmlspark-deep-learning:{mmlspark_version}\n",
                "\n",
                "> For MML Spark dependencies, set the resolver to `https://mmlspark.azureedge.net/maven`, and set the version to master version.\n",
                "\n",
                "Python dependencies:\n",
                "\n",
                "- onnxmltools==1.7.0\n",
                "- lightgbm==3.2.1"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Download training data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd\r\n",
                "data=pd.read_csv(\"https://mmlspark.blob.core.windows.net/publicwasb/company_bankruptcy_prediction_data.csv\")\r\n",
                "data"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Use LightGBM to train a model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from lightgbm import LGBMClassifier, Dataset\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "\r\n",
                "y = data[\"Bankrupt?\"].values\r\n",
                "x = data.drop([\"Bankrupt?\"], axis=1).values\r\n",
                "x, x_test, y, y_test = train_test_split(x, y, test_size=0.15, random_state=42, stratify=y)\r\n",
                "train_data = Dataset(x, label=y)\r\n",
                "test_data = Dataset(x_test, label=y_test)\r\n",
                "\r\n",
                "model = LGBMClassifier(boosting_type=\"gbdt\", num_leaves=31, reg_alpha=0.5, reg_lambda=1, learning_rate=0.05, max_depth=-1, n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=2, objective=\"binary\", is_unbalance=\"true\", min_child_weight=20, random_state=2021, n_jobs=-1, min_split_gain=0.01)\r\n",
                "model.fit(x, y, verbose=1, eval_set=[(x, y),(x_test, y_test)], eval_names = ['train', 'test'], eval_metric='auc', early_stopping_rounds=300)\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Convert the model to ONNX format, load it into an `ONNXModel`, and inspect the model inputs and outputs."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from mmlspark.onnx import ONNXModel\r\n",
                "import numpy as np\r\n",
                "\r\n",
                "def convertModel(lgbm_model: LGBMClassifier, X: np.ndarray) -> bytes:\r\n",
                "  from onnxmltools.convert import convert_lightgbm\r\n",
                "  from onnxconverter_common.data_types import FloatTensorType\r\n",
                "  initial_types = [(\"input\", FloatTensorType([-1, x.shape[1]]))]\r\n",
                "  onnx_model = convert_lightgbm(lgbm_model, initial_types=initial_types, target_opset=9)\r\n",
                "  return onnx_model.SerializeToString()\r\n",
                "\r\n",
                "model_payload_ml = convertModel(model, x)\r\n",
                "onnx_ml = ONNXModel().setModelPayload(model_payload_ml)\r\n",
                "\r\n",
                "print(\"Model inputs:\" + str(onnx_ml.getModelInputs()))\r\n",
                "print(\"Model outputs:\" + str(onnx_ml.getModelOutputs()))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Map the model input to the input dataframe's column name (FeedDict), and map the output dataframe's column names to the model outputs (FetchDict)."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "input_name = list(onnx_ml.getModelInputs().keys())[0]\r\n",
                "output_name_prob = list(onnx_ml.getModelOutputs().keys())[0]\r\n",
                "output_name_pred = list(onnx_ml.getModelOutputs().keys())[1]\r\n",
                "\r\n",
                "onnx_ml.setDeviceType(\"CPU\").setFeedDict({input_name: \"features\"}).setFetchDict({\"probability\": output_name_prob, \"prediction\": output_name_pred}).setMiniBatchSize(5000)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create some testing data and transform the data through the ONNX model."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from pyspark.ml.feature import VectorAssembler\r\n",
                "\r\n",
                "n = 1000 * 1000\r\n",
                "m = 95\r\n",
                "test = np.random.rand(n, m)\r\n",
                "testPdf = pd.DataFrame(test)\r\n",
                "cols = list(map(str, testPdf.columns))\r\n",
                "testDf = spark.createDataFrame(testPdf).repartition(200)\r\n",
                "testDf = VectorAssembler().setInputCols(cols).setOutputCol(\"features\").transform(testDf).drop(*cols).cache()\r\n",
                "\r\n",
                "display(onnx_ml.transform(testDf))"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}