{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7a2d7f1b-99c4-44d2-9ac5-62ca59002d61",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Interpretability - Image Explainers\n",
    "\n",
    "In this example, we use LIME and Kernel SHAP explainers to explain the ResNet50 model's multi-class output of an image.\n",
    "\n",
    "First we import the packages and define some UDFs and a plotting function we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ae5c16d1-fd1d-466b-9974-9a514f5f0e92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mmlspark.downloader import ModelDownloader\n",
    "from mmlspark.explainers import *\n",
    "from mmlspark.cntk import ImageFeaturizer\n",
    "from mmlspark.stages import UDFTransformer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL, io\n",
    "from PIL import Image\n",
    "\n",
    "vec_access = udf(lambda vec, i: float(vec[i]), FloatType())\n",
    "vec_slice = udf(lambda vec, indices: (vec.toArray())[indices].tolist(), ArrayType(FloatType()))\n",
    "arg_top = udf(lambda vec, n: (-vec.toArray()).argsort()[:n].tolist(), ArrayType(IntegerType()))\n",
    "\n",
    "\n",
    "def plot_superpixels(image_data, sp_clusters, weights):\n",
    "    image_bytes = image_data\n",
    "    superpixels = sp_clusters\n",
    "    green_value = np.percentile(weights, 80)\n",
    "    red_value = np.percentile(weights, 20)\n",
    "    img = (PIL.Image.open(io.BytesIO(image_bytes))).convert(\"RGBA\")\n",
    "    image_array = np.asarray(img).copy()\n",
    "    for (sp, v) in zip(superpixels, weights):\n",
    "        if v > green_value:\n",
    "            for (x, y) in sp:\n",
    "                image_array[y, x, 1] = 255\n",
    "                image_array[y, x, 3] = 200\n",
    "        if v < red_value:\n",
    "            for (x, y) in sp:\n",
    "                image_array[y, x, 0] = 255\n",
    "                image_array[y, x, 3] = 200\n",
    "    plt.clf()\n",
    "    plt.imshow(image_array)\n",
    "    display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54f606d1-f0e1-482c-a363-eec5d040fc12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We download an image for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e3f6ce95-29dc-4caf-b088-22ddd763e090",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_image_url = (\n",
    "    \"https://mmlspark.blob.core.windows.net/publicwasb/explainers/images/david-lusvardi-dWcUncxocQY-unsplash.jpg\"\n",
    ")\n",
    "with urllib.request.urlopen(test_image_url) as url:\n",
    "    barr = url.read()\n",
    "\n",
    "img = (PIL.Image.open(io.BytesIO(barr))).convert(\"RGBA\")\n",
    "image_array = np.asarray(img).copy()\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(image_array)\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5bbfae73-8289-49cc-9ddb-212ed3905bbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Create a dataframe from the downloaded image, and use ResNet50 model to infer the image.\n",
    "\n",
    "The result shows 88.7% probability of \"upright piano\", and 9.6% probability of \"cello\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2eeee2c8-6d20-4c19-ba4a-092c549cccb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_df = spark.createDataFrame([(bytearray(barr),)], [\"image\"])\n",
    "\n",
    "network = ModelDownloader(spark, \"dbfs:/Models/\").downloadByName(\"ResNet50\")\n",
    "\n",
    "model = ImageFeaturizer(inputCol=\"image\", outputCol=\"probability\", cutOutputLayers=0).setModel(network)\n",
    "\n",
    "predicted = (\n",
    "    model.transform(image_df)\n",
    "    .withColumn(\"top2pred\", arg_top(col(\"probability\"), lit(2)))\n",
    "    .withColumn(\"top2prob\", vec_slice(col(\"probability\"), col(\"top2pred\")))\n",
    ")\n",
    "\n",
    "display(predicted.select(\"top2pred\", \"top2prob\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d9785d3d-2d92-4990-bda0-8867bfc5f251",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First we use the LIME image explainer to explain the model's top 2 classes' probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0a550898-47d1-4e63-acbb-f3ee68d94e4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lime = (\n",
    "    ImageLIME()\n",
    "    .setModel(model)\n",
    "    .setOutputCol(\"weights\")\n",
    "    .setInputCol(\"image\")\n",
    "    .setCellSize(50.0)\n",
    "    .setModifier(20.0)\n",
    "    .setNumSamples(500)\n",
    "    .setMetricsCol(\"r2\")\n",
    "    .setTargetCol(\"probability\")\n",
    "    .setTargetClassesCol(\"top2pred\")\n",
    "    .setSamplingFraction(0.7)\n",
    ")\n",
    "\n",
    "lime_result = (\n",
    "    lime.transform(predicted)\n",
    "    .withColumn(\"weights_piano\", col(\"weights\").getItem(0))\n",
    "    .withColumn(\"weights_cello\", col(\"weights\").getItem(1))\n",
    "    .withColumn(\"r2_piano\", vec_access(\"r2\", lit(0)))\n",
    "    .withColumn(\"r2_cello\", vec_access(\"r2\", lit(1)))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "display(lime_result.select(col(\"weights_piano\"), col(\"r2_piano\"), col(\"weights_cello\"), col(\"r2_cello\")))\n",
    "lime_row = lime_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41a48718-30b8-41e8-8dc0-0adedbd3a12d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We plot the LIME weights for \"piano\" output and \"cell\" output.\n",
    "\n",
    "Green area are superpixels with LIME weights above 90 percentile, and red area are superpixels with LIME weights below 10 percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "33915bc4-197c-453d-a4fc-3c12c26712c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_superpixels(barr, lime_row[\"superpixels\"][\"clusters\"], list(lime_row[\"weights_piano\"]))\n",
    "plot_superpixels(barr, lime_row[\"superpixels\"][\"clusters\"], list(lime_row[\"weights_cello\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "75ec74d0-1e74-46dd-aeeb-f41919875487",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Your results will look like:\n",
    "\n",
    "<img src=\"https://mmlspark.blob.core.windows.net/graphics/explainers/image-lime.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "578dcfcc-7659-40ff-afad-ebea55f4d870",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Then we use the Kernel SHAP image explainer to explain the model's top 2 classes' probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23cf13f4-093e-441d-becf-29c8d1eead0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap = (\n",
    "    ImageSHAP()\n",
    "    .setModel(model)\n",
    "    .setOutputCol(\"shaps\")\n",
    "    .setSuperpixelCol(\"superpixels\")\n",
    "    .setInputCol(\"image\")\n",
    "    .setCellSize(50.0)\n",
    "    .setModifier(20.0)\n",
    "    .setNumSamples(500)\n",
    "    .setMetricsCol(\"r2\")\n",
    "    .setTargetCol(\"probability\")\n",
    "    .setTargetClassesCol(\"top2pred\")\n",
    ")\n",
    "\n",
    "shap_result = (\n",
    "    shap.transform(predicted)\n",
    "    .withColumn(\"shaps_piano\", col(\"shaps\").getItem(0))\n",
    "    .withColumn(\"shaps_cello\", col(\"shaps\").getItem(1))\n",
    "    .withColumn(\"r2_piano\", vec_access(\"r2\", lit(0)))\n",
    "    .withColumn(\"r2_cello\", vec_access(\"r2\", lit(1)))\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "display(shap_result.select(col(\"shaps_piano\"), col(\"r2_piano\"), col(\"shaps_cello\"), col(\"r2_cello\")))\n",
    "shap_row = shap_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d069a2bd-20f2-4235-93a3-b145f93e2b4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We plot the SHAP values for \"piano\" output and \"cell\" output.\n",
    "\n",
    "Green area are superpixels with SHAP values above 90 percentile, and red area are superpixels with SHAP values below 10 percentile.\n",
    "\n",
    "> Notice that we drop the base value from the SHAP output before rendering the superpixels. The base value is the model output for the background (all black) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63c8d593-e336-46d5-94f4-a7466b65bfc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_superpixels(barr, shap_row[\"superpixels\"][\"clusters\"], list(shap_row[\"shaps_piano\"][1:]))\n",
    "plot_superpixels(barr, shap_row[\"superpixels\"][\"clusters\"], list(shap_row[\"shaps_cello\"][1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4a2673b4-cdec-41f7-a311-fa8939f6ae3a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Your results will look like:\n",
    "\n",
    "<img src=\"https://mmlspark.blob.core.windows.net/graphics/explainers/image-shap.png\"/>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Interpretability - Image Explainers",
   "notebookOrigID": 496759265154124,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
