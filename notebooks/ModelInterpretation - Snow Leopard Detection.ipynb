{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Automated Snow Leopard Detection with Microsoft ML for Apache Spark\n",
    "\n",
    "<img src=\"https://mmlspark.blob.core.windows.net/graphics/SnowLeopardAD/SLTrust.PNG\" width=\"900\" style=\"float: left;\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "if os.environ.get(\"AZURE_SERVICE\", None) == \"Microsoft.ProjectArcadia\":\n",
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    from notebookutils.mssparkutils.credentials import getSecret\n",
    "    os.environ[\"BING_IMAGE_SEARCH_KEY\"] = getSecret(\"mmlspark-keys\", \"bing-image-search-key\")\n",
    "\n",
    "# WARNING this notebook requires alot of memory.\n",
    "# If you get a heap space error, try dropping the number of images bing returns\n",
    "# or by writing out the images to parquet first\n",
    "\n",
    "# Replace the following with a line like: BING_IMAGE_SEARCH_KEY =  \"hdwo2oyd3o928s.....\"\n",
    "BING_IMAGE_SEARCH_KEY = os.environ[\"BING_IMAGE_SEARCH_KEY\"]"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from synapse.ml.cognitive import *\n",
    "from synapse.ml.core.spark import FluentAPI\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def bingPhotoSearch(name, queries, pages):\n",
    "  offsets = [offset*10 for offset in range(0, pages)] \n",
    "  parameters = [(query, offset) for offset in offsets for query in queries]\n",
    "  \n",
    "  return spark.createDataFrame(parameters, (\"queries\",\"offsets\")) \\\n",
    "    .mlTransform(\n",
    "      BingImageSearch()                             # Apply Bing Image Search\n",
    "        .setSubscriptionKey(BING_IMAGE_SEARCH_KEY)  # Set the API Key\n",
    "        .setOffsetCol(\"offsets\")                    # Specify a column containing the offsets\n",
    "        .setQueryCol(\"queries\")                     # Specify a column containing the query words\n",
    "        .setCount(10)                               # Specify the number of images to return per offset\n",
    "        .setImageType(\"photo\")                      # Specify a filter to ensure we get photos\n",
    "        .setOutputCol(\"images\")) \\\n",
    "    .mlTransform(BingImageSearch.getUrlTransformer(\"images\", \"urls\")) \\\n",
    "    .withColumn(\"labels\", lit(name)) \\\n",
    "    .limit(400)\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://mmlspark.blob.core.windows.net/graphics/SparkSummit2/cog_services.png\" width=\"900\" style=\"float: left;\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def displayDF(df, n=5, image_cols = set([\"urls\"])):\n",
    "  rows = df.take(n)\n",
    "  cols = df.columns\n",
    "  header = \"\".join([\"<th>\" + c  + \"</th>\" for c in cols])\n",
    "  \n",
    "  style = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table {\n",
    "    font-family: arial, sans-serif;\n",
    "    border-collapse: collapse;\n",
    "    width: 300;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    border: 1px solid #dddddd;\n",
    "    text-align: left;\n",
    "    padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "    background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\"\"\"\n",
    "  \n",
    "  table = []\n",
    "  for row in rows:\n",
    "    table.append(\"<tr>\")\n",
    "    for col in cols:\n",
    "      if col in image_cols:\n",
    "        rep = '<img src=\"{}\",  width=\"100\">'.format(row[col])\n",
    "      else:\n",
    "        rep = row[col]\n",
    "      table.append(\"<td>{}</td>\".format(rep))\n",
    "    table.append(\"</tr>\")\n",
    "  tableHTML = \"\".join(table)\n",
    "  \n",
    "  body = \"\"\"\n",
    "<body>\n",
    "<table>\n",
    "  <tr>\n",
    "    {} \n",
    "  </tr>\n",
    "  {}\n",
    "</table>\n",
    "</body>\n",
    "</html>\n",
    "  \"\"\".format(header, tableHTML)\n",
    "  try:\n",
    "    displayHTML(style + body)\n",
    "  except:\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "snowLeopardQueries = [\"snow leopard\"]\n",
    "snowLeopardUrls = bingPhotoSearch(\"snow leopard\", snowLeopardQueries, pages=100)\n",
    "displayDF(snowLeopardUrls)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "randomWords = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/random_words.parquet\").cache()\n",
    "randomWords.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "randomLinks = randomWords \\\r\n",
    "  .mlTransform(BingImageSearch()\r\n",
    "    .setSubscriptionKey(BING_IMAGE_SEARCH_KEY)\r\n",
    "    .setCount(10)\r\n",
    "    .setQueryCol(\"words\")\r\n",
    "    .setOutputCol(\"images\")) \\\r\n",
    "  .mlTransform(BingImageSearch.getUrlTransformer(\"images\", \"urls\")) \\\r\n",
    "  .withColumn(\"label\", lit(\"other\")) \\\r\n",
    "  .limit(400)\r\n",
    "  \r\n",
    "displayDF(randomLinks)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images = snowLeopardUrls.union(randomLinks).distinct().repartition(100)\\\r\n",
    "  .mlTransform(BingImageSearch.downloadFromUrls(\"urls\", \"image\", concurrency=5, timeout=5000))\\\r\n",
    "  .dropna()\r\n",
    "\r\n",
    "train, test = images.randomSplit([.7,.3], seed=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pyspark.ml import Pipeline\r\n",
    "from pyspark.ml.feature import StringIndexer\r\n",
    "from pyspark.ml.classification import LogisticRegression\r\n",
    "from pyspark.sql.functions import udf\r\n",
    "from synapse.ml.downloader import ModelDownloader\r\n",
    "from synapse.ml.cntk import ImageFeaturizer\r\n",
    "from synapse.ml.stages import UDFTransformer\r\n",
    "from pyspark.sql.types import *\r\n",
    "\r\n",
    "def getIndex(row):\r\n",
    "  return float(row[1])\r\n",
    "\r\n",
    "if os.environ.get(\"AZURE_SERVICE\", None) == \"Microsoft.ProjectArcadia\":\r\n",
    "  network = ModelDownloader(spark, \"abfss://synapse@mmlsparkeuap.dfs.core.windows.net/models/\").downloadByName(\"ResNet50\")\r\n",
    "else:\r\n",
    "  network = ModelDownloader(spark, \"dbfs:/Models/\").downloadByName(\"ResNet50\")\r\n",
    "\r\n",
    "model = Pipeline(stages=[\r\n",
    "  StringIndexer(inputCol = \"labels\", outputCol=\"index\"),\r\n",
    "  ImageFeaturizer(inputCol=\"image\", outputCol=\"features\", cutOutputLayers=1).setModel(network),\r\n",
    "  LogisticRegression(maxIter=5, labelCol=\"index\", regParam=10.0),\r\n",
    "  UDFTransformer()\\\r\n",
    "      .setUDF(udf(getIndex, DoubleType()))\\\r\n",
    "      .setInputCol(\"probability\")\\\r\n",
    "      .setOutputCol(\"leopard_prob\")\r\n",
    "])\r\n",
    "\r\n",
    "fitModel = model.fit(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://mmlspark.blob.core.windows.net/graphics/SnowLeopardAD/SLPipeline.PNG\" width=\"900\" style=\"float: left;\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plotConfusionMatrix(df, label, prediction, classLabels):\r\n",
    "  from synapse.ml.plot import confusionMatrix\r\n",
    "  import matplotlib.pyplot as plt\r\n",
    "  fig = plt.figure(figsize=(4.5, 4.5))\r\n",
    "  confusionMatrix(df, label, prediction, classLabels)\r\n",
    "  display(fig)\r\n",
    "\r\n",
    "if os.environ.get(\"AZURE_SERVICE\", None) != \"Microsoft.ProjectArcadia\":\r\n",
    "  plotConfusionMatrix(fitModel.transform(test), \"index\", \"prediction\", fitModel.stages[0].labels)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import urllib.request\r\n",
    "from synapse.ml.lime import ImageLIME\r\n",
    "\r\n",
    "test_image_url = \"https://mmlspark.blob.core.windows.net/graphics/SnowLeopardAD/snow_leopard1.jpg\"\r\n",
    "with urllib.request.urlopen(test_image_url) as url:\r\n",
    "    barr = url.read()\r\n",
    "test_subsample = spark.createDataFrame([(bytearray(barr),)], [\"image\"])\r\n",
    "\r\n",
    "lime = ImageLIME()\\\r\n",
    "  .setModel(fitModel)\\\r\n",
    "  .setPredictionCol(\"leopard_prob\")\\\r\n",
    "  .setOutputCol(\"weights\")\\\r\n",
    "  .setInputCol(\"image\")\\\r\n",
    "  .setCellSize(100.0)\\\r\n",
    "  .setModifier(50.0)\\\r\n",
    "  .setNSamples(300)\r\n",
    "\r\n",
    "result = lime.transform(test_subsample)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL, io, numpy as np\n",
    "\n",
    "def plot_superpixels(row):\n",
    "    image_bytes = row['image']\n",
    "    superpixels = row['superpixels']['clusters']\n",
    "    weights = list(row['weights'])\n",
    "    mean_weight = np.percentile(weights,90)\n",
    "    img = (PIL.Image.open(io.BytesIO(image_bytes))).convert('RGBA')\n",
    "    image_array = np.asarray(img).copy()\n",
    "    for (sp, w) in zip(superpixels, weights):\n",
    "        if w > mean_weight:\n",
    "            for (x, y) in sp:\n",
    "                image_array[y, x, 1] = 255\n",
    "                image_array[y, x, 3] = 200\n",
    "    plt.clf()\n",
    "    plt.imshow(image_array)\n",
    "    display()\n",
    "\n",
    "# Gets first row from the LIME-transformed data frame\n",
    "if os.environ.get(\"AZURE_SERVICE\", None) != \"Microsoft.ProjectArcadia\":\n",
    "    plot_superpixels(result.take(1)[0])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Your results will look like:\n",
    "<img src=\"https://mmlspark.blob.core.windows.net/graphics/SnowLeopardAD/lime_results.png\" width=\"900\" style=\"float: left;\"/>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}