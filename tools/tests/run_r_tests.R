library("sparklyr")
print(spark_available_versions(show_hadoop=TRUE, show_minor=TRUE))
flush.console()
Sys.sleep(1)
#spark_install(version = "3.2.1", hadoop_version = "3.2")
tryCatch({
  print("running spark_install_find")
  flush.console()
  Sys.sleep(1)
  spark_install_find(version = "3.2.1", hadoop_version = "3.2")
  flush.console()
  Sys.sleep(1)
  print("ran spark_install_find")  
  flush.console()
  Sys.sleep(1)
},
error=function(err) {
  print("Installing ../../../../../../../spark-3.2.1-bin-hadoop3.2.tgz")
  flush.console()
  Sys.sleep(1)
  spark_install_tar("../../../../../../../spark-3.2.1-bin-hadoop3.2.tgz")
  flush.console()
  Sys.sleep(1)
  print("installed ../../../../../../../spark-3.2.1-bin-hadoop3.2.tgz")
  flush.console()
  Sys.sleep(1)
})
options("testthat.output_file" = "../../../../r-test-results.xml")
tryCatch({
  flush.console()
  Sys.sleep(1)
  print(paste("SPARK_HOME=", Sys.getenv("SPARK_HOME")))
  flush.console()
  Sys.sleep(1)
  devtools::test(reporter = JunitReporter$new())
  flush.console()
  Sys.sleep(1)
},
error = function(err) {
  flush.console()
  Sys.sleep(1)
  print(paste("Error: ", err))
  flush.console()
  Sys.sleep(1)
  stop(err)
})