resources:
- repo: self

trigger:
  branches:
    include:
    - master
  paths:
    exclude:
    - README.md
    - docs/*
    - CODEOWNERS
    - .github

pr:
  branches:
    include:
    - master
  paths:
    exclude:
    - README.md
    - docs/*
    - CODEOWNERS
    - .github

variables:
  runTests: True
  CONDA_CACHE_DIR: /usr/share/miniconda/envs
  ComponentDetection.Timeout: 900

jobs:
- job: Style
  cancelTimeoutInMinutes: 0
  condition: eq(variables.runTests, 'True')
  pool:
    vmImage: ubuntu-18.04
  steps:
    - task: AzureCLI@1
      displayName: 'Scala Style Check'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: 'sbt scalastyle test:scalastyle'
    - task: UsePythonVersion@00
      inputs:
        versionSpec: '3.8'
    - script: pip install -r requirements.txt
      displayName: 'Install requirements'
    - bash: |
        black --check .
      displayName: 'Python Style Check'

- job: Publish
  cancelTimeoutInMinutes: 0
  pool:
    vmImage: ubuntu-18.04
  steps:
    #- template: templates/ivy_cache.yml
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - bash: |
        set -e
        source activate synapseml
        sbt packagePython
        sbt publishBlob publishDocs publishR publishPython
        sbt publishSigned
        sbt genBuildInfo
        echo "##vso[task.uploadsummary]$(pwd)/target/Build.md"
      displayName: Publish Artifacts
      env:
        STORAGE-KEY: $(storage-key)
        NEXUS-UN: $(nexus-un)
        NEXUS-PW: $(nexus-pw)
        PGP-PRIVATE: $(pgp-private)
        PGP-PUBLIC: $(pgp-public)
        PGP-PW: $(pgp-pw)
    - bash: |
        set -e
        sbt publishBadges
      condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))
      displayName: Publish Badges
      env:
        STORAGE-KEY: $(storage-key)
        NEXUS-UN: $(nexus-un)
        NEXUS-PW: $(nexus-pw)
        PGP-PRIVATE: $(pgp-private)
        PGP-PUBLIC: $(pgp-public)
        PGP-PW: $(pgp-pw)

- job: DatabricksE2E
  timeoutInMinutes: 120
  cancelTimeoutInMinutes: 0
  pool:
    vmImage: ubuntu-18.04
  steps:
    #- template: templates/ivy_cache.yml
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - bash: |
        set -e
        source activate synapseml
        sbt packagePython
        sbt publishBlob
      displayName: Publish Blob Artifacts
      env:
        STORAGE-KEY: $(storage-key)
        NEXUS-UN: $(nexus-un)
        NEXUS-PW: $(nexus-pw)
        PGP-PRIVATE: $(pgp-private)
        PGP-PUBLIC: $(pgp-public)
        PGP-PW: $(pgp-pw)
    - task: AzureCLI@1
      displayName: 'E2E'
      inputs:
        azureSubscription:  'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: 'sbt "testOnly com.microsoft.azure.synapse.ml.nbtest.DatabricksTests"'
      condition: and(succeeded(), eq(variables.runTests, 'True'))
    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: '**/test-reports/TEST-*.xml'
        failTaskOnFailedTests: true
      condition: and(eq(variables.runTests, 'True'), succeededOrFailed())

- job: SynapseE2E
  timeoutInMinutes: 120
  cancelTimeoutInMinutes: 0
  pool:
    vmImage: ubuntu-18.04
  steps:
    # - template: templates/ivy_cache.yml
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - bash: |
        set -e
        source activate synapseml
        sbt packagePython
        sbt publishBlob
      displayName: Publish Blob Artifacts
      env:
        STORAGE-KEY: $(storage-key)
        NEXUS-UN: $(nexus-un)
        NEXUS-PW: $(nexus-pw)
        PGP-PRIVATE: $(pgp-private)
        PGP-PUBLIC: $(pgp-public)
        PGP-PW: $(pgp-pw)
    - task: AzureCLI@1
      displayName: 'E2E'
      inputs:
        azureSubscription:  'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          source activate synapseml
          sbt "testOnly com.microsoft.azure.synapse.ml.nbtest.SynapseTests"
      condition: and(succeeded(), eq(variables.runTests, 'True'))
    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: '**/test-reports/TEST-*.xml'
        failTaskOnFailedTests: true
      condition: and(eq(variables.runTests, 'True'), succeededOrFailed())

- job: PublishDocker
  displayName: PublishDocker
  pool:
    vmImage: ubuntu-18.04
  steps:
    - task: AzureCLI@1
      displayName: 'Get Docker Tag + Version'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          VERSION=$(sbt "core/version" | tail -1 |  cut -d' ' -f2 | sed 's/\x1b\[[0-9;]*m//g')
          echo '##vso[task.setvariable variable=version]'$VERSION
          echo '##vso[task.setvariable variable=gittag]'$(git tag -l --points-at HEAD)
    - task: Docker@2
      displayName: Demo Image Build
      inputs:
        containerRegistry: 'mmlspark-mcr-connection-1'
        repository: 'public/mmlspark/build-demo'
        command: 'build'
        buildContext: "."
        Dockerfile: 'tools/docker/demo/Dockerfile'
        tags: $(version)
        arguments: --build-arg SYNAPSEML_VERSION=$(version)
    - task: Docker@2
      displayName: Demo Image Push
      inputs:
        containerRegistry: 'mmlspark-mcr-connection-1'
        repository: 'public/mmlspark/build-demo'
        command: 'push'
        tags: $(version)
    - task: Docker@2
      displayName: Minimal Image Build
      inputs:
        containerRegistry: 'mmlspark-mcr-connection-1'
        repository: 'public/mmlspark/build-minimal'
        command: 'build'
        buildContext: "."
        Dockerfile: 'tools/docker/minimal/Dockerfile'
        tags: $(version)
        arguments: --build-arg SYNAPSEML_VERSION=$(version)
    - task: Docker@2
      displayName: Minimal Image Push
      inputs:
        containerRegistry: 'mmlspark-mcr-connection-1'
        repository: 'public/mmlspark/build-minimal'
        command: 'push'
        tags: $(version)
    - task: Docker@2
      condition: startsWith(variables['gittag'], 'v')
      displayName: Release Image Build
      inputs:
        containerRegistry: 'mmlspark-mcr-connection-1'
        repository: 'public/mmlspark/release'
        command: 'build'
        buildContext: "."
        Dockerfile: 'tools/docker/demo/Dockerfile'
        tags: |
          $(version)
          latest
        arguments: --build-arg SYNAPSEML_VERSION=$(version)
    - task: Docker@2
      condition: startsWith(variables['gittag'], 'v')
      displayName: Release Image Push
      inputs:
        containerRegistry: 'mmlspark-mcr-connection-1'
        repository: 'public/mmlspark/release'
        command: 'push'
        tags: |
          $(version)
          latest
    - task: ComponentGovernanceComponentDetection@0

- job: Release
  cancelTimeoutInMinutes: 0
  pool:
    vmImage: ubuntu-18.04
  steps:
    - template: templates/update_cli.yml
    - bash: |
        echo '##vso[task.setvariable variable=tag]'$(git tag -l --points-at HEAD)
      displayName: 'Get Git Tag'
    - bash: |
        set -e
        wget https://github.com/git-chglog/git-chglog/releases/download/0.8.0/git-chglog_linux_amd64
        chmod +x git-chglog_linux_amd64
        ./git-chglog_linux_amd64 -o CHANGELOG.md $TAG
      condition: startsWith(variables['tag'], 'v')
    - task: GitHubRelease@0
      condition: startsWith(variables['tag'], 'v')
      inputs:
        gitHubConnection: 'MMLSpark Github'
        repositoryName: '$(Build.Repository.Name)'
        action: 'create'
        target: '$(Build.SourceVersion)'
        tagSource: 'auto'
        releaseNotesFile: 'CHANGELOG.md'
        isDraft: true
    - bash: echo "##vso[task.prependpath]$CONDA/bin"
      condition: startsWith(variables['tag'], 'v')
      displayName: Add conda to PATH
    - bash: sudo chown -R $(whoami):$(id -ng) $(CONDA_CACHE_DIR)
      displayName: Fix directory permissions
      condition: startsWith(variables['tag'], 'v')
    - task: Cache@2
      displayName: Use cached Anaconda environment
      condition: startsWith(variables['tag'], 'v')
      inputs:
        key: 'conda | "$(Agent.OS)" | environment.yml'
        restoreKeys: |
          python | "$(Agent.OS)"
          python
        path: $(CONDA_CACHE_DIR)
        cacheHitVar: CONDA_CACHE_RESTORED
    - bash: |
        conda env create -f environment.yml -v -v -v
      condition: and(startsWith(variables['tag'], 'v'), eq(variables.CONDA_CACHE_RESTORED, 'false'))
      displayName: Create Anaconda environment
    - task: AzureKeyVault@1
      condition: startsWith(variables['tag'], 'v')
      inputs:
        azureSubscription: 'MMLSpark Build'
        keyVaultName: mmlspark-keys
    - bash: |
        set -e
        source activate synapseml
        sbt publishPypi
      condition: startsWith(variables['tag'], 'v')
      env:
        STORAGE-KEY: $(storage-key)
        NEXUS-UN: $(nexus-un)
        NEXUS-PW: $(nexus-pw)
        PGP-PRIVATE: $(pgp-private)
        PGP-PUBLIC: $(pgp-public)
        PGP-PW: $(pgp-pw)
        PYPI-API-TOKEN: $(pypi-api-token)
      displayName: 'publish python package to pypi'
    - bash: |
        set -e
        source activate synapseml
        sbt publishSigned
        sbt sonatypeBundleRelease
      condition: startsWith(variables['tag'], 'v')
      env:
        STORAGE-KEY: $(storage-key)
        NEXUS-UN: $(nexus-un)
        NEXUS-PW: $(nexus-pw)
        PGP-PRIVATE: $(pgp-private)
        PGP-PUBLIC: $(pgp-public)
        PGP-PW: $(pgp-pw)
      displayName: 'publish jar package to maven central'

- job: PythonTests
  timeoutInMinutes: 120
  cancelTimeoutInMinutes: 0
  condition: eq(variables.runTests, 'True')
  pool:
    vmImage: ubuntu-18.04
  strategy:
    matrix:
      core:
        PACKAGE: "core"
      deep-learning:
        PACKAGE: "deepLearning"
      lightgbm:
        PACKAGE: "lightgbm"
      opencv:
        PACKAGE: "opencv"
      vw:
        PACKAGE: "vw"
      cognitive:
        PACKAGE: "cognitive"
  steps:
    #- template: templates/ivy_cache.yml
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - task: AzureCLI@1
      displayName: 'Install Pip Package'
      timeoutInMinutes: 10
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          source activate synapseml
          (timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup)
          sbt installPipPackage
    - task: AzureCLI@1
      displayName: 'Test Python Code'
      timeoutInMinutes: 40
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          source activate synapseml
          (sbt "project $(PACKAGE)" coverage testPython) || (sbt "project $(PACKAGE)" coverage testPython) || (sbt "project $(PACKAGE)" coverage testPython)
    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: '**/python-test-*.xml'
        failTaskOnFailedTests: true
      condition: succeededOrFailed()
    - task: AzureCLI@1
      displayName: 'Generate Codecov report'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: 'sbt coverageReport'
      condition: succeededOrFailed()
    - template: templates/codecov.yml



- job: RTests
  cancelTimeoutInMinutes: 0
  condition: eq(variables.runTests, 'True')
  pool:
    vmImage: ubuntu-18.04
  steps:
    #- template: templates/ivy_cache_2.yml
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - bash: curl https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz -o spark-3.2.0-bin-hadoop3.2.tgz
      displayName: Download spark
    - task: AzureCLI@1
      displayName: 'Test R Code'
      timeoutInMinutes: 30
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          source activate synapseml
          (timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup)
          (sbt coverage testR) || (echo "retrying" && sbt coverage testR) || (echo "retrying" && sbt coverage testR)
    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: '**/r-test-*.xml'
        failTaskOnFailedTests: true
      condition: succeededOrFailed()
    - task: AzureCLI@1
      displayName: 'Generate Codecov report'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: 'sbt coverageReport'
      condition: succeededOrFailed()
    - template: templates/codecov.yml


- job: WebsiteSamplesTests
  cancelTimeoutInMinutes: 0
  condition: eq(variables.runTests, 'True')
  pool:
    vmImage: ubuntu-18.04
  steps:
    #- template: templates/ivy_cache.yml
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - task: AzureCLI@1
      displayName: 'Test Website Samples'
      timeoutInMinutes: 30
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          set -e
          source activate synapseml
          sbt packagePython
          sbt publishBlob
          (timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup)
          (sbt coverage testWebsiteDocs)
    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: '**/website-test-result.xml'
        failTaskOnFailedTests: true
      condition: succeededOrFailed()
    - task: AzureCLI@1
      displayName: 'Generate Codecov report'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: 'sbt coverageReport'
      condition: succeededOrFailed()
    - template: templates/codecov.yml



- job: WebsiteAutoDeployment
  cancelTimeoutInMinutes: 0
  pool:
    vmImage: ubuntu-18.04
  steps:
    - checkout: self
      persistCredentials: true
    - template: templates/update_cli.yml
    - template: templates/conda.yml
    - template: templates/kv.yml
    - task: NodeTool@0
      inputs:
        versionSpec: '16.x'
      displayName: 'Install Node.js'
    - task: AzureCLI@1
      displayName: 'Convert notebooks to markdowns'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          source activate synapseml
          sbt convertNotebooks
    - bash: |
        set -e
        yarn install
        cd website
        yarn
        yarn build
      displayName: 'yarn install and build'
    - bash: |
        set -e
        git config --global user.name "${GH_NAME}"
        git config --global user.email "${GH_EMAIL}"
        git checkout -b main
        echo "machine github.com login ${GH_NAME} password ${GH_TOKEN}" > ~/.netrc
        cd website
        GIT_USER="${GH_NAME}" yarn deploy
      condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))
      env:
        GH_NAME: $(gh-name)
        GH_EMAIL: $(gh-email)
        GH_TOKEN: $(gh-token)
      displayName: 'yarn deploy'


- job: UnitTests
  cancelTimeoutInMinutes: 1
  timeoutInMinutes: 80
  condition: eq(variables.runTests, 'True')
  pool:
    vmImage: ubuntu-18.04
  strategy:
    matrix:
      automl:
        PACKAGE: "automl"
      cntk:
        PACKAGE: "cntk"
      geospatial:
        PACKAGE: "geospatial"
      onnx:
        PACKAGE: "onnx"
      cognitive1:
        PACKAGE: "cognitive.split1"
        FLAKY: "true"
      cognitive2:
        PACKAGE: "cognitive.split2"
        FFMPEG: "true"
        FLAKY: "true"
      cognitive3:
        PACKAGE: "cognitive.split3"
        FFMPEG: "true"
        FLAKY: "true"
      cognitive4:
        PACKAGE: "cognitive.split4"
        FLAKY: "true"
      core:
        PACKAGE: "core"
      downloader:
        PACKAGE: "downloader"
      explainers1:
        PACKAGE: "explainers.split1"
      explainers2:
        PACKAGE: "explainers.split2"
      explainers3:
        PACKAGE: "explainers.split3"
      exploratory:
        PACKAGE: "exploratory"
      featurize:
        PACKAGE: "featurize"
      image:
        PACKAGE: "image"
      io1:
        PACKAGE: "io.split1"
        FLAKY: "true"
      io2:
        PACKAGE: "io.split2"
        FLAKY: "true"
      isolationforest:
        PACKAGE: "isolationforest"
      flaky:
        PACKAGE: "flaky"           #TODO fix flaky test so isolation is not needed
        FLAKY: "true"
      lightgbm1:
        PACKAGE: "lightgbm.split1" #TODO speed up LGBM Tests and remove split
        FLAKY: "true"
      lightgbm2:
        PACKAGE: "lightgbm.split2"
        FLAKY: "true"
      lime:
        PACKAGE: "lime"
      opencv:
        PACKAGE: "opencv"
      recommendation:
        PACKAGE: "recommendation"
      stages:
        PACKAGE: "stages"
      nn:
        PACKAGE: "nn"
      train:
        PACKAGE: "train"
      vw:
        PACKAGE: "vw"
  steps:
    #- template: templates/ivy_cache.yml
    - task: AzureCLI@1
      displayName: 'Setup repo'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          (timeout 30s pip install requests) || (echo "retrying" && timeout 30s pip install requests)
          (timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup) || (echo "retrying" && timeout 5m sbt setup)
    - task: AzureCLI@1
      displayName: 'Unit Test'
      timeoutInMinutes: 90
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: |
          (${FFMPEG:-false} && sudo add-apt-repository ppa:jonathonf/ffmpeg-4 -y && \
          sudo apt-get update && sudo apt-get install ffmpeg libgstreamer1.0-0 \
          gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly -y)
          export SBT_OPTS="-Xmx2G -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=2G -Xss2M  -Duser.timezone=GMT"
          (timeout 30m sbt coverage "testOnly com.microsoft.azure.synapse.ml.$(PACKAGE).**") ||
          (${FLAKY:-false} && timeout 30m sbt coverage "testOnly com.microsoft.azure.synapse.ml.$(PACKAGE).**") ||
          (${FLAKY:-false} && timeout 30m sbt coverage "testOnly com.microsoft.azure.synapse.ml.$(PACKAGE).**")

    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: '**/test-reports/TEST-*.xml'
        failTaskOnFailedTests: true
      condition: succeededOrFailed()
    - task: AzureCLI@1
      displayName: 'Generate Codecov report'
      inputs:
        azureSubscription: 'MMLSpark Build'
        scriptLocation: inlineScript
        inlineScript: 'sbt coverageReport'
      condition: succeededOrFailed()
    - template: templates/kv.yml
    - template: templates/codecov.yml

