(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[2010],{3905:function(e,a,t){"use strict";t.d(a,{Zo:function(){return i},kt:function(){return d}});var s=t(7294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);a&&(s=s.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,s)}return t}function r(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?l(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,s,n=function(e,a){if(null==e)return{};var t,s,n={},l=Object.keys(e);for(s=0;s<l.length;s++)t=l[s],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(s=0;s<l.length;s++)t=l[s],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var m=s.createContext({}),p=function(e){var a=s.useContext(m),t=a;return e&&(t="function"==typeof e?e(a):r(r({},a),e)),t},i=function(e){var a=p(e.components);return s.createElement(m.Provider,{value:a},e.children)},u={inlineCode:"code",wrapper:function(e){var a=e.children;return s.createElement(s.Fragment,{},a)}},c=s.forwardRef((function(e,a){var t=e.components,n=e.mdxType,l=e.originalType,m=e.parentName,i=o(e,["components","mdxType","originalType","parentName"]),c=p(t),d=n,y=c["".concat(m,".").concat(d)]||c[d]||u[d]||l;return t?s.createElement(y,r(r({ref:a},i),{},{components:t})):s.createElement(y,r({ref:a},i))}));function d(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var l=t.length,r=new Array(l);r[0]=c;var o={};for(var m in a)hasOwnProperty.call(a,m)&&(o[m]=a[m]);o.originalType=e,o.mdxType="string"==typeof e?e:n,r[1]=o;for(var p=2;p<l;p++)r[p]=t[p];return s.createElement.apply(null,r)}return s.createElement.apply(null,t)}c.displayName="MDXCreateElement"},1332:function(e,a,t){"use strict";var s=t(7294);a.Z=function(e){var a=e.children,t=e.hidden,n=e.className;return s.createElement("div",{role:"tabpanel",hidden:t,className:n},a)}},5386:function(e,a,t){"use strict";t.d(a,{Z:function(){return c}});var s=t(4034),n=t(7294),l=t(2389),r=t(8578);var o=function(){var e=(0,n.useContext)(r.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},m=t(9558),p=t(6010),i="tabItem_2kG2";function u(e){var a,t,s,l=e.lazy,r=e.block,u=e.defaultValue,c=e.values,d=e.groupId,y=e.className,b=n.Children.map(e.children,(function(e){if((0,n.isValidElement)(e)&&"string"==typeof e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),f=null!=c?c:b.map((function(e){var a=e.props;return{value:a.value,label:a.label}})),g=(0,m.lx)(f,(function(e,a){return e.value===a.value}));if(g.length>0)throw new Error('Docusaurus error: Duplicate values "'+g.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var k=null===u?u:null!=(a=null!=u?u:null==(t=b.find((function(e){return e.props.default})))?void 0:t.props.value)?a:null==(s=b[0])?void 0:s.props.value;if(null!==k&&!f.some((function(e){return e.value===k})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+k+'" but none of its children has the corresponding value. Available values are: '+f.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var h=o(),T=h.tabGroupChoices,v=h.setTabGroupChoices,x=(0,n.useState)(k),S=x[0],C=x[1],N=[],I=(0,m.o5)().blockElementScrollPositionUntilNextRender;if(null!=d){var D=T[d];null!=D&&D!==S&&f.some((function(e){return e.value===D}))&&C(D)}var z=function(e){var a=e.currentTarget,t=N.indexOf(a),s=f[t].value;s!==S&&(I(a),C(s),null!=d&&v(d,s))},w=function(e){var a,t=null;switch(e.key){case"ArrowRight":var s=N.indexOf(e.currentTarget)+1;t=N[s]||N[0];break;case"ArrowLeft":var n=N.indexOf(e.currentTarget)-1;t=N[n]||N[N.length-1]}null==(a=t)||a.focus()};return n.createElement("div",{className:"tabs-container"},n.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,p.Z)("tabs",{"tabs--block":r},y)},f.map((function(e){var a=e.value,t=e.label;return n.createElement("li",{role:"tab",tabIndex:S===a?0:-1,"aria-selected":S===a,className:(0,p.Z)("tabs__item",i,{"tabs__item--active":S===a}),key:a,ref:function(e){return N.push(e)},onKeyDown:w,onFocus:z,onClick:z},null!=t?t:a)}))),l?(0,n.cloneElement)(b.filter((function(e){return e.props.value===S}))[0],{className:"margin-vert--md"}):n.createElement("div",{className:"margin-vert--md"},b.map((function(e,a){return(0,n.cloneElement)(e,{key:a,hidden:e.props.value!==S})}))))}function c(e){var a=(0,l.Z)();return n.createElement(u,(0,s.Z)({key:String(a)},e))}},8578:function(e,a,t){"use strict";var s=(0,t(7294).createContext)(void 0);a.Z=s},1989:function(e,a,t){"use strict";var s=t(7294),n=t(2263);a.Z=function(e){var a=e.className,t=e.py,l=e.scala,r=e.sourceLink,o=(0,n.Z)().siteConfig.customFields.version,m="https://mmlspark.blob.core.windows.net/docs/"+o+"/pyspark/"+t,p="https://mmlspark.blob.core.windows.net/docs/"+o+"/scala/"+l;return s.createElement("table",null,s.createElement("tbody",null,s.createElement("tr",null,s.createElement("td",null,s.createElement("strong",null,"Python API: "),s.createElement("a",{href:m},a)),s.createElement("td",null,s.createElement("strong",null,"Scala API: "),s.createElement("a",{href:p},a)),s.createElement("td",null,s.createElement("strong",null,"Source: "),s.createElement("a",{href:r},a)))))}},1062:function(e,a,t){"use strict";t.r(a),t.d(a,{contentTitle:function(){return V},default:function(){return H},frontMatter:function(){return R},metadata:function(){return B},toc:function(){return j}});var s=t(4034),n=t(9973),l=(t(7294),t(3905)),r=t(5386),o=t(1332),m=t(1989),p=["components"],i=[{value:"Explainers",id:"explainers",children:[{value:"ImageLIME",id:"imagelime",children:[],level:3},{value:"ImageSHAP",id:"imageshap",children:[],level:3},{value:"TabularLIME",id:"tabularlime",children:[],level:3},{value:"TabularSHAP",id:"tabularshap",children:[],level:3},{value:"TextLIME",id:"textlime",children:[],level:3},{value:"TextSHAP",id:"textshap",children:[],level:3},{value:"VectorLIME",id:"vectorlime",children:[],level:3},{value:"VectorSHAP",id:"vectorshap",children:[],level:3}],level:2}],u={toc:i};function c(e){var a=e.components,t=(0,n.Z)(e,p);return(0,l.kt)("wrapper",(0,s.Z)({},u,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"explainers"},"Explainers"),(0,l.kt)("h3",{id:"imagelime"},"ImageLIME"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nlime = (ImageLIME()\n    .setModel(model)\n    .setOutputCol("weights")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n    .setSamplingFraction(0.7))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval lime = (new ImageLIME()\n    .setModel(model)\n    .setOutputCol("weights")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n    .setSamplingFraction(0.7))\n')))),(0,l.kt)(m.Z,{className:"ImageLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.ImageLIME",scala:"com/microsoft/azure/synapse/ml/explainers/ImageLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/ImageLIME.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"imageshap"},"ImageSHAP"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nshap = (\n    ImageSHAP()\n    .setModel(model)\n    .setOutputCol("shaps")\n    .setSuperpixelCol("superpixels")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n)\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval shap = (new ImageSHAP()\n    .setModel(model)\n    .setOutputCol("shaps")\n    .setSuperpixelCol("superpixels")\n    .setInputCol("image")\n    .setCellSize(150.0)\n    .setModifier(50.0)\n    .setNumSamples(500)\n    .setTargetCol("probability")\n    .setTargetClassesCol("top2pred")\n))\n')))),(0,l.kt)(m.Z,{className:"ImageSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.ImageSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/ImageSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/ImageSHAP.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"tabularlime"},"TabularLIME"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\ndata = spark.createDataFrame([\n    (-6.0, 0),\n    (-5.0, 0),\n    (5.0, 1),\n    (6.0, 1)\n], ["col1", "label"])\n\nlime = (TabularLIME()\n    .setModel(model)\n    .setInputCols(["col1"])\n    .setOutputCol("weights")\n    .setBackgroundData(data)\n    .setKernelWidth(0.001)\n    .setNumSamples(1000)\n    .setTargetCol("probability")\n    .setTargetClasses([0, 1]))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\nval data = Seq(\n  (-6.0, 0),\n  (-5.0, 0),\n  (5.0, 1),\n  (6.0, 1)\n).toDF("col1", "label")\n\nval lime = (new TabularLIME()\n    .setInputCols(Array("col1"))\n    .setOutputCol("weights")\n    .setBackgroundData(data)\n    .setKernelWidth(0.001)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses(Array(0, 1)))\n')))),(0,l.kt)(m.Z,{className:"TabularLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TabularLIME",scala:"com/microsoft/azure/synapse/ml/explainers/TabularLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TabularLIME.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"tabularshap"},"TabularSHAP"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\ndata = spark.createDataFrame([\n    (-5.0, "a", -5.0, 0),\n    (-5.0, "b", -5.0, 0),\n    (5.0, "a", 5.0, 1),\n    (5.0, "b", 5.0, 1)\n]*100, ["col1", "label"])\n\nshap = (TabularSHAP()\n    .setInputCols(["col1", "col2", "col3"])\n    .setOutputCol("shapValues")\n    .setBackgroundData(data)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses([1]))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\nval data = (1 to 100).flatMap(_ => Seq(\n    (-5d, "a", -5d, 0),\n    (-5d, "b", -5d, 0),\n    (5d, "a", 5d, 1),\n    (5d, "b", 5d, 1)\n  )).toDF("col1", "col2", "col3", "label")\n\nval shap = (new TabularSHAP()\n    .setInputCols(Array("col1", "col2", "col3"))\n    .setOutputCol("shapValues")\n    .setBackgroundData(data)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses(Array(1)))\n')))),(0,l.kt)(m.Z,{className:"TabularSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TabularSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/TabularSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TabularSHAP.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"textlime"},"TextLIME"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nlime = (TextLIME()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses([1])\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setSamplingFraction(0.7)\n    .setNumSamples(1000))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval lime = (new TextLIME()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses(Array(1))\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setSamplingFraction(0.7)\n    .setNumSamples(1000))\n')))),(0,l.kt)(m.Z,{className:"TextLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TextLIME",scala:"com/microsoft/azure/synapse/ml/explainers/TextLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TextLIME.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"textshap"},"TextSHAP"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nshap = (TextSHAP()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses([1])\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setNumSamples(1000))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport com.microsoft.azure.synapse.ml.onnx._\nimport spark.implicits._\n\nval model = (new ONNXModel())\n\nval shap = (new TextSHAP()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses(Array(1))\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setNumSamples(1000))\n')))),(0,l.kt)(m.Z,{className:"TextSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.TextSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/TextSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/TextSHAP.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"vectorlime"},"VectorLIME"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\ndf = spark.createDataframe([\n  ([0.2729799734928408, -0.4637273304253777, 1.565593782147994], 4.541185129673482),\n  ([1.9511879801376864, 1.495644437589599, -0.4667847796501322], 0.19526424470709836)\n])\n\nlime = (VectorLIME()\n    .setModel(model)\n    .setBackgroundData(df)\n    .setInputCol("features")\n    .setTargetCol("label")\n    .setOutputCol("weights")\n    .setNumSamples(1000))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport spark.implicits._\nimport breeze.linalg.{*, DenseMatrix => BDM}\nimport breeze.stats.distributions.Rand\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.regression.LinearRegression\n\nval d1 = 3\nval d2 = 1\nval coefficients: BDM[Double] = new BDM(d1, d2, Array(1.0, -1.0, 2.0))\n\nval df = {\n    val nRows = 100\n    val intercept: Double = math.random()\n\n    val x: BDM[Double] = BDM.rand(nRows, d1, Rand.gaussian)\n    val y = x * coefficients + intercept\n\n    val xRows = x(*, ::).iterator.toSeq.map(dv => Vectors.dense(dv.toArray))\n    val yRows = y(*, ::).iterator.toSeq.map(dv => dv(0))\n    xRows.zip(yRows).toDF("features", "label")\n  }\n\nval model: LinearRegressionModel = new LinearRegression().fit(df)\n\nval lime = (new VectorLIME()\n    .setModel(model)\n    .setBackgroundData(df)\n    .setInputCol("features")\n    .setTargetCol(model.getPredictionCol)\n    .setOutputCol("weights")\n    .setNumSamples(1000))\n')))),(0,l.kt)(m.Z,{className:"VectorLIME",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.VectorLIME",scala:"com/microsoft/azure/synapse/ml/explainers/VectorLIME.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/VectorLIME.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"vectorshap"},"VectorSHAP"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.explainers import *\nfrom synapse.ml.onnx import ONNXModel\n\nmodel = ONNXModel()\n\nshap = (VectorSHAP()\n    .setModel(model)\n    .setInputCol("text")\n    .setTargetCol("prob")\n    .setTargetClasses([1])\n    .setOutputCol("weights")\n    .setTokensCol("tokens")\n    .setNumSamples(1000))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.explainers._\nimport spark.implicits._\nimport breeze.linalg.{*, DenseMatrix => BDM}\nimport breeze.stats.distributions.RandBasis\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.Vectors\n\nval randBasis = RandBasis.withSeed(123)\nval m: BDM[Double] = BDM.rand[Double](1000, 5, randBasis.gaussian)\nval l: BDV[Double] = m(*, ::).map {\n    row =>\n      if (row(2) + row(3) > 0.5) 1d else 0d\n  }\nval data = m(*, ::).iterator.zip(l.valuesIterator).map {\n    case (f, l) => (f.toSpark, l)\n  }.toSeq.toDF("features", "label")\n\nval model = new LogisticRegression()\n    .setFeaturesCol("features")\n    .setLabelCol("label")\n    .fit(data)\n\nval shap = (new VectorSHAP()\n    .setInputCol("features")\n    .setOutputCol("shapValues")\n    .setBackgroundData(data)\n    .setNumSamples(1000)\n    .setModel(model)\n    .setTargetCol("probability")\n    .setTargetClasses(Array(1))\n\nval infer = Seq(\n    Tuple1(Vectors.dense(1d, 1d, 1d, 1d, 1d))\n  ) toDF "features"\nval predicted = model.transform(infer)\ndisplay(shap.transform(predicted))\n')))),(0,l.kt)(m.Z,{className:"VectorSHAP",py:"synapse.ml.explainers.html#module-synapse.ml.explainers.VectorSHAP",scala:"com/microsoft/azure/synapse/ml/explainers/VectorSHAP.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/explainers/VectorSHAP.scala",mdxType:"DocTable"}))}c.isMDXComponent=!0;var d=["components"],y=[{value:"Featurize",id:"featurize",children:[{value:"DataConversion",id:"dataconversion",children:[],level:3},{value:"IndexToValue",id:"indextovalue",children:[],level:3}],level:2},{value:"Featurize Text",id:"featurize-text",children:[{value:"MultiNGram",id:"multingram",children:[],level:3},{value:"PageSplitter",id:"pagesplitter",children:[],level:3}],level:2}],b={toc:y};function f(e){var a=e.components,t=(0,n.Z)(e,d);return(0,l.kt)("wrapper",(0,s.Z)({},b,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"featurize"},"Featurize"),(0,l.kt)("h3",{id:"dataconversion"},"DataConversion"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndf = spark.createDataFrame([\n    (True, 1, 2, 3, 4, 5.0, 6.0, "7", "8.0"),\n    (False, 9, 10, 11, 12, 14.5, 15.5, "16", "17.456"),\n    (True, -127, 345, 666, 1234, 18.91, 20.21, "100", "200.12345")\n], ["bool", "byte", "short", "int", "long", "float", "double", "intstring", "doublestring"])\n\ndc = (DataConversion()\n        .setCols(["byte"])\n        .setConvertTo("boolean"))\n\ndisplay(dc.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport spark.implicits._\n\nval df = Seq(\n    (true: Boolean, 1: Byte, 2: Short, 3: Integer, 4: Long, 5.0F, 6.0, "7", "8.0"),\n    (false, 9: Byte, 10: Short, 11: Integer, 12: Long, 14.5F, 15.5, "16", "17.456"),\n    (true, -127: Byte, 345: Short, Short.MaxValue + 100, (Int.MaxValue).toLong + 100, 18.91F, 20.21, "100", "200.12345"))\n    .toDF("bool", "byte", "short", "int", "long", "float", "double", "intstring", "doublestring")\n\nval dc = (new DataConversion()\n        .setCols(Array("byte"))\n        .setConvertTo("boolean"))\n\ndisplay(dc.transform(df))\n')))),(0,l.kt)(m.Z,{className:"DataConversion",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.DataConversion",scala:"com/microsoft/azure/synapse/ml/featurize/DataConversion.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/DataConversion.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"indextovalue"},"IndexToValue"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndf = spark.createDataFrame([\n    (-3, 24, 0.32534, True, "piano"),\n    (1, 5, 5.67, False, "piano"),\n    (-3, 5, 0.32534, False, "guitar")\n], ["int", "long", "double", "bool", "string"])\n\ndf2 = ValueIndexer().setInputCol("string").setOutputCol("string_cat").fit(df).transform(df)\n\nitv = (IndexToValue()\n        .setInputCol("string_cat")\n        .setOutputCol("string_noncat"))\n\ndisplay(itv.transform(df2))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport spark.implicits._\n\nval df = Seq[(Int, Long, Double, Boolean, String)](\n    (-3, 24L, 0.32534, true, "piano"),\n    (1, 5L, 5.67, false, "piano"),\n    (-3, 5L, 0.32534, false, "guitar")).toDF("int", "long", "double", "bool", "string")\n\nval df2 = new ValueIndexer().setInputCol("string").setOutputCol("string_cat").fit(df).transform(df)\n\nval itv = (new IndexToValue()\n        .setInputCol("string_cat")\n        .setOutputCol("string_noncat"))\n\ndisplay(itv.transform(df2))\n')))),(0,l.kt)(m.Z,{className:"IndexToValue",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.IndexToValue",scala:"com/microsoft/azure/synapse/ml/featurize/IndexToValue.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/IndexToValue.scala",mdxType:"DocTable"}),(0,l.kt)("h2",{id:"featurize-text"},"Featurize Text"),(0,l.kt)("h3",{id:"multingram"},"MultiNGram"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize.text import *\nfrom pyspark.ml.feature import Tokenizer\n\ndfRaw = spark.createDataFrame([\n    (0, "Hi I"),\n    (1, "I wish for snow today"),\n    (2, "we Cant go to the park, because of the snow!"),\n    (3, ""),\n    (4, "1 2 3 4 5 6 7 8 9")\n], ["label", "sentence"])\n\ndfTok = (Tokenizer()\n    .setInputCol("sentence")\n    .setOutputCol("tokens")\n    .transform(dfRaw))\n\nmng = (MultiNGram()\n    .setLengths([1, 3, 4])\n    .setInputCol("tokens")\n    .setOutputCol("ngrams"))\n\ndisplay(mng.transform(dfTok))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize.text._\nimport org.apache.spark.ml.feature.Tokenizer\nimport spark.implicits._\n\nval dfRaw = (Seq(\n    (0, "Hi I"),\n    (1, "I wish for snow today"),\n    (2, "we Cant go to the park, because of the snow!"),\n    (3, ""),\n    (4, (1 to 10).map(_.toString).mkString(" ")))\n    .toDF("label", "sentence"))\n\nval dfTok = (new Tokenizer()\n    .setInputCol("sentence")\n    .setOutputCol("tokens")\n    .transform(dfRaw))\n\nval mng = (new MultiNGram()\n    .setLengths(Array(1, 3, 4))\n    .setInputCol("tokens")\n    .setOutputCol("ngrams"))\n\ndisplay(mng.transform(dfTok))\n')))),(0,l.kt)(m.Z,{className:"MultiNGram",py:"synapse.ml.featurize.text.html#module-synapse.ml.featurize.text.MultiNGram",scala:"com/microsoft/azure/synapse/ml/featurize/text/MultiNGram.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/text/MultiNGram.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"pagesplitter"},"PageSplitter"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize.text import *\n\ndf = spark.createDataFrame([\n    ("words words  words     wornssaa ehewjkdiw weijnsikjn xnh", ),\n    ("s s  s   s     s           s", ),\n    ("hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd", ),\n    ("hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd 190872340870271091309831097813097130i3u709781", ),\n    ("", ),\n    (None, )\n], ["text"])\n\nps = (PageSplitter()\n    .setInputCol("text")\n    .setMaximumPageLength(20)\n    .setMinimumPageLength(10)\n    .setOutputCol("pages"))\n\ndisplay(ps.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize.text._\nimport spark.implicits._\n\nval df = Seq(\n    "words words  words     wornssaa ehewjkdiw weijnsikjn xnh",\n    "s s  s   s     s           s",\n    "hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd",\n    "hsjbhjhnskjhndwjnbvckjbnwkjwenbvfkjhbnwevkjhbnwejhkbnvjkhnbndjkbnd " +\n      "190872340870271091309831097813097130i3u709781",\n    "",\n    null\n  ).toDF("text")\n\nval ps = (new PageSplitter()\n    .setInputCol("text")\n    .setMaximumPageLength(20)\n    .setMinimumPageLength(10)\n    .setOutputCol("pages"))\n\ndisplay(ps.transform(df))\n')))),(0,l.kt)(m.Z,{className:"PageSplitter",py:"synapse.ml.featurize.text.html#module-synapse.ml.featurize.text.PageSplitter",scala:"com/microsoft/azure/synapse/ml/featurize/text/PageSplitter.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/text/PageSplitter.scala",mdxType:"DocTable"}))}f.isMDXComponent=!0;var g=["components"],k=[{value:"Image",id:"image",children:[{value:"ResizeImageTransformer",id:"resizeimagetransformer",children:[],level:3},{value:"UnrollImage",id:"unrollimage",children:[],level:3},{value:"UnrollBinaryImage",id:"unrollbinaryimage",children:[],level:3}],level:2}],h={toc:k};function T(e){var a=e.components,t=(0,n.Z)(e,g);return(0,l.kt)("wrapper",(0,s.Z)({},h,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"image"},"Image"),(0,l.kt)("h3",{id:"resizeimagetransformer"},"ResizeImageTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.image import *\n\n# images = (spark.read.format("image")\n#         .option("dropInvalid", True)\n#         .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nrit = (ResizeImageTransformer()\n        .setOutputCol("out")\n        .setHeight(15)\n        .setWidth(10))\n\n# display(rit.transform(images))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.image._\nimport spark.implicits._\n\n// val images = (spark.read.format("image")\n//     .option("dropInvalid", true)\n//     .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nval rit = (new ResizeImageTransformer()\n    .setOutputCol("out")\n    .setHeight(15)\n    .setWidth(10))\n\n// display(rit.transform(images))\n')))),(0,l.kt)(m.Z,{className:"ResizeImageTransformer",py:"mmlspark.image.html#module-mmlspark.image.ResizeImageTransformer",scala:"com/microsoft/azure/synapse/ml/image/ResizeImageTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/image/ResizeImageTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"unrollimage"},"UnrollImage"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.image import *\nfrom azure.storage.blob import *\n\nimages = (spark.read.format("image")\n        .option("dropInvalid", True)\n        .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nrit = (ResizeImageTransformer()\n        .setOutputCol("out")\n        .setHeight(15)\n        .setWidth(10))\n\npreprocessed = rit.transform(images)\n\nunroll = (UnrollImage()\n      .setInputCol(rit.getOutputCol)\n      .setOutputCol("final"))\n\ndisplay(unroll.transform(preprocessed))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.image._\nimport spark.implicits._\n\nval images = (spark.read.format("image")\n    .option("dropInvalid", true)\n    .load("wasbs://datasets@mmlspark.blob.core.windows.net/LIME/greyscale.jpg"))\n\nval rit = (new ResizeImageTransformer()\n    .setOutputCol("out")\n    .setHeight(15)\n    .setWidth(10))\n\nval preprocessed = rit.transform(images)\n\nval unroll = (new UnrollImage()\n      .setInputCol(rit.getOutputCol)\n      .setOutputCol("final"))\n\ndisplay(unroll.transform(preprocessed))\n')))),(0,l.kt)(m.Z,{className:"UnrollImage",py:"mmlspark.image.html#module-mmlspark.image.UnrollImage",scala:"com/microsoft/azure/synapse/ml/image/UnrollImage.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/image/UnrollImage.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"unrollbinaryimage"},"UnrollBinaryImage"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.image import *\n\nunroll = (UnrollBinaryImage()\n      .setInputCol("input_col")\n      .setOutputCol("final"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.image._\nimport spark.implicits._\n\nval unroll = (new UnrollBinaryImage()\n        .setInputCol("input_col")\n        .setOutputCol("final"))\n\n')))),(0,l.kt)(m.Z,{className:"UnrollBinaryImage",py:"mmlspark.image.html#module-mmlspark.image.UnrollBinaryImage",scala:"com/microsoft/azure/synapse/ml/image/UnrollBinaryImage.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/image/UnrollBinaryImage.scala",mdxType:"DocTable"}))}T.isMDXComponent=!0;var v=["components"],x=[{value:"IO",id:"io",children:[{value:"HTTPTransformer",id:"httptransformer",children:[],level:3},{value:"SimpleHTTPTransformer",id:"simplehttptransformer",children:[],level:3},{value:"JSONInputParser",id:"jsoninputparser",children:[],level:3},{value:"JSONOutputParser",id:"jsonoutputparser",children:[],level:3},{value:"StringOutputParser",id:"stringoutputparser",children:[],level:3},{value:"CustomInputParser",id:"custominputparser",children:[],level:3},{value:"CustomOutputParser",id:"customoutputparser",children:[],level:3}],level:2}],S={toc:x};function C(e){var a=e.components,t=(0,n.Z)(e,v);return(0,l.kt)("wrapper",(0,s.Z)({},S,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"io"},"IO"),(0,l.kt)("h3",{id:"httptransformer"},"HTTPTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\nfrom pyspark.sql.functions import udf, col\nfrom requests import Request\n\ndef world_bank_request(country):\n    return Request("GET", "http://api.worldbank.org/v2/country/{}?format=json".format(country))\n\ndf = (spark.createDataFrame([("br",), ("usa",)], ["country"])\n      .withColumn("request", http_udf(world_bank_request)(col("country"))))\n\nht = (HTTPTransformer()\n      .setConcurrency(3)\n      .setInputCol("request")\n      .setOutputCol("response"))\n\ndisplay(ht.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval ht = (new HTTPTransformer()\n      .setConcurrency(3)\n      .setInputCol("request")\n      .setOutputCol("response"))\n')))),(0,l.kt)(m.Z,{className:"HTTPTransformer",py:"mmlspark.io.http.html#module-mmlspark.io.http.HTTPTransformer",scala:"com/microsoft/azure/synapse/ml/io/http/HTTPTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/HTTPTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"simplehttptransformer"},"SimpleHTTPTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\nfrom pyspark.sql.types import StringType, StructType\n\nsht = (SimpleHTTPTransformer()\n        .setInputCol("data")\n        .setOutputParser(JSONOutputParser()\n            .setDataType(StructType().add("blah", StringType)))\n        .setUrl("PUT_YOUR_URL")\n        .setOutputCol("results")\n        .setConcurrency(3))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\nimport org.apache.spark.sql.types.{StringType, StructType}\n\nval sht = (new SimpleHTTPTransformer()\n        .setInputCol("data")\n        .setOutputParser(new JSONOutputParser()\n            .setDataType(new StructType().add("blah", StringType)))\n        .setUrl("PUT_YOUR_URL")\n        .setOutputCol("results")\n        .setConcurrency(3))\n')))),(0,l.kt)(m.Z,{className:"SimpleHTTPTransformer",py:"mmlspark.io.http.html#module-mmlspark.io.http.SimpleHTTPTransformer",scala:"com/microsoft/azure/synapse/ml/io/http/SimpleHTTPTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/SimpleHTTPTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"jsoninputparser"},"JSONInputParser"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\njsonIP = (JSONInputParser()\n      .setInputCol("data")\n      .setOutputCol("out")\n      .setUrl("PUT_YOUR_URL"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval jsonIP = (new JSONInputParser()\n      .setInputCol("data")\n      .setOutputCol("out")\n      .setUrl("PUT_YOUR_URL"))\n')))),(0,l.kt)(m.Z,{className:"JSONInputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.JSONInputParser",scala:"com/microsoft/azure/synapse/ml/io/http/JSONInputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/JSONInputParser.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"jsonoutputparser"},"JSONOutputParser"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\nfrom pyspark.sql.types import StringType, StructType\n\njsonOP = (JSONOutputParser()\n      .setDataType(StructType().add("foo", StringType))\n      .setInputCol("unparsedOutput")\n      .setOutputCol("parsedOutput"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\nimport org.apache.spark.sql.types.{StringType, StructType}\n\nval jsonOP = (new JSONOutputParser()\n      .setDataType(new StructType().add("foo", StringType))\n      .setInputCol("unparsedOutput")\n      .setOutputCol("parsedOutput"))\n')))),(0,l.kt)(m.Z,{className:"JSONOutputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.JSONOutputParser",scala:"com/microsoft/azure/synapse/ml/io/http/JSONOutputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/JSONOutputParser.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"stringoutputparser"},"StringOutputParser"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\nsop = (StringOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval sop = (new StringOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n')))),(0,l.kt)(m.Z,{className:"StringOutputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.StringOutputParser",scala:"com/microsoft/azure/synapse/ml/io/http/StringOutputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/StringOutputParser.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"custominputparser"},"CustomInputParser"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\ncip = (CustomInputParser()\n      .setInputCol("data")\n      .setOutputCol("out"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval cip = (new CustomInputParser()\n      .setInputCol("data")\n      .setOutputCol("out")\n      .setUDF({ x: Int => new HttpPost(s"http://$x") }))\n')))),(0,l.kt)(m.Z,{className:"CustomInputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.CustomInputParser",scala:"com/microsoft/azure/synapse/ml/io/http/CustomInputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/CustomInputParser.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"customoutputparser"},"CustomOutputParser"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.io.http import *\n\ncop = (CustomOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.io.http._\n\nval cop = (new CustomOutputParser()\n      .setInputCol("unparsedOutput")\n      .setOutputCol("out"))\n')))),(0,l.kt)(m.Z,{className:"CustomOutputParser",py:"mmlspark.io.http.html#module-mmlspark.io.http.CustomOutputParser",scala:"com/microsoft/azure/synapse/ml/io/http/CustomOutputParser.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/io/http/CustomOutputParser.scala",mdxType:"DocTable"}))}C.isMDXComponent=!0;var N=["components"],I=[{value:"LIME",id:"lime",children:[{value:"SuperpixelTransformer",id:"superpixeltransformer",children:[],level:3}],level:2}],D={toc:I};function z(e){var a=e.components,t=(0,n.Z)(e,N);return(0,l.kt)("wrapper",(0,s.Z)({},D,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"lime"},"LIME"),(0,l.kt)("h3",{id:"superpixeltransformer"},"SuperpixelTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.lime import *\n\nspt = (SuperpixelTransformer()\n      .setInputCol("images"))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.lime._\n\nval spt = (new SuperpixelTransformer()\n      .setInputCol("images"))\n')))),(0,l.kt)(m.Z,{className:"SuperpixelTransformer",py:"mmlspark.lime.html#module-mmlspark.lime.SuperpixelTransformer",scala:"com/microsoft/azure/synapse/ml/lime/SuperpixelTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/lime/SuperpixelTransformer.scala",mdxType:"DocTable"}))}z.isMDXComponent=!0;var w=["components"],M=[{value:"Stages",id:"stages",children:[{value:"Cacher",id:"cacher",children:[],level:3},{value:"DropColumns",id:"dropcolumns",children:[],level:3},{value:"EnsembleByKey",id:"ensemblebykey",children:[],level:3},{value:"Explode",id:"explode",children:[],level:3},{value:"Lambda",id:"lambda",children:[],level:3},{value:"DynamicMiniBatchTransformer",id:"dynamicminibatchtransformer",children:[],level:3},{value:"FixedMiniBatchTransformer",id:"fixedminibatchtransformer",children:[],level:3},{value:"TimeIntervalMiniBatchTransformer",id:"timeintervalminibatchtransformer",children:[],level:3},{value:"FlattenBatch",id:"flattenbatch",children:[],level:3},{value:"RenameColumn",id:"renamecolumn",children:[],level:3},{value:"Repartition",id:"repartition",children:[],level:3},{value:"SelectColumns",id:"selectcolumns",children:[],level:3},{value:"StratifiedRepartition",id:"stratifiedrepartition",children:[],level:3},{value:"SummarizeData",id:"summarizedata",children:[],level:3},{value:"TextPreprocessor",id:"textpreprocessor",children:[],level:3},{value:"UDFTransformer",id:"udftransformer",children:[],level:3},{value:"UnicodeNormalize",id:"unicodenormalize",children:[],level:3}],level:2}],L={toc:M};function P(e){var a=e.components,t=(0,n.Z)(e,w);return(0,l.kt)("wrapper",(0,s.Z)({},L,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"stages"},"Stages"),(0,l.kt)("h3",{id:"cacher"},"Cacher"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, "guitars", "drums"),\n      (1, "piano", "trumpet"),\n      (2, "bass", "cymbals"),\n      (3, "guitars", "drums"),\n      (4, "piano", "trumpet"),\n      (5, "bass", "cymbals"),\n      (6, "guitars", "drums"),\n      (7, "piano", "trumpet"),\n      (8, "bass", "cymbals"),\n      (9, "guitars", "drums"),\n      (10, "piano", "trumpet"),\n      (11, "bass", "cymbals")\n      ], ["numbers", "words", "more"]))\n\ncacher = Cacher()\n\ndisplay(cacher.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = Seq(\n      (0, "guitars", "drums"),\n      (1, "piano", "trumpet"),\n      (2, "bass", "cymbals"),\n      (3, "guitars", "drums"),\n      (4, "piano", "trumpet"),\n      (5, "bass", "cymbals"),\n      (6, "guitars", "drums"),\n      (7, "piano", "trumpet"),\n      (8, "bass", "cymbals"),\n      (9, "guitars", "drums"),\n      (10, "piano", "trumpet"),\n      (11, "bass", "cymbals")\n    ).toDF("numbers", "words", "more")\n\nval cacher = new Cacher()\n\ndisplay(cacher.transform(df))\n')))),(0,l.kt)(m.Z,{className:"HTTPTransformer",py:"synapse.ml.stages.html#module-synapse.ml.stages.Cacher",scala:"com/microsoft/azure/synapse/ml/stages/Cacher.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Cacher.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"dropcolumns"},"DropColumns"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true)\n      ], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\ndc = DropColumns().setCols([])\n\ndisplay(dc.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval dc = new DropColumns().setCols(Array())\n\ndisplay(dc.transform(df))\n')))),(0,l.kt)(m.Z,{className:"DropColumns",py:"synapse.ml.stages.html#module-synapse.ml.stages.DropColumns",scala:"com/microsoft/azure/synapse/ml/stages/DropColumns.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/DropColumns.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"ensemblebykey"},"EnsembleByKey"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\nscoreDF = (spark.createDataFrame([\n      (0, "foo", 1.0, .1),\n      (1, "bar", 4.0, -2.0),\n      (1, "bar", 0.0, -3.0)\n      ], ["label1", "label2", "score1", "score2"]))\n\nva = VectorAssembler().setInputCols(["score1", "score2"]).setOutputCol("v1")\nscoreDF2 = va.transform(scoreDF)\n\nebk = EnsembleByKey().setKey("label1").setCol("score1")\n\ndisplay(ebk.transform(scoreDF2))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.ml.feature.VectorAssembler\n\nval scoreDF = (Seq(\n      (0, "foo", 1.0, .1),\n      (1, "bar", 4.0, -2.0),\n      (1, "bar", 0.0, -3.0))\n      .toDF("label1", "label2", "score1", "score2"))\n\nval va = new VectorAssembler().setInputCols(Array("score1", "score2")).setOutputCol("v1")\nval scoreDF2 = va.transform(scoreDF)\n\nval ebk = new EnsembleByKey().setKey("label1").setCol("score1")\n\ndisplay(ebk.transform(scoreDF2))\n')))),(0,l.kt)(m.Z,{className:"EnsembleByKey",py:"synapse.ml.stages.html#module-synapse.ml.stages.EnsembleByKey",scala:"com/microsoft/azure/synapse/ml/stages/EnsembleByKey.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/EnsembleByKey.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"explode"},"Explode"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, ["guitars", "drums"]),\n      (1, ["piano"]),\n      (2, [])\n      ], ["numbers", "words"]))\n\nexplode = Explode().setInputCol("words").setOutputCol("exploded")\n\ndisplay(explode.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    (0, Seq("guitars", "drums")),\n    (1, Seq("piano")),\n    (2, Seq()))\n    .toDF("numbers", "words"))\n\nval explode = new Explode().setInputCol("words").setOutputCol("exploded")\n\ndisplay(explode.transform(df))\n')))),(0,l.kt)(m.Z,{className:"Explode",py:"synapse.ml.stages.html#module-synapse.ml.stages.Explode",scala:"com/microsoft/azure/synapse/ml/stages/Explode.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Explode.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"lambda"},"Lambda"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.sql.types import StringType, StructType\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n      ], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nl = (Lambda()\n      .setTransform(lambda df : df.select("numbers"))\n      .setTransformSchema(lambda schema : StructType([schema("numbers")])))\n\ndisplay(l.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.sql.types.{StringType, StructType}\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval lambda = (new Lambda()\n      .setTransform(df => df.select("numbers"))\n      .setTransformSchema(schema => new StructType(Array(schema("numbers")))))\n\ndisplay(lambda.transform(df))\n')))),(0,l.kt)(m.Z,{className:"Lambda",py:"synapse.ml.stages.html#module-mmlspark.stages.Lambda",scala:"com/microsoft/azure/synapse/ml/stages/Lambda.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Lambda.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"dynamicminibatchtransformer"},"DynamicMiniBatchTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.sql.types import StringType, StructType\n\ndf = (spark.createDataFrame([(_, "foo") for _ in range(1, 11)], ["in1", "in2"]))\n\ndmbt = DynamicMiniBatchTransformer()\n\ndisplay(dmbt.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (1 until 11).map(x => (x, "foo")).toDF("in1", "in2")\n\nval dmbt = new DynamicMiniBatchTransformer()\n\ndisplay(dmbt.transform(df))\n')))),(0,l.kt)(m.Z,{className:"DynamicMiniBatchTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.DynamicMiniBatchTransformer",scala:"com/microsoft/azure/synapse/ml/stages/DynamicMiniBatchTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"fixedminibatchtransformer"},"FixedMiniBatchTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from synapse.ml.stages import *\n\nfmbt = (FixedMiniBatchTransformer()\n      .setBuffered(true)\n      .setBatchSize(3))\n"))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},"import com.microsoft.azure.synapse.ml.stages._\n\nval fmbt = (new FixedMiniBatchTransformer()\n      .setBuffered(true)\n      .setBatchSize(3))\n")))),(0,l.kt)(m.Z,{className:"FixedMiniBatchTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.FixedMiniBatchTransformer",scala:"com/microsoft/azure/synapse/ml/stages/FixedMiniBatchTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"timeintervalminibatchtransformer"},"TimeIntervalMiniBatchTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([(_, "foo") for _ in range(1, 11)], ["in1", "in2"]))\n\ntimbt = (TimeIntervalMiniBatchTransformer()\n        .setMillisToWait(1000)\n        .setMaxBatchSize(30))\n\ndisplay(timbt.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (1 until 11).map(x => (x, "foo")).toDF("in1", "in2")\n\nval timbt = (new TimeIntervalMiniBatchTransformer()\n        .setMillisToWait(1000)\n        .setMaxBatchSize(30))\n\ndisplay(timbt.transform(df))\n')))),(0,l.kt)(m.Z,{className:"TimeIntervalMiniBatchTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.TimeIntervalMiniBatchTransformer",scala:"com/microsoft/azure/synapse/ml/stages/TimeIntervalMiniBatchTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"flattenbatch"},"FlattenBatch"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([(_, "foo") for _ in range(1, 11)], ["in1", "in2"]))\n\ntransDF = DynamicMiniBatchTransformer().transform(df)\n\nfb = FlattenBatch()\n\ndisplay(fb.transform(transDF))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (1 until 11).map(x => (x, "foo")).toDF("in1", "in2")\n\nval transDF = new DynamicMiniBatchTransformer().transform(df)\n\nval fb = new FlattenBatch()\n\ndisplay(fb.transform(transDF))\n')))),(0,l.kt)(m.Z,{className:"FlattenBatch",py:"mmlspark.stages.html#module-mmlspark.stages.FlattenBatch",scala:"com/microsoft/azure/synapse/ml/stages/FlattenBatch.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MiniBatchTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"renamecolumn"},"RenameColumn"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true)\n], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nrc = RenameColumn().setInputCol("words").setOutputCol("numbers")\n\ndisplay(rc.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval rc = new RenameColumn().setInputCol("words").setOutputCol("numbers")\n\ndisplay(rc.transform(df))\n')))),(0,l.kt)(m.Z,{className:"RenameColumn",py:"mmlspark.stages.html#module-mmlspark.stages.RenameColumn",scala:"com/microsoft/azure/synapse/ml/stages/RenameColumn.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/RenameColumn.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"repartition"},"Repartition"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, "guitars", "drums"),\n      (1, "piano", "trumpet"),\n      (2, "bass", "cymbals"),\n      (3, "guitars", "drums"),\n      (4, "piano", "trumpet"),\n      (5, "bass", "cymbals"),\n      (6, "guitars", "drums"),\n      (7, "piano", "trumpet"),\n      (8, "bass", "cymbals"),\n      (9, "guitars", "drums"),\n      (10, "piano", "trumpet"),\n      (11, "bass", "cymbals")\n], ["numbers", "words", "more"]))\n\nrepartition = Repartition().setN(1)\n\ndisplay(repartition.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    (0, "guitars", "drums"),\n    (1, "piano", "trumpet"),\n    (2, "bass", "cymbals"),\n    (3, "guitars", "drums"),\n    (4, "piano", "trumpet"),\n    (5, "bass", "cymbals"),\n    (6, "guitars", "drums"),\n    (7, "piano", "trumpet"),\n    (8, "bass", "cymbals"),\n    (9, "guitars", "drums"),\n    (10, "piano", "trumpet"),\n    (11, "bass", "cymbals")\n  ).toDF("numbers", "words", "more"))\n\nval repartition = new Repartition().setN(1)\n\ndisplay(repartition.transform(df))\n')))),(0,l.kt)(m.Z,{className:"Repartition",py:"mmlspark.stages.html#module-mmlspark.stages.Repartition",scala:"com/microsoft/azure/synapse/ml/stages/Repartition.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Repartition.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"selectcolumns"},"SelectColumns"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n], ["numbers", "words", "more"]))\n\nsc = SelectColumns().setCols(["words", "more"])\n\ndisplay(sc.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval sc = new SelectColumns().setCols(Array("words", "more"))\n\ndisplay(sc.transform(df))\n')))),(0,l.kt)(m.Z,{className:"SelectColumns",py:"mmlspark.stages.html#module-mmlspark.stages.SelectColumns",scala:"com/microsoft/azure/synapse/ml/stages/SelectColumns.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/SelectColumns.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"stratifiedrepartition"},"StratifiedRepartition"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, "Blue", 2),\n      (0, "Red", 2),\n      (0, "Green", 2),\n      (1, "Purple", 2),\n      (1, "Orange", 2),\n      (1, "Indigo", 2),\n      (2, "Violet", 2),\n      (2, "Black", 2),\n      (2, "White", 2),\n      (3, "Gray", 2),\n      (3, "Yellow", 2),\n      (3, "Cerulean", 2)\n], ["values", "colors", "const"]))\n\nsr = StratifiedRepartition().setLabelCol("values").setMode("equal")\n\ndisplay(sr.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    (0, "Blue", 2),\n    (0, "Red", 2),\n    (0, "Green", 2),\n    (1, "Purple", 2),\n    (1, "Orange", 2),\n    (1, "Indigo", 2),\n    (2, "Violet", 2),\n    (2, "Black", 2),\n    (2, "White", 2),\n    (3, "Gray", 2),\n    (3, "Yellow", 2),\n    (3, "Cerulean", 2)\n  ).toDF("values", "colors", "const"))\n\nval sr = new StratifiedRepartition().setLabelCol("values").setMode("equal")\n\ndisplay(sr.transform(df))\n')))),(0,l.kt)(m.Z,{className:"StratifiedRepartition",py:"mmlspark.stages.html#module-mmlspark.stages.StratifiedRepartition",scala:"com/microsoft/azure/synapse/ml/stages/StratifiedRepartition.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/StratifiedRepartition.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"summarizedata"},"SummarizeData"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nsummary = SummarizeData()\n\ndisplay(summary.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval summary = new SummarizeData()\n\ndisplay(summary.transform(df))\n')))),(0,l.kt)(m.Z,{className:"SummarizeData",py:"mmlspark.stages.html#module-mmlspark.stages.SummarizeData",scala:"com/microsoft/azure/synapse/ml/stages/SummarizeData.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/SummarizeData.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"textpreprocessor"},"TextPreprocessor"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      ("The happy sad boy drank sap", ),\n      ("The hater sad doy drank sap", ),\n      ("foo", ),\n      ("The hater sad doy aABc0123456789Zz_", )\n], ["words1"]))\n\ntestMap = {"happy": "sad", "hater": "sap",\n      "sad": "sap", "sad doy": "sap"}\n\ntextPreprocessor = (TextPreprocessor()\n      .setNormFunc("lowerCase")\n      .setMap(testMap)\n      .setInputCol("words1")\n      .setOutputCol("out"))\n\ndisplay(textPreprocessor.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    ("The happy sad boy drank sap", ),\n    ("The hater sad doy drank sap", ),\n    ("foo", ),\n    ("The hater sad doy aABc0123456789Zz_", ))\n    .toDF("words1"))\n\nval testMap = Map[String, String] (\n    "happy"   -> "sad",\n    "hater"   -> "sap",\n    "sad"     -> "sap",\n    "sad doy" -> "sap"\n  )\n\nval textPreprocessor = (new TextPreprocessor()\n      .setNormFunc("lowerCase")\n      .setMap(testMap)\n      .setInputCol("words1")\n      .setOutputCol("out"))\n\ndisplay(textPreprocessor.transform(df))\n')))),(0,l.kt)(m.Z,{className:"TextPreprocessor",py:"mmlspark.stages.html#module-mmlspark.stages.TextPreprocessor",scala:"com/microsoft/azure/synapse/ml/stages/TextPreprocessor.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/TextPreprocessor.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"udftransformer"},"UDFTransformer"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.sql.functions import udf\n\ndf = (spark.createDataFrame([\n      (0, 0.0, "guitars", "drums", 1, True),\n      (1, 1.0, "piano", "trumpet", 2, False),\n      (2, 2.0, "bass", "cymbals", 3, True)\n], ["numbers", "doubles", "words", "more", "longs", "booleans"]))\n\nstringToIntegerUDF = udf(lambda x: 1)\n\nudfTransformer = (UDFTransformer()\n      .setUDF(stringToIntegerUDF)\n      .setInputCol("numbers")\n      .setOutputCol("out"))\n\ndisplay(udfTransformer.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.sql.functions.udf\n\nval df = (Seq(\n      (0, 0.toDouble, "guitars", "drums", 1.toLong, true),\n      (1, 1.toDouble, "piano", "trumpet", 2.toLong, false),\n      (2, 2.toDouble, "bass", "cymbals", 3.toLong, true))\n      .toDF("numbers", "doubles", "words", "more", "longs", "booleans"))\n\nval stringToIntegerUDF = udf((_: String) => 1)\n\nval udfTransformer = (new UDFTransformer()\n      .setUDF(stringToIntegerUDF)\n      .setInputCol("numbers")\n      .setOutputCol("out"))\n\ndisplay(udfTransformer.transform(df))\n')))),(0,l.kt)(m.Z,{className:"UDFTransformer",py:"mmlspark.stages.html#module-mmlspark.stages.UDFTransformer",scala:"com/microsoft/azure/synapse/ml/stages/UDFTransformer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/UDFTransformer.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"unicodenormalize"},"UnicodeNormalize"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      ("Sch\xf6n", 1),\n      ("Scho\\u0308n", 1),\n      (None, 1)\n], ["words1", "dummy"]))\n\nunicodeNormalize = (UnicodeNormalize()\n      .setForm("NFC")\n      .setInputCol("words1")\n      .setOutputCol("norm1"))\n\ndisplay(unicodeNormalize.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = (Seq(\n    ("Sch\xf6n", 1),\n    ("Scho\\u0308n", 1),\n    (null, 1))\n    .toDF("words1", "dummy"))\n\nval unicodeNormalize = (new UnicodeNormalize()\n      .setForm("NFC")\n      .setInputCol("words1")\n      .setOutputCol("norm1"))\n\ndisplay(unicodeNormalize.transform(df))\n')))),(0,l.kt)(m.Z,{className:"UnicodeNormalize",py:"mmlspark.stages.html#module-mmlspark.stages.UnicodeNormalize",scala:"com/microsoft/azure/synapse/ml/stages/UnicodeNormalize.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/UnicodeNormalize.scala",mdxType:"DocTable"}))}P.isMDXComponent=!0;var Z=["components"],O=[{value:"Train",id:"train",children:[{value:"ComputeModelStatistics",id:"computemodelstatistics",children:[],level:3},{value:"ComputePerInstanceStatistics",id:"computeperinstancestatistics",children:[],level:3}],level:2}],F={toc:O};function _(e){var a=e.components,t=(0,n.Z)(e,Z);return(0,l.kt)("wrapper",(0,s.Z)({},F,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"train"},"Train"),(0,l.kt)("h3",{id:"computemodelstatistics"},"ComputeModelStatistics"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import *\nfrom numpy import random\n\ndf = spark.createDataFrame(\n      [(random.rand(), random.rand()) for _ in range(4096)], ["label", "prediction"]\n)\n\ncms = (ComputeModelStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("prediction")\n      .setEvaluationMetric("classification"))\n\ndisplay(cms.transform(df))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.train._\nimport scala.util.Random\n\nval rand = new Random(1337)\nval df = (Seq.fill(4096)(rand.nextDouble())\n      .zip(Seq.fill(4096)(rand.nextDouble()))\n      .toDF("label", "prediction"))\n\nval cms = (new ComputeModelStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("prediction")\n      .setEvaluationMetric("classification"))\n\ndisplay(cms.transform(df))\n')))),(0,l.kt)(m.Z,{className:"ComputeModelStatistics",py:"mmlspark.train.html#module-mmlspark.train.ComputeModelStatistics",scala:"com/microsoft/azure/synapse/ml/train/ComputeModelStatistics.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/train/ComputeModelStatistics.scala",mdxType:"DocTable"}),(0,l.kt)("h3",{id:"computeperinstancestatistics"},"ComputePerInstanceStatistics"),(0,l.kt)(r.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"py",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import *\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import FastVectorAssembler\n\nlogisticRegression = (LogisticRegression()\n      .setRegParam(0.3)\n      .setElasticNetParam(0.8)\n      .setMaxIter(10)\n      .setLabelCol("label")\n      .setPredictionCol("LogRegScoredLabelsCol")\n      .setRawPredictionCol("LogRegScoresCol")\n      .setProbabilityCol("LogRegProbCol")\n      .setFeaturesCol("features"))\n\ndataset = (spark.createDataFrame([\n    (0.0, 2, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 4, 0.78, 0.99, 2.0),\n    (3.0, 5, 0.12, 0.34, 3.0),\n    (0.0, 1, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0),\n    (0.0, 0, 0.50, 0.60, 0.0),\n    (1.0, 2, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0)],\n    ["label", "col1", "col2", "col3", "prediction"]))\n\nassembler = (FastVectorAssembler()\n      .setInputCols(["col1", "col2", "col3"])\n      .setOutputCol("features"))\nassembledDataset = assembler.transform(dataset)\nmodel = logisticRegression.fit(assembledDataset)\nscoredData = model.transform(assembledDataset)\n\ncps = (ComputePerInstanceStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("LogRegScoredLabelsCol")\n      .setScoresCol("LogRegScoresCol")\n      .setScoredProbabilitiesCol("LogRegProbCol")\n      .setEvaluationMetric("classification"))\n\ndisplay(cps.transform(scoredData))\n'))),(0,l.kt)(o.Z,{value:"scala",mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.train._\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.feature.FastVectorAssembler\n\nval logisticRegression = (new LogisticRegression()\n      .setRegParam(0.3)\n      .setElasticNetParam(0.8)\n      .setMaxIter(10)\n      .setLabelCol("label")\n      .setPredictionCol("LogRegScoredLabelsCol")\n      .setRawPredictionCol("LogRegScoresCol")\n      .setProbabilityCol("LogRegProbCol")\n      .setFeaturesCol("features"))\n\nval dataset = spark.createDataFrame(Seq(\n    (0.0, 2, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 4, 0.78, 0.99, 2.0),\n    (3.0, 5, 0.12, 0.34, 3.0),\n    (0.0, 1, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0),\n    (0.0, 0, 0.50, 0.60, 0.0),\n    (1.0, 2, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0)))\n    .toDF("label", "col1", "col2", "col3", "prediction")\n\nval assembler = (new FastVectorAssembler()\n      .setInputCols(Array("col1", "col2", "col3"))\n      .setOutputCol("features"))\nval assembledDataset = assembler.transform(dataset)\nval model = logisticRegression.fit(assembledDataset)\nval scoredData = model.transform(assembledDataset)\n\nval cps = (new ComputePerInstanceStatistics()\n      .setLabelCol("label")\n      .setScoredLabelsCol("LogRegScoredLabelsCol")\n      .setScoresCol("LogRegScoresCol")\n      .setScoredProbabilitiesCol("LogRegProbCol")\n      .setEvaluationMetric("classification"))\n\ndisplay(cps.transform(scoredData))\n')))),(0,l.kt)(m.Z,{className:"ComputePerInstanceStatistics",py:"mmlspark.train.html#module-mmlspark.train.ComputePerInstanceStatistics",scala:"com/microsoft/azure/synapse/ml/train/ComputePerInstanceStatistics.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/train/ComputePerInstanceStatistics.scala",mdxType:"DocTable"}))}_.isMDXComponent=!0;var E=["components"],R={title:"Transformers - Core",sidebar_label:"Core",hide_title:!0},V=void 0,B={unversionedId:"documentation/transformers/transformers_core",id:"documentation/transformers/transformers_core",isDocsHomePage:!1,title:"Transformers - Core",description:"export const toc = [...ExplainersTOC, ...FeaturizeTOC, ...ImageTOC,",source:"@site/docs/documentation/transformers/transformers_core.md",sourceDirName:"documentation/transformers",slug:"/documentation/transformers/transformers_core",permalink:"/SynapseML/docs/next/documentation/transformers/transformers_core",tags:[],version:"current",frontMatter:{title:"Transformers - Core",sidebar_label:"Core",hide_title:!0},sidebar:"docs",previous:{title:"Cognitive",permalink:"/SynapseML/docs/next/documentation/transformers/transformers_cognitive"},next:{title:"OpenCV",permalink:"/SynapseML/docs/next/documentation/transformers/transformers_opencv"}},j=[].concat(i,y,k,x,I,M,O),A={toc:j};function H(e){var a=e.components,t=(0,n.Z)(e,E);return(0,l.kt)("wrapper",(0,s.Z)({},A,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)(c,{mdxType:"Explainers"}),(0,l.kt)(f,{mdxType:"Featurize"}),(0,l.kt)(T,{mdxType:"Image"}),(0,l.kt)(C,{mdxType:"IO"}),(0,l.kt)(z,{mdxType:"SuperpixelTransformer"}),(0,l.kt)(P,{mdxType:"Stages"}),(0,l.kt)(_,{mdxType:"Train"}))}H.isMDXComponent=!0}}]);