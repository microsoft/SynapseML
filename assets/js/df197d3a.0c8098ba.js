"use strict";(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[1941],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),p=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),m=p(n),d=o,h=m["".concat(l,".").concat(d)]||m[d]||c[d]||a;return n?r.createElement(h,i(i({ref:t},u),{},{components:n})):r.createElement(h,i({ref:t},u))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var p=2;p<a;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},69556:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var r=n(83117),o=(n(67294),n(3905));const a={title:"Quickstart - Chat Completion with Azure AI Foundry Model",hide_title:!0,status:"stable"},i="Chat Completion with Azure AI Foundry model",s={unversionedId:"Explore Algorithms/Deep Learning/Quickstart - Chat Completion with Azure AI Foundry Model",id:"version-1.0.15/Explore Algorithms/Deep Learning/Quickstart - Chat Completion with Azure AI Foundry Model",title:"Quickstart - Chat Completion with Azure AI Foundry Model",description:"Azure AI Foundry enables the execution of a wide range of natural language tasks using the Completion API. Its integration with SynapseML simplifies leveraging the Apache Spark distributed computing framework to handle large volumes of prompts across various models, including those from Deepseek, Meta, Microsoft, xAI, and others. For a full list of supported models, refer to Azure AI Foundry documentation.",source:"@site/versioned_docs/version-1.0.15/Explore Algorithms/Deep Learning/Quickstart - Chat Completion with Azure AI Foundry Model.md",sourceDirName:"Explore Algorithms/Deep Learning",slug:"/Explore Algorithms/Deep Learning/Quickstart - Chat Completion with Azure AI Foundry Model",permalink:"/SynapseML/docs/1.0.15/Explore Algorithms/Deep Learning/Quickstart - Chat Completion with Azure AI Foundry Model",draft:!1,tags:[],version:"1.0.15",frontMatter:{title:"Quickstart - Chat Completion with Azure AI Foundry Model",hide_title:!0,status:"stable"},sidebar:"docs",previous:{title:"Quickstart - Apply Phi Model with HuggingFace CausalLM",permalink:"/SynapseML/docs/1.0.15/Explore Algorithms/Deep Learning/Quickstart - Apply Phi Model with HuggingFace CausalLM"},next:{title:"Interpreting Model Predictions",permalink:"/SynapseML/docs/1.0.15/Explore Algorithms/Responsible AI/Interpreting Model Predictions"}},l={},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Chat Completion",id:"chat-completion",level:2}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"chat-completion-with-azure-ai-foundry-model"},"Chat Completion with Azure AI Foundry model"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry"},"Azure AI Foundry")," enables the execution of a wide range of natural language tasks using the Completion API. Its integration with SynapseML simplifies leveraging the Apache Spark distributed computing framework to handle large volumes of prompts across various models, including those from Deepseek, Meta, Microsoft, xAI, and others. For a full list of ",(0,o.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models"},"supported models"),", refer to Azure AI Foundry documentation.\nNote: To use OpenAI models, integration is available through the OpenAIChatCompletion class. Refer to the relevant documentation for details on ",(0,o.kt)("a",{parentName:"p",href:"https://microsoft.github.io/SynapseML/docs/Explore%20Algorithms/OpenAI/"},"using OpenAI models"),"."),(0,o.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,o.kt)("p",null,"The key prerequisites for this quickstart include "),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"An ",(0,o.kt)("a",{parentName:"p",href:"https://azure.microsoft.com/en-us/pricing/purchase-options/azure-account"},"Azure subscription"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"A working Azure AI Foundry project resource and a model deployed"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Sign in to the ",(0,o.kt)("a",{parentName:"p",href:"https://ai.azure.com/"},"Azure AI foundry portal"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Select a chat completion model. We use Phi-4-mini-instruct model as an example. "),(0,o.kt)("img",{src:"https://mmlspark.blob.core.windows.net/graphics/phi_4.png",width:"500"})),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"On the model details page, select Use this model.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Fill in a name to use for your project and select Create.")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"An Apache Spark cluster with SynapseML installed."))),(0,o.kt)("h1",{id:"fill-in-service-information"},"Fill in service information"),(0,o.kt)("p",null,"Next, edit the cell in the notebook to point to your service. "),(0,o.kt)("p",null,"In particular set the service_name, api_version to match them to your AI Foundry model.\nTo get your service_name, api_version and api_key, Select My Asset, Find Target URI. API version is also in target URI."),(0,o.kt)("img",{src:"https://mmlspark.blob.core.windows.net/graphics/phi_4_2.png",width:"500"}),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.core.platform import find_secret\n\n# Fill in the following lines with your service information\nservice_name = "synapseml-ai-foundry-resource"\napi_verion = "2024-05-01-preview"\nmodel = "Phi-4-mini-instruct"\napi_key = find_secret(\n    secret_name="synapseml-ai-foundry-resource-key", keyvault="mmlspark-build-keys"\n)  # please replace this line with your key as a string\n\nassert api_key is not None and service_name is not None\n')),(0,o.kt)("h2",{id:"chat-completion"},"Chat Completion"),(0,o.kt)("p",null,"Models such as Phi-4 and llama are capable of understanding chats instead of single prompts. The ",(0,o.kt)("inlineCode",{parentName:"p"},"AIFoundryChatCompletion")," transformer exposes this functionality at scale."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.services.aifoundry import AIFoundryChatCompletion\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\n\n\ndef make_message(role, content):\n    return Row(role=role, content=content, name=role)\n\n\nchat_df = spark.createDataFrame(\n    [\n        (\n            [\n                make_message(\n                    "system", "You are an AI chatbot with red as your favorite color"\n                ),\n                make_message("user", "Whats your favorite color"),\n            ],\n        ),\n        (\n            [\n                make_message("system", "You are very excited"),\n                make_message("user", "How are you today"),\n            ],\n        ),\n    ]\n).toDF("messages")\n\n\nchat_completion = (\n    AIFoundryChatCompletion()\n    .setSubscriptionKey(api_key)\n    .setCustomServiceName(service_name)\n    .setModel(model)\n    .setApiVersion("2024-05-01-preview")\n    .setMessagesCol("messages")\n    .setErrorCol("error")\n    .setOutputCol("chat_completions")\n)\n\ndisplay(\n    chat_completion.transform(chat_df).select(\n        "messages", "chat_completions.choices.message.content"\n    )\n)\n')))}c.isMDXComponent=!0}}]);