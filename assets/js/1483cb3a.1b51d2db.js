(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[3022],{3905:function(e,a,n){"use strict";n.d(a,{Zo:function(){return c},kt:function(){return d}});var t=n(7294);function o(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function r(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function s(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?r(Object(n),!0).forEach((function(a){o(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function l(e,a){if(null==e)return{};var n,t,o=function(e,a){if(null==e)return{};var n,t,o={},r=Object.keys(e);for(t=0;t<r.length;t++)n=r[t],a.indexOf(n)>=0||(o[n]=e[n]);return o}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)n=r[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var i=t.createContext({}),m=function(e){var a=t.useContext(i),n=a;return e&&(n="function"==typeof e?e(a):s(s({},a),e)),n},c=function(e){var a=m(e.components);return t.createElement(i.Provider,{value:a},e.children)},p={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},u=t.forwardRef((function(e,a){var n=e.components,o=e.mdxType,r=e.originalType,i=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=m(n),d=o,f=u["".concat(i,".").concat(d)]||u[d]||p[d]||r;return n?t.createElement(f,s(s({ref:a},c),{},{components:n})):t.createElement(f,s({ref:a},c))}));function d(e,a){var n=arguments,o=a&&a.mdxType;if("string"==typeof e||o){var r=n.length,s=new Array(r);s[0]=u;var l={};for(var i in a)hasOwnProperty.call(a,i)&&(l[i]=a[i]);l.originalType=e,l.mdxType="string"==typeof e?e:o,s[1]=l;for(var m=2;m<r;m++)s[m]=n[m];return t.createElement.apply(null,s)}return t.createElement.apply(null,n)}u.displayName="MDXCreateElement"},1332:function(e,a,n){"use strict";var t=n(7294);a.Z=function(e){var a=e.children,n=e.hidden,o=e.className;return t.createElement("div",{role:"tabpanel",hidden:n,className:o},a)}},5386:function(e,a,n){"use strict";n.d(a,{Z:function(){return u}});var t=n(4034),o=n(7294),r=n(2389),s=n(8578);var l=function(){var e=(0,o.useContext)(s.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},i=n(9558),m=n(6010),c="tabItem_2kG2";function p(e){var a,n,t,r=e.lazy,s=e.block,p=e.defaultValue,u=e.values,d=e.groupId,f=e.className,y=o.Children.map(e.children,(function(e){if((0,o.isValidElement)(e)&&"string"==typeof e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),v=null!=u?u:y.map((function(e){var a=e.props;return{value:a.value,label:a.label}})),g=(0,i.lx)(v,(function(e,a){return e.value===a.value}));if(g.length>0)throw new Error('Docusaurus error: Duplicate values "'+g.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var k=null===p?p:null!=(a=null!=p?p:null==(n=y.find((function(e){return e.props.default})))?void 0:n.props.value)?a:null==(t=y[0])?void 0:t.props.value;if(null!==k&&!v.some((function(e){return e.value===k})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+k+'" but none of its children has the corresponding value. Available values are: '+v.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var b=l(),h=b.tabGroupChoices,T=b.setTabGroupChoices,M=(0,o.useState)(k),C=M[0],I=M[1],x=[],N=(0,i.o5)().blockElementScrollPositionUntilNextRender;if(null!=d){var D=h[d];null!=D&&D!==C&&v.some((function(e){return e.value===D}))&&I(D)}var w=function(e){var a=e.currentTarget,n=x.indexOf(a),t=v[n].value;t!==C&&(N(a),I(t),null!=d&&T(d,t))},S=function(e){var a,n=null;switch(e.key){case"ArrowRight":var t=x.indexOf(e.currentTarget)+1;n=x[t]||x[0];break;case"ArrowLeft":var o=x.indexOf(e.currentTarget)-1;n=x[o]||x[x.length-1]}null==(a=n)||a.focus()};return o.createElement("div",{className:"tabs-container"},o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,m.Z)("tabs",{"tabs--block":s},f)},v.map((function(e){var a=e.value,n=e.label;return o.createElement("li",{role:"tab",tabIndex:C===a?0:-1,"aria-selected":C===a,className:(0,m.Z)("tabs__item",c,{"tabs__item--active":C===a}),key:a,ref:function(e){return x.push(e)},onKeyDown:S,onFocus:w,onClick:w},null!=n?n:a)}))),r?(0,o.cloneElement)(y.filter((function(e){return e.props.value===C}))[0],{className:"margin-vert--md"}):o.createElement("div",{className:"margin-vert--md"},y.map((function(e,a){return(0,o.cloneElement)(e,{key:a,hidden:e.props.value!==C})}))))}function u(e){var a=(0,r.Z)();return o.createElement(p,(0,t.Z)({key:String(a)},e))}},8578:function(e,a,n){"use strict";var t=(0,n(7294).createContext)(void 0);a.Z=t},1989:function(e,a,n){"use strict";var t=n(7294),o=n(2263);a.Z=function(e){var a=e.className,n=e.py,r=e.scala,s=e.sourceLink,l=(0,o.Z)().siteConfig.customFields.version,i="https://mmlspark.blob.core.windows.net/docs/"+l+"/pyspark/"+n,m="https://mmlspark.blob.core.windows.net/docs/"+l+"/scala/"+r;return t.createElement("table",null,t.createElement("tbody",null,t.createElement("tr",null,t.createElement("td",null,t.createElement("strong",null,"Python API: "),t.createElement("a",{href:i},a)),t.createElement("td",null,t.createElement("strong",null,"Scala API: "),t.createElement("a",{href:m},a)),t.createElement("td",null,t.createElement("strong",null,"Source: "),t.createElement("a",{href:s},a)))))}},6979:function(e,a,n){"use strict";n.r(a),n.d(a,{contentTitle:function(){return B},default:function(){return K},frontMatter:function(){return P},metadata:function(){return A},toc:function(){return H}});var t=n(4034),o=n(9973),r=(n(7294),n(3905)),s=n(5386),l=n(1332),i=n(1989),m=["components"],c=[{value:"AutoML",id:"automl",children:[{value:"FindBestModel",id:"findbestmodel",children:[],level:3},{value:"TuneHyperparameters",id:"tunehyperparameters",children:[],level:3}],level:2}],p={toc:c};function u(e){var a=e.components,n=(0,o.Z)(e,m);return(0,r.kt)("wrapper",(0,t.Z)({},p,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"automl"},"AutoML"),(0,r.kt)("h3",{id:"findbestmodel"},"FindBestModel"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.automl import *\nfrom synapse.ml.train import *\nfrom pyspark.ml.classification import RandomForestClassifier\n\ndf = (spark.createDataFrame([\n    (0, 2, 0.50, 0.60, 0),\n    (1, 3, 0.40, 0.50, 1),\n    (0, 4, 0.78, 0.99, 2),\n    (1, 5, 0.12, 0.34, 3),\n    (0, 1, 0.50, 0.60, 0),\n    (1, 3, 0.40, 0.50, 1),\n    (0, 3, 0.78, 0.99, 2),\n    (1, 4, 0.12, 0.34, 3),\n    (0, 0, 0.50, 0.60, 0),\n    (1, 2, 0.40, 0.50, 1),\n    (0, 3, 0.78, 0.99, 2),\n    (1, 4, 0.12, 0.34, 3)\n], ["Label", "col1", "col2", "col3", "col4"]))\n\n# mocking models\nrandomForestClassifier = (TrainClassifier()\n      .setModel(RandomForestClassifier()\n        .setMaxBins(32)\n        .setMaxDepth(5)\n        .setMinInfoGain(0.0)\n        .setMinInstancesPerNode(1)\n        .setNumTrees(20)\n        .setSubsamplingRate(1.0)\n        .setSeed(0))\n      .setFeaturesCol("mlfeatures")\n      .setLabelCol("Label"))\nmodel = randomForestClassifier.fit(df)\n\nfindBestModel = (FindBestModel()\n  .setModels([model, model])\n  .setEvaluationMetric("accuracy"))\nbestModel = findBestModel.fit(df)\ndisplay(bestModel.transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.automl._\nimport com.microsoft.azure.synapse.ml.train._\nimport spark.implicits._\nimport org.apache.spark.ml.Transformer\n\nval df = (Seq(\n      (0, 2, 0.50, 0.60, 0),\n      (1, 3, 0.40, 0.50, 1),\n      (0, 4, 0.78, 0.99, 2),\n      (1, 5, 0.12, 0.34, 3),\n      (0, 1, 0.50, 0.60, 0),\n      (1, 3, 0.40, 0.50, 1),\n      (0, 3, 0.78, 0.99, 2),\n      (1, 4, 0.12, 0.34, 3),\n      (0, 0, 0.50, 0.60, 0),\n      (1, 2, 0.40, 0.50, 1),\n      (0, 3, 0.78, 0.99, 2),\n      (1, 4, 0.12, 0.34, 3)\n  ).toDF("Label", "col1", "col2", "col3", "col4"))\n\n// mocking models\nval randomForestClassifier = (new TrainClassifier()\n      .setModel(\n        new RandomForestClassifier()\n        .setMaxBins(32)\n        .setMaxDepth(5)\n        .setMinInfoGain(0.0)\n        .setMinInstancesPerNode(1)\n        .setNumTrees(20)\n        .setSubsamplingRate(1.0)\n        .setSeed(0L))\n      .setFeaturesCol("mlfeatures")\n      .setLabelCol("Label"))\nval model = randomForestClassifier.fit(df)\n\nval findBestModel = (new FindBestModel()\n  .setModels(Array(model.asInstanceOf[Transformer], model.asInstanceOf[Transformer]))\n  .setEvaluationMetric("accuracy"))\nval bestModel = findBestModel.fit(df)\ndisplay(bestModel.transform(df))\n')))),(0,r.kt)(i.Z,{className:"FindBestModel",py:"synapse.ml.automl.html#module-synapse.ml.automl.FindBestModel",scala:"com/microsoft/azure/synapse/ml/automl/FindBestModel.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/automl/FindBestModel.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"tunehyperparameters"},"TuneHyperparameters"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.automl import *\nfrom synapse.ml.train import *\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n\n\ndf = (spark.createDataFrame([\n    (0, 1, 1, 1, 1, 1, 1.0, 3, 1, 1),\n    (0, 1, 1, 1, 1, 2, 1.0, 1, 1, 1),\n    (0, 1, 1, 1, 1, 2, 1.0, 2, 1, 1),\n    (0, 1, 2, 3, 1, 2, 1.0, 3, 1, 1),\n    (0, 3, 1, 1, 1, 2, 1.0, 3, 1, 1)\n], ["Label", "Clump_Thickness", "Uniformity_of_Cell_Size",\n    "Uniformity_of_Cell_Shape", "Marginal_Adhesion", "Single_Epithelial_Cell_Size",\n    "Bare_Nuclei", "Bland_Chromatin", "Normal_Nucleoli", "Mitoses"]))\n\nlogReg = LogisticRegression()\nrandForest = RandomForestClassifier()\ngbt = GBTClassifier()\nsmlmodels = [logReg, randForest, gbt]\nmmlmodels = [TrainClassifier(model=model, labelCol="Label") for model in smlmodels]\n\nparamBuilder = (HyperparamBuilder()\n    .addHyperparam(logReg, logReg.regParam, RangeHyperParam(0.1, 0.3))\n    .addHyperparam(randForest, randForest.numTrees, DiscreteHyperParam([5,10]))\n    .addHyperparam(randForest, randForest.maxDepth, DiscreteHyperParam([3,5]))\n    .addHyperparam(gbt, gbt.maxBins, RangeHyperParam(8,16))\n    .addHyperparam(gbt, gbt.maxDepth, DiscreteHyperParam([3,5])))\nsearchSpace = paramBuilder.build()\n# The search space is a list of params to tuples of estimator and hyperparam\nrandomSpace = RandomSpace(searchSpace)\n\nbestModel = TuneHyperparameters(\n              evaluationMetric="accuracy", models=mmlmodels, numFolds=2,\n              numRuns=len(mmlmodels) * 2, parallelism=2,\n              paramSpace=randomSpace.space(), seed=0).fit(df)\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.automl._\nimport com.microsoft.azure.synapse.ml.train._\nimport spark.implicits._\n\nval logReg = new LogisticRegression()\nval randForest = new RandomForestClassifier()\nval gbt = new GBTClassifier()\nval smlmodels = Seq(logReg, randForest, gbt)\nval mmlmodels = smlmodels.map(model => new TrainClassifier().setModel(model).setLabelCol("Label"))\n\nval paramBuilder = new HyperparamBuilder()\n  .addHyperparam(logReg.regParam, new DoubleRangeHyperParam(0.1, 0.3))\n  .addHyperparam(randForest.numTrees, new DiscreteHyperParam(List(5,10)))\n  .addHyperparam(randForest.maxDepth, new DiscreteHyperParam(List(3,5)))\n  .addHyperparam(gbt.maxBins, new IntRangeHyperParam(8,16))\n.addHyperparam(gbt.maxDepth, new DiscreteHyperParam(List(3,5)))\nval searchSpace = paramBuilder.build()\nval randomSpace = new RandomSpace(searchSpace)\n\nval dataset: DataFrame = Seq(\n  (0, 1, 1, 1, 1, 1, 1.0, 3, 1, 1),\n  (0, 1, 1, 1, 1, 2, 1.0, 1, 1, 1),\n  (0, 1, 1, 1, 1, 2, 1.0, 2, 1, 1),\n  (0, 1, 2, 3, 1, 2, 1.0, 3, 1, 1),\n  (0, 3, 1, 1, 1, 2, 1.0, 3, 1, 1))\n  .toDF("Label", "Clump_Thickness", "Uniformity_of_Cell_Size",\n    "Uniformity_of_Cell_Shape", "Marginal_Adhesion", "Single_Epithelial_Cell_Size",\n    "Bare_Nuclei", "Bland_Chromatin", "Normal_Nucleoli", "Mitoses")\n\nval tuneHyperparameters = new TuneHyperparameters().setEvaluationMetric("accuracy")\n  .setModels(mmlmodels.toArray).setNumFolds(2).setNumRuns(mmlmodels.length * 2)\n  .setParallelism(1).setParamSpace(randomSpace).setSeed(0)\ndisplay(tuneHyperparameters.fit(dataset))\n')))),(0,r.kt)(i.Z,{className:"TuneHyperparameters",py:"synapse.ml.automl.html#module-synapse.ml.automl.TuneHyperparameters",scala:"com/microsoft/azure/synapse/ml/automl/TuneHyperparameters.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/automl/TuneHyperparameters.scala",mdxType:"DocTable"}))}u.isMDXComponent=!0;var d=["components"],f=[{value:"Featurize",id:"featurize",children:[{value:"CleanMissingData",id:"cleanmissingdata",children:[],level:3},{value:"CountSelector",id:"countselector",children:[],level:3},{value:"Featurize",id:"featurize-1",children:[],level:3},{value:"ValueIndexer",id:"valueindexer",children:[],level:3}],level:2},{value:"Featurize Text",id:"featurize-text",children:[{value:"TextFeaturizer",id:"textfeaturizer",children:[],level:3}],level:2}],y={toc:f};function v(e){var a=e.components,n=(0,o.Z)(e,d);return(0,r.kt)("wrapper",(0,t.Z)({},y,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"featurize"},"Featurize"),(0,r.kt)("h3",{id:"cleanmissingdata"},"CleanMissingData"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndataset = spark.createDataFrame([\n    (0,    2,    0.50, 0.60, 0),\n    (1,    3,    0.40, None, None),\n    (0,    4,    0.78, 0.99, 2),\n    (1,    5,    0.12, 0.34, 3),\n    (0,    1,    0.50, 0.60, 0),\n    (None, None, None, None, None),\n    (0,    3,    0.78, 0.99, 2),\n    (1,    4,    0.12, 0.34, 3),\n    (0,    None, 0.50, 0.60, 0),\n    (1,    2,    0.40, 0.50, None),\n    (0,    3,    None, 0.99, 2),\n    (1,    4,    0.12, 0.34, 3)\n], ["col1", "col2", "col3", "col4", "col5"])\n\ncmd = (CleanMissingData()\n      .setInputCols(dataset.columns)\n      .setOutputCols(dataset.columns)\n      .setCleaningMode("Mean"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport java.lang.{Boolean => JBoolean, Double => JDouble, Integer => JInt}\nimport spark.implicits._\n\ndef createMockDataset: DataFrame = {\n    Seq[(JInt, JInt, JDouble, JDouble, JInt)](\n      (0,    2,    0.50, 0.60, 0),\n      (1,    3,    0.40, null, null),\n      (0,    4,    0.78, 0.99, 2),\n      (1,    5,    0.12, 0.34, 3),\n      (0,    1,    0.50, 0.60, 0),\n      (null, null, null, null, null),\n      (0,    3,    0.78, 0.99, 2),\n      (1,    4,    0.12, 0.34, 3),\n      (0,    null, 0.50, 0.60, 0),\n      (1,    2,    0.40, 0.50, null),\n      (0,    3,    null, 0.99, 2),\n      (1,    4,    0.12, 0.34, 3))\n      .toDF("col1", "col2", "col3", "col4", "col5")\n  }\n\nval dataset = createMockDataset\nval cmd = (new CleanMissingData()\n      .setInputCols(dataset.columns)\n      .setOutputCols(dataset.columns)\n      .setCleaningMode("Mean"))\n')))),(0,r.kt)(i.Z,{className:"CleanMissingData",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.CleanMissingData",scala:"com/microsoft/azure/synapse/ml/featurize/CleanMissingData.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/CleanMissingData.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"countselector"},"CountSelector"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\nfrom pyspark.ml.linalg import Vectors\n\ndf = spark.createDataFrame([\n    (Vectors.sparse(3, [(0, 1.0), (2, 2.0)]), Vectors.dense(1.0, 0.1, 0)),\n    (Vectors.sparse(3, [(0, 1.0), (2, 2.0)]), Vectors.dense(1.0, 0.1, 0))\n], ["col1", "col2"])\n\ncs = CountSelector().setInputCol("col1").setOutputCol("col3")\n\ndisplay(cs.fit(df).transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport org.apache.spark.ml.linalg.Vectors\nimport spark.implicits._\n\nval df = Seq(\n    (Vectors.sparse(3, Seq((0, 1.0), (2, 2.0))), Vectors.dense(1.0, 0.1, 0)),\n    (Vectors.sparse(3, Seq((0, 1.0), (2, 2.0))), Vectors.dense(1.0, 0.1, 0))\n  ).toDF("col1", "col2")\n\nval cs = (new CountSelector()\n            .setInputCol("col1")\n            .setOutputCol("col3"))\n\ndisplay(cs.fit(df).transform(df))\n')))),(0,r.kt)(i.Z,{className:"CountSelector",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.CountSelector",scala:"com/microsoft/azure/synapse/ml/featurize/CountSelector.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/CountSelector.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"featurize-1"},"Featurize"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndataset = spark.createDataFrame([\n    (0, 2, 0.50, 0.60, "pokemon are everywhere"),\n    (1, 3, 0.40, 0.50, "they are in the woods"),\n    (0, 4, 0.78, 0.99, "they are in the water"),\n    (1, 5, 0.12, 0.34, "they are in the fields"),\n    (0, 3, 0.78, 0.99, "pokemon - gotta catch em all")\n], ["Label", "col1", "col2", "col3"])\n\nfeatureColumns = filter(lambda x: x != "Label", dataset.columns)\n\nfeat = (Featurize()\n      .setNumFeatures(10)\n      .setOutputCol("testColumn")\n      .setInputCols(list(featureColumns))\n      .setOneHotEncodeCategoricals(False))\n\ndisplay(feat.fit(dataset).transform(dataset))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport spark.implicits._\n\nval dataset = Seq(\n      (0, 2, 0.50, 0.60, "pokemon are everywhere"),\n      (1, 3, 0.40, 0.50, "they are in the woods"),\n      (0, 4, 0.78, 0.99, "they are in the water"),\n      (1, 5, 0.12, 0.34, "they are in the fields"),\n      (0, 3, 0.78, 0.99, "pokemon - gotta catch em all")).toDF("Label", "col1", "col2", "col3")\n\nval featureColumns = dataset.columns.filter(_ != "Label")\n\nval feat = (new Featurize()\n      .setNumFeatures(10)\n      .setOutputCol("testColumn")\n      .setInputCols(featureColumns)\n      .setOneHotEncodeCategoricals(false))\n\ndisplay(feat.fit(dataset).transform(dataset))\n')))),(0,r.kt)(i.Z,{className:"Featurize",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.Featurize",scala:"com/microsoft/azure/synapse/ml/featurize/Featurize.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/Featurize.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"valueindexer"},"ValueIndexer"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize import *\n\ndf = spark.createDataFrame([\n    (-3, 24, 0.32534, True, "piano"),\n    (1, 5, 5.67, False, "piano"),\n    (-3, 5, 0.32534, False, "guitar")\n], ["int", "long", "double", "bool", "string"])\n\nvi = ValueIndexer().setInputCol("string").setOutputCol("string_cat")\n\ndisplay(vi.fit(df).transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize._\nimport spark.implicits._\n\nval df = Seq[(Int, Long, Double, Boolean, String)](\n    (-3, 24L, 0.32534, true, "piano"),\n    (1, 5L, 5.67, false, "piano"),\n    (-3, 5L, 0.32534, false, "guitar")).toDF("int", "long", "double", "bool", "string")\n\nval vi = new ValueIndexer().setInputCol("string").setOutputCol("string_cat")\n\ndisplay(vi.fit(df).transform(df))\n')))),(0,r.kt)(i.Z,{className:"ValueIndexer",py:"synapse.ml.featurize.html#module-synapse.ml.featurize.ValueIndexer",scala:"com/microsoft/azure/synapse/ml/featurize/ValueIndexer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/ValueIndexer.scala",mdxType:"DocTable"}),(0,r.kt)("h2",{id:"featurize-text"},"Featurize Text"),(0,r.kt)("h3",{id:"textfeaturizer"},"TextFeaturizer"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.featurize.text import *\n\ndfRaw = spark.createDataFrame([\n    (0, "Hi I"),\n    (1, "I wish for snow today"),\n    (2, "we Cant go to the park, because of the snow!"),\n    (3, "")\n], ["label", "sentence"])\n\ntfRaw = (TextFeaturizer()\n      .setInputCol("sentence")\n      .setOutputCol("features")\n      .setNumFeatures(20))\n\ndisplay(tfRaw.fit(dfRaw).transform(dfRaw))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.featurize.text._\nimport spark.implicits._\n\nval dfRaw = Seq((0, "Hi I"),\n            (1, "I wish for snow today"),\n            (2, "we Cant go to the park, because of the snow!"),\n            (3, "")).toDF("label", "sentence")\n\nval tfRaw = (new TextFeaturizer()\n      .setInputCol("sentence")\n      .setOutputCol("features")\n      .setNumFeatures(20))\n\ndisplay(tfRaw.fit(dfRaw).transform(dfRaw))\n')))),(0,r.kt)(i.Z,{className:"TextFeaturizer",py:"synapse.ml.featurize.text.html#module-synapse.ml.featurize.text.TextFeaturizer",scala:"com/microsoft/azure/synapse/ml/featurize/text/TextFeaturizer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/featurize/text/TextFeaturizer.scala",mdxType:"DocTable"}))}v.isMDXComponent=!0;var g=["components"],k=[{value:"Isolation Forest",id:"isolation-forest",children:[{value:"IsolationForest",id:"isolationforest",children:[],level:3}],level:2}],b={toc:k};function h(e){var a=e.components,n=(0,o.Z)(e,g);return(0,r.kt)("wrapper",(0,t.Z)({},b,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"isolation-forest"},"Isolation Forest"),(0,r.kt)("h3",{id:"isolationforest"},"IsolationForest"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.isolationforest import *\n\nisolationForest = (IsolationForest()\n      .setNumEstimators(100)\n      .setBootstrap(False)\n      .setMaxSamples(256)\n      .setMaxFeatures(1.0)\n      .setFeaturesCol("features")\n      .setPredictionCol("predictedLabel")\n      .setScoreCol("outlierScore")\n      .setContamination(0.02)\n      .setContaminationError(0.02 * 0.01)\n      .setRandomSeed(1))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.isolationforest._\nimport spark.implicits._\n\nval isolationForest = (new IsolationForest()\n      .setNumEstimators(100)\n      .setBootstrap(false)\n      .setMaxSamples(256)\n      .setMaxFeatures(1.0)\n      .setFeaturesCol("features")\n      .setPredictionCol("predictedLabel")\n      .setScoreCol("outlierScore")\n      .setContamination(0.02)\n      .setContaminationError(0.02 * 0.01)\n      .setRandomSeed(1))\n')))),(0,r.kt)(i.Z,{className:"CleanMissingData",py:"mmlspark.isolationforest.html#module-mmlspark.isolationforest.IsolationForest",scala:"com/microsoft/azure/synapse/ml/isolationforest/IsolationForest.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/isolationforest/IsolationForest.scala",mdxType:"DocTable"}))}h.isMDXComponent=!0;var T=["components"],M=[{value:"NN",id:"nn",children:[{value:"ConditionalKNN",id:"conditionalknn",children:[],level:3},{value:"KNN",id:"knn",children:[],level:3}],level:2}],C={toc:M};function I(e){var a=e.components,n=(0,o.Z)(e,T);return(0,r.kt)("wrapper",(0,t.Z)({},C,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"nn"},"NN"),(0,r.kt)("h3",{id:"conditionalknn"},"ConditionalKNN"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.nn import *\n\ncknn = (ConditionalKNN()\n      .setOutputCol("matches")\n      .setFeaturesCol("features"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.nn._\nimport spark.implicits._\n\nval cknn = (new ConditionalKNN()\n            .setOutputCol("matches")\n            .setFeaturesCol("features"))\n')))),(0,r.kt)(i.Z,{className:"ConditionalKNN",py:"mmlspark.nn.html#module-mmlspark.nn.ConditionalKNN",scala:"com/microsoft/azure/synapse/ml/nn/ConditionalKNN.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/nn/ConditionalKNN.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"knn"},"KNN"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.nn import *\n\nknn = (KNN()\n      .setOutputCol("matches"))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.nn._\nimport spark.implicits._\n\nval knn = (new KNN()\n      .setOutputCol("matches"))\n')))),(0,r.kt)(i.Z,{className:"KNN",py:"mmlspark.nn.html#module-mmlspark.nn.KNN",scala:"com/microsoft/azure/synapse/ml/nn/KNN.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/nn/KNN.scala",mdxType:"DocTable"}))}I.isMDXComponent=!0;var x=["components"],N=[{value:"Recommendation",id:"recommendation",children:[{value:"RecommendationIndexer, RankingEvaluator, RankingAdapter and RankingTrainValidationSplit",id:"recommendationindexer-rankingevaluator-rankingadapter-and-rankingtrainvalidationsplit",children:[],level:3},{value:"SAR",id:"sar",children:[],level:3}],level:2}],D={toc:N};function w(e){var a=e.components,n=(0,o.Z)(e,x);return(0,r.kt)("wrapper",(0,t.Z)({},D,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"recommendation"},"Recommendation"),(0,r.kt)("h3",{id:"recommendationindexer-rankingevaluator-rankingadapter-and-rankingtrainvalidationsplit"},"RecommendationIndexer, RankingEvaluator, RankingAdapter and RankingTrainValidationSplit"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.recommendation import *\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.tuning import *\n\nratings = (spark.createDataFrame([\n      ("11", "Movie 01", 2),\n      ("11", "Movie 03", 1),\n      ("11", "Movie 04", 5),\n      ("11", "Movie 05", 3),\n      ("11", "Movie 06", 4),\n      ("11", "Movie 07", 1),\n      ("11", "Movie 08", 5),\n      ("11", "Movie 09", 3),\n      ("22", "Movie 01", 4),\n      ("22", "Movie 02", 5),\n      ("22", "Movie 03", 1),\n      ("22", "Movie 05", 3),\n      ("22", "Movie 06", 3),\n      ("22", "Movie 07", 5),\n      ("22", "Movie 08", 1),\n      ("22", "Movie 10", 3),\n      ("33", "Movie 01", 4),\n      ("33", "Movie 03", 1),\n      ("33", "Movie 04", 5),\n      ("33", "Movie 05", 3),\n      ("33", "Movie 06", 4),\n      ("33", "Movie 08", 1),\n      ("33", "Movie 09", 5),\n      ("33", "Movie 10", 3),\n      ("44", "Movie 01", 4),\n      ("44", "Movie 02", 5),\n      ("44", "Movie 03", 1),\n      ("44", "Movie 05", 3),\n      ("44", "Movie 06", 4),\n      ("44", "Movie 07", 5),\n      ("44", "Movie 08", 1),\n      ("44", "Movie 10", 3)\n      ], ["customerIDOrg", "itemIDOrg", "rating"])\n    .dropDuplicates()\n    .cache())\n\nrecommendationIndexer = (RecommendationIndexer()\n    .setUserInputCol("customerIDOrg")\n    .setUserOutputCol("customerID")\n    .setItemInputCol("itemIDOrg")\n    .setItemOutputCol("itemID")\n    .setRatingCol("rating"))\n\ntransformedDf = (recommendationIndexer.fit(ratings)\n    .transform(ratings).cache())\n\nals = (ALS()\n    .setNumUserBlocks(1)\n    .setNumItemBlocks(1)\n    .setUserCol("customerID")\n    .setItemCol("itemID")\n    .setRatingCol("rating")\n    .setSeed(0))\n\nevaluator = (RankingEvaluator()\n    .setK(3)\n    .setNItems(10))\n\nadapter = (RankingAdapter()\n    .setK(evaluator.getK())\n    .setRecommender(als))\n\ndisplay(adapter.fit(transformedDf).transform(transformedDf))\n\nparamGrid = (ParamGridBuilder()\n    .addGrid(als.regParam, [1.0])\n    .build())\n\ntvRecommendationSplit = (RankingTrainValidationSplit()\n      .setEstimator(als)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setTrainRatio(0.8)\n      .setUserCol(recommendationIndexer.getUserOutputCol())\n      .setItemCol(recommendationIndexer.getItemOutputCol())\n      .setRatingCol("rating"))\n\ndisplay(tvRecommendationSplit.fit(transformedDf).transform(transformedDf))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.recommendation._\nimport org.apache.spark.ml.recommendation.ALS\nimport org.apache.spark.ml.tuning._\nimport spark.implicits._\n\nval ratings = (Seq(\n      ("11", "Movie 01", 2),\n      ("11", "Movie 03", 1),\n      ("11", "Movie 04", 5),\n      ("11", "Movie 05", 3),\n      ("11", "Movie 06", 4),\n      ("11", "Movie 07", 1),\n      ("11", "Movie 08", 5),\n      ("11", "Movie 09", 3),\n      ("22", "Movie 01", 4),\n      ("22", "Movie 02", 5),\n      ("22", "Movie 03", 1),\n      ("22", "Movie 05", 3),\n      ("22", "Movie 06", 3),\n      ("22", "Movie 07", 5),\n      ("22", "Movie 08", 1),\n      ("22", "Movie 10", 3),\n      ("33", "Movie 01", 4),\n      ("33", "Movie 03", 1),\n      ("33", "Movie 04", 5),\n      ("33", "Movie 05", 3),\n      ("33", "Movie 06", 4),\n      ("33", "Movie 08", 1),\n      ("33", "Movie 09", 5),\n      ("33", "Movie 10", 3),\n      ("44", "Movie 01", 4),\n      ("44", "Movie 02", 5),\n      ("44", "Movie 03", 1),\n      ("44", "Movie 05", 3),\n      ("44", "Movie 06", 4),\n      ("44", "Movie 07", 5),\n      ("44", "Movie 08", 1),\n      ("44", "Movie 10", 3))\n    .toDF("customerIDOrg", "itemIDOrg", "rating")\n    .dropDuplicates()\n    .cache())\n\nval recommendationIndexer = (new RecommendationIndexer()\n    .setUserInputCol("customerIDOrg")\n    .setUserOutputCol("customerID")\n    .setItemInputCol("itemIDOrg")\n    .setItemOutputCol("itemID")\n    .setRatingCol("rating"))\n\nval transformedDf = (recommendationIndexer.fit(ratings)\n    .transform(ratings).cache())\n\nval als = (new ALS()\n    .setNumUserBlocks(1)\n    .setNumItemBlocks(1)\n    .setUserCol("customerID")\n    .setItemCol("itemID")\n    .setRatingCol("rating")\n    .setSeed(0))\n\nval evaluator = (new RankingEvaluator()\n    .setK(3)\n    .setNItems(10))\n\nval adapter = (new RankingAdapter()\n    .setK(evaluator.getK)\n    .setRecommender(als))\n\ndisplay(adapter.fit(transformedDf).transform(transformedDf))\n\nval paramGrid = (new ParamGridBuilder()\n    .addGrid(als.regParam, Array(1.0))\n    .build())\n\nval tvRecommendationSplit = (new RankingTrainValidationSplit()\n      .setEstimator(als)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setTrainRatio(0.8)\n      .setUserCol(recommendationIndexer.getUserOutputCol)\n      .setItemCol(recommendationIndexer.getItemOutputCol)\n      .setRatingCol("rating"))\n\ndisplay(tvRecommendationSplit.fit(transformedDf).transform(transformedDf))\n')))),(0,r.kt)(i.Z,{className:"RecommendationIndexer",py:"mmlspark.recommendation.html#module-mmlspark.recommendation.RecommendationIndexer",scala:"com/microsoft/azure/synapse/ml/recommendation/RecommendationIndexer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/recommendation/RecommendationIndexer.scala",mdxType:"DocTable"}),(0,r.kt)(i.Z,{className:"RankingEvaluator",py:"mmlspark.recommendation.html#module-mmlspark.recommendation.RankingEvaluator",scala:"com/microsoft/azure/synapse/ml/recommendation/RankingEvaluator.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/recommendation/RankingEvaluator.scala",mdxType:"DocTable"}),(0,r.kt)(i.Z,{className:"RankingAdapter",py:"mmlspark.recommendation.html#module-mmlspark.recommendation.RankingAdapter",scala:"com/microsoft/azure/synapse/ml/recommendation/RankingAdapter.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/recommendation/RankingAdapter.scala",mdxType:"DocTable"}),(0,r.kt)(i.Z,{className:"RankingTrainValidationSplit",py:"mmlspark.recommendation.html#module-mmlspark.recommendation.RankingTrainValidationSplit",scala:"com/microsoft/azure/synapse/ml/recommendation/RankingTrainValidationSplit.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/recommendation/RankingTrainValidationSplit.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"sar"},"SAR"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.recommendation import *\n\nratings = (spark.createDataFrame([\n      ("11", "Movie 01", 2),\n      ("11", "Movie 03", 1),\n      ("11", "Movie 04", 5),\n      ("11", "Movie 05", 3),\n      ("11", "Movie 06", 4),\n      ("11", "Movie 07", 1),\n      ("11", "Movie 08", 5),\n      ("11", "Movie 09", 3),\n      ("22", "Movie 01", 4),\n      ("22", "Movie 02", 5),\n      ("22", "Movie 03", 1),\n      ("22", "Movie 05", 3),\n      ("22", "Movie 06", 3),\n      ("22", "Movie 07", 5),\n      ("22", "Movie 08", 1),\n      ("22", "Movie 10", 3),\n      ("33", "Movie 01", 4),\n      ("33", "Movie 03", 1),\n      ("33", "Movie 04", 5),\n      ("33", "Movie 05", 3),\n      ("33", "Movie 06", 4),\n      ("33", "Movie 08", 1),\n      ("33", "Movie 09", 5),\n      ("33", "Movie 10", 3),\n      ("44", "Movie 01", 4),\n      ("44", "Movie 02", 5),\n      ("44", "Movie 03", 1),\n      ("44", "Movie 05", 3),\n      ("44", "Movie 06", 4),\n      ("44", "Movie 07", 5),\n      ("44", "Movie 08", 1),\n      ("44", "Movie 10", 3)\n      ], ["customerIDOrg", "itemIDOrg", "rating"])\n    .dropDuplicates()\n    .cache())\n\nrecommendationIndexer = (RecommendationIndexer()\n    .setUserInputCol("customerIDOrg")\n    .setUserOutputCol("customerID")\n    .setItemInputCol("itemIDOrg")\n    .setItemOutputCol("itemID")\n    .setRatingCol("rating"))\n\nalgo = (SAR()\n      .setUserCol("customerID")\n      .setItemCol("itemID")\n      .setRatingCol("rating")\n      .setTimeCol("timestamp")\n      .setSupportThreshold(1)\n      .setSimilarityFunction("jacccard")\n      .setActivityTimeFormat("EEE MMM dd HH:mm:ss Z yyyy"))\n\nadapter = (RankingAdapter()\n      .setK(5)\n      .setRecommender(algo))\n\nres1 = recommendationIndexer.fit(ratings).transform(ratings).cache()\n\ndisplay(adapter.fit(res1).transform(res1))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.recommendation._\nimport spark.implicits._\n\nval ratings = (Seq(\n      ("11", "Movie 01", 2),\n      ("11", "Movie 03", 1),\n      ("11", "Movie 04", 5),\n      ("11", "Movie 05", 3),\n      ("11", "Movie 06", 4),\n      ("11", "Movie 07", 1),\n      ("11", "Movie 08", 5),\n      ("11", "Movie 09", 3),\n      ("22", "Movie 01", 4),\n      ("22", "Movie 02", 5),\n      ("22", "Movie 03", 1),\n      ("22", "Movie 05", 3),\n      ("22", "Movie 06", 3),\n      ("22", "Movie 07", 5),\n      ("22", "Movie 08", 1),\n      ("22", "Movie 10", 3),\n      ("33", "Movie 01", 4),\n      ("33", "Movie 03", 1),\n      ("33", "Movie 04", 5),\n      ("33", "Movie 05", 3),\n      ("33", "Movie 06", 4),\n      ("33", "Movie 08", 1),\n      ("33", "Movie 09", 5),\n      ("33", "Movie 10", 3),\n      ("44", "Movie 01", 4),\n      ("44", "Movie 02", 5),\n      ("44", "Movie 03", 1),\n      ("44", "Movie 05", 3),\n      ("44", "Movie 06", 4),\n      ("44", "Movie 07", 5),\n      ("44", "Movie 08", 1),\n      ("44", "Movie 10", 3))\n    .toDF("customerIDOrg", "itemIDOrg", "rating")\n    .dropDuplicates()\n    .cache())\n\nval recommendationIndexer = (new RecommendationIndexer()\n    .setUserInputCol("customerIDOrg")\n    .setUserOutputCol("customerID")\n    .setItemInputCol("itemIDOrg")\n    .setItemOutputCol("itemID")\n    .setRatingCol("rating"))\n\nval algo = (new SAR()\n      .setUserCol("customerID")\n      .setItemCol("itemID")\n      .setRatingCol("rating")\n      .setTimeCol("timestamp")\n      .setSupportThreshold(1)\n      .setSimilarityFunction("jacccard")\n      .setActivityTimeFormat("EEE MMM dd HH:mm:ss Z yyyy"))\n\nval adapter = (new RankingAdapter()\n      .setK(5)\n      .setRecommender(algo))\n\nval res1 = recommendationIndexer.fit(ratings).transform(ratings).cache()\n\ndisplay(adapter.fit(res1).transform(res1))\n')))),(0,r.kt)(i.Z,{className:"SAR",py:"mmlspark.recommendation.html#module-mmlspark.recommendation.SAR",scala:"com/microsoft/azure/synapse/ml/recommendation/SAR.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/recommendation/SAR.scala",mdxType:"DocTable"}))}w.isMDXComponent=!0;var S=["components"],R=[{value:"Stages",id:"stages",children:[{value:"ClassBalancer",id:"classbalancer",children:[],level:3},{value:"MultiColumnAdapter",id:"multicolumnadapter",children:[],level:3},{value:"Timer",id:"timer",children:[],level:3}],level:2}],z={toc:R};function F(e){var a=e.components,n=(0,o.Z)(e,S);return(0,r.kt)("wrapper",(0,t.Z)({},z,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"stages"},"Stages"),(0,r.kt)("h3",{id:"classbalancer"},"ClassBalancer"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\n\ndf = (spark.createDataFrame([\n      (0, 1.0, "Hi I"),\n      (1, 1.0, "I wish for snow today"),\n      (2, 2.0, "I wish for snow today"),\n      (3, 2.0, "I wish for snow today"),\n      (4, 2.0, "I wish for snow today"),\n      (5, 2.0, "I wish for snow today"),\n      (6, 0.0, "I wish for snow today"),\n      (7, 1.0, "I wish for snow today"),\n      (8, 0.0, "we Cant go to the park, because of the snow!"),\n      (9, 2.0, "")\n      ], ["index", "label", "sentence"]))\n\ncb = ClassBalancer().setInputCol("label")\n\ndisplay(cb.fit(df).transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\n\nval df = Seq(\n      (0, 1.0, "Hi I"),\n      (1, 1.0, "I wish for snow today"),\n      (2, 2.0, "I wish for snow today"),\n      (3, 2.0, "I wish for snow today"),\n      (4, 2.0, "I wish for snow today"),\n      (5, 2.0, "I wish for snow today"),\n      (6, 0.0, "I wish for snow today"),\n      (7, 1.0, "I wish for snow today"),\n      (8, 0.0, "we Cant go to the park, because of the snow!"),\n      (9, 2.0, "")).toDF("index", "label", "sentence")\n\nval cb = new ClassBalancer().setInputCol("label")\n\ndisplay(cb.fit(df).transform(df))\n')))),(0,r.kt)(i.Z,{className:"ClassBalancer",py:"synapse.ml.stages.html#module-synapse.ml.stages.ClassBalancer",scala:"com/microsoft/azure/synapse/ml/stages/ClassBalancer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/ClassBalancer.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"multicolumnadapter"},"MultiColumnAdapter"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.ml.feature import Tokenizer\n\ndf = (spark.createDataFrame([\n        (0, "This is a test", "this is one too"),\n        (1, "could be a test", "bar"),\n        (2, "foo", "bar"),\n        (3, "foo", "maybe not")\n      ], ["label", "words1", "words2"]))\n\nstage1 = Tokenizer()\nmca = (MultiColumnAdapter()\n        .setBaseStage(stage1)\n        .setInputCols(["words1",  "words2"])\n        .setOutputCols(["output1", "output2"]))\n\ndisplay(mca.fit(df).transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.ml.feature.Tokenizer\n\nval df = (Seq(\n    (0, "This is a test", "this is one too"),\n    (1, "could be a test", "bar"),\n    (2, "foo", "bar"),\n    (3, "foo", "maybe not"))\n    .toDF("label", "words1", "words2"))\n\nval stage1 = new Tokenizer()\nval mca = (new MultiColumnAdapter()\n        .setBaseStage(stage1)\n        .setInputCols(Array[String]("words1",  "words2"))\n        .setOutputCols(Array[String]("output1", "output2")))\n\ndisplay(mca.fit(df).transform(df))\n')))),(0,r.kt)(i.Z,{className:"MultiColumnAdapter",py:"synapse.ml.stages.html#module-synapse.ml.stages.MultiColumnAdapter",scala:"com/microsoft/azure/synapse/ml/stages/MultiColumnAdapter.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/MultiColumnAdapter.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"timer"},"Timer"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import *\nfrom pyspark.ml.feature import *\n\ndf = (spark.createDataFrame([\n        (0, "Hi I"),\n        (1, "I wish for snow today"),\n        (2, "we Cant go to the park, because of the snow!"),\n        (3, "")\n      ], ["label", "sentence"]))\n\ntok = (Tokenizer()\n      .setInputCol("sentence")\n      .setOutputCol("tokens"))\n\ndf2 = Timer().setStage(tok).fit(df).transform(df)\n\ndf3 = HashingTF().setInputCol("tokens").setOutputCol("hash").transform(df2)\n\nidf = IDF().setInputCol("hash").setOutputCol("idf")\ntimer = Timer().setStage(idf)\n\ndisplay(timer.fit(df3).transform(df3))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.stages._\nimport org.apache.spark.ml.feature._\n\nval df = (Seq(\n    (0, "Hi I"),\n    (1, "I wish for snow today"),\n    (2, "we Cant go to the park, because of the snow!"),\n    (3, "")\n  ).toDF("label", "sentence"))\n\nval tok = (new Tokenizer()\n      .setInputCol("sentence")\n      .setOutputCol("tokens"))\n\nval df2 = new Timer().setStage(tok).fit(df).transform(df)\n\nval df3 = new HashingTF().setInputCol("tokens").setOutputCol("hash").transform(df2)\n\nval idf = new IDF().setInputCol("hash").setOutputCol("idf")\nval timer = new Timer().setStage(idf)\n\ndisplay(timer.fit(df3).transform(df3))\n')))),(0,r.kt)(i.Z,{className:"Timer",py:"synapse.ml.stages.html#module-synapse.ml.stages.Timer",scala:"com/microsoft/azure/synapse/ml/stages/Timer.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/stages/Timer.scala",mdxType:"DocTable"}))}F.isMDXComponent=!0;var L=["components"],Z=[{value:"Train",id:"train",children:[{value:"TrainClassifier",id:"trainclassifier",children:[],level:3},{value:"TrainRegressor",id:"trainregressor",children:[],level:3}],level:2}],O={toc:Z};function _(e){var a=e.components,n=(0,o.Z)(e,L);return(0,r.kt)("wrapper",(0,t.Z)({},O,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"train"},"Train"),(0,r.kt)("h3",{id:"trainclassifier"},"TrainClassifier"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import *\nfrom pyspark.ml.classification import LogisticRegression\n\ndf = spark.createDataFrame([\n      (0, 2, 0.50, 0.60, 0),\n      (1, 3, 0.40, 0.50, 1),\n      (0, 4, 0.78, 0.99, 2),\n      (1, 5, 0.12, 0.34, 3),\n      (0, 1, 0.50, 0.60, 0),\n      (1, 3, 0.40, 0.50, 1),\n      (0, 3, 0.78, 0.99, 2),\n      (1, 4, 0.12, 0.34, 3),\n      (0, 0, 0.50, 0.60, 0),\n      (1, 2, 0.40, 0.50, 1),\n      (0, 3, 0.78, 0.99, 2),\n      (1, 4, 0.12, 0.34, 3)],\n      ["Label", "col1", "col2", "col3", "col4"]\n)\n\ntc = (TrainClassifier()\n      .setModel(LogisticRegression())\n      .setLabelCol("Label"))\n\ndisplay(tc.fit(df).transform(df))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.train._\nimport org.apache.spark.ml.classification.LogisticRegression\n\nval df = (Seq(\n      (0, 2, 0.50, 0.60, 0),\n      (1, 3, 0.40, 0.50, 1),\n      (0, 4, 0.78, 0.99, 2),\n      (1, 5, 0.12, 0.34, 3),\n      (0, 1, 0.50, 0.60, 0),\n      (1, 3, 0.40, 0.50, 1),\n      (0, 3, 0.78, 0.99, 2),\n      (1, 4, 0.12, 0.34, 3),\n      (0, 0, 0.50, 0.60, 0),\n      (1, 2, 0.40, 0.50, 1),\n      (0, 3, 0.78, 0.99, 2),\n      (1, 4, 0.12, 0.34, 3))\n      .toDF("Label", "col1", "col2", "col3", "col4"))\n\nval tc = (new TrainClassifier()\n      .setModel(new LogisticRegression())\n      .setLabelCol("Label"))\n\ndisplay(tc.fit(df).transform(df))\n')))),(0,r.kt)(i.Z,{className:"TrainClassifier",py:"mmlspark.train.html#module-mmlspark.train.TrainClassifier",scala:"com/microsoft/azure/synapse/ml/train/TrainClassifier.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/train/TrainClassifier.scala",mdxType:"DocTable"}),(0,r.kt)("h3",{id:"trainregressor"},"TrainRegressor"),(0,r.kt)(s.Z,{defaultValue:"py",values:[{label:"Python",value:"py"},{label:"Scala",value:"scala"}],mdxType:"Tabs"},(0,r.kt)(l.Z,{value:"py",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import *\nfrom pyspark.ml.classification import LogisticRegression\n\ndataset = (spark.createDataFrame([\n    (0.0, 2, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 4, 0.78, 0.99, 2.0),\n    (3.0, 5, 0.12, 0.34, 3.0),\n    (0.0, 1, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0),\n    (0.0, 0, 0.50, 0.60, 0.0),\n    (1.0, 2, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0)],\n    ["label", "col1", "col2", "col3", "prediction"]))\n\nlinearRegressor = (LinearRegression()\n      .setRegParam(0.3)\n      .setElasticNetParam(0.8))\ntrainRegressor = (TrainRegressor()\n      .setModel(linearRegressor)\n      .setLabelCol("Label"))\n\ndisplay(trainRegressor.fit(dataset).transform(dataset))\n'))),(0,r.kt)(l.Z,{value:"scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.microsoft.azure.synapse.ml.train._\nimport org.apache.spark.ml.classification.LogisticRegression\n\nval dataset = spark.createDataFrame(Seq(\n    (0.0, 2, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 4, 0.78, 0.99, 2.0),\n    (3.0, 5, 0.12, 0.34, 3.0),\n    (0.0, 1, 0.50, 0.60, 0.0),\n    (1.0, 3, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0),\n    (0.0, 0, 0.50, 0.60, 0.0),\n    (1.0, 2, 0.40, 0.50, 1.0),\n    (2.0, 3, 0.78, 0.99, 2.0),\n    (3.0, 4, 0.12, 0.34, 3.0)))\n    .toDF("label", "col1", "col2", "col3", "prediction")\n\nval linearRegressor = (new LinearRegression()\n      .setRegParam(0.3)\n      .setElasticNetParam(0.8))\nval trainRegressor = (new TrainRegressor()\n      .setModel(linearRegressor)\n      .setLabelCol("Label"))\n\ndisplay(trainRegressor.fit(dataset).transform(dataset))\n')))),(0,r.kt)(i.Z,{className:"TrainRegressor",py:"mmlspark.train.html#module-mmlspark.train.TrainRegressor",scala:"com/microsoft/azure/synapse/ml/train/TrainRegressor.html",sourceLink:"https://github.com/microsoft/SynapseML/blob/master/core/src/main/scala/com/microsoft/azure/synapse/ml/train/TrainRegressor.scala",mdxType:"DocTable"}))}_.isMDXComponent=!0;var E=["components"],P={title:"Estimators - Core",sidebar_label:"Core",hide_title:!0},B=void 0,A={unversionedId:"documentation/estimators/estimators_core",id:"version-0.9.1/documentation/estimators/estimators_core",isDocsHomePage:!1,title:"Estimators - Core",description:"export const toc = [...AutoMLTOC, ...FeaturizeTOC, ...IsolationForestTOC,",source:"@site/versioned_docs/version-0.9.1/documentation/estimators/estimators_core.md",sourceDirName:"documentation/estimators",slug:"/documentation/estimators/estimators_core",permalink:"/SynapseML/docs/documentation/estimators/estimators_core",tags:[],version:"0.9.1",frontMatter:{title:"Estimators - Core",sidebar_label:"Core",hide_title:!0},sidebar:"version-0.9.1/docs",previous:{title:"Deep Learning",permalink:"/SynapseML/docs/documentation/transformers/transformers_deep_learning"},next:{title:"LightGBM",permalink:"/SynapseML/docs/documentation/estimators/estimators_lightgbm"}},H=[].concat(c,f,k,M,N,R,Z),V={toc:H};function K(e){var a=e.components,n=(0,o.Z)(e,E);return(0,r.kt)("wrapper",(0,t.Z)({},V,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)(u,{mdxType:"AutoML"}),(0,r.kt)(v,{mdxType:"Featurize"}),(0,r.kt)(h,{mdxType:"IsolationForest"}),(0,r.kt)(I,{mdxType:"NN"}),(0,r.kt)(w,{mdxType:"Recommendation"}),(0,r.kt)(F,{mdxType:"Stages"}),(0,r.kt)(_,{mdxType:"Train"}))}K.isMDXComponent=!0}}]);