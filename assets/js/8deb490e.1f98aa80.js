"use strict";(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[47310],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>c});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),u=p(a),c=r,f=u["".concat(l,".").concat(c)]||u[c]||d[c]||s;return a?n.createElement(f,o(o({ref:t},m),{},{components:a})):n.createElement(f,o({ref:t},m))}));function c(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=u;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var p=2;p<s;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},30202:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>p});var n=a(83117),r=(a(67294),a(3905));const s={title:"Quickstart - SparkML vs SynapseML",hide_title:!0,status:"stable"},o="Classification - SparkML vs SynapseML",i={unversionedId:"Explore Algorithms/Classification/Quickstart - SparkML vs SynapseML",id:"version-1.0.13/Explore Algorithms/Classification/Quickstart - SparkML vs SynapseML",title:"Quickstart - SparkML vs SynapseML",description:"In this article, you perform the same classification task in two",source:"@site/versioned_docs/version-1.0.13/Explore Algorithms/Classification/Quickstart - SparkML vs SynapseML.md",sourceDirName:"Explore Algorithms/Classification",slug:"/Explore Algorithms/Classification/Quickstart - SparkML vs SynapseML",permalink:"/SynapseML/docs/Explore Algorithms/Classification/Quickstart - SparkML vs SynapseML",draft:!1,tags:[],version:"1.0.13",frontMatter:{title:"Quickstart - SparkML vs SynapseML",hide_title:!0,status:"stable"},sidebar:"docs",previous:{title:"Quickstart - Train Classifier",permalink:"/SynapseML/docs/Explore Algorithms/Classification/Quickstart - Train Classifier"},next:{title:"Quickstart - Vowpal Wabbit on Tabular Data",permalink:"/SynapseML/docs/Explore Algorithms/Classification/Quickstart - Vowpal Wabbit on Tabular Data"}},l={},p=[{value:"Setup",id:"setup",level:2},{value:"Read the data",id:"read-the-data",level:2},{value:"Extract features and process data",id:"extract-features-and-process-data",level:2},{value:"Classify using pyspark",id:"classify-using-pyspark",level:2},{value:"Classify using SynapseML",id:"classify-using-synapseml",level:2}],m={toc:p};function d(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"classification---sparkml-vs-synapseml"},"Classification - SparkML vs SynapseML"),(0,r.kt)("p",null,(0,r.kt)("img",{src:"https://images-na.ssl-images-amazon.com/images/G/01/img16/books/bookstore/landing-page/1000638_books_landing-page_bookstore-photo-01.jpg",title:"Image from https://images-na.ssl-images-amazon.com/images/G/01/img16/books/bookstore/landing-page/1000638_books_landing-page_bookstore-photo-01.jpg"}),(0,r.kt)("br",null)),(0,r.kt)("p",null,"In this article, you perform the same classification task in two\ndifferent ways: once using plain ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"pyspark"))," and once using the\n",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"synapseml"))," library.  The two methods yield the same performance,\nbut highlights the simplicity of using ",(0,r.kt)("inlineCode",{parentName:"p"},"synapseml")," compared to ",(0,r.kt)("inlineCode",{parentName:"p"},"pyspark"),"."),(0,r.kt)("p",null,"The task is to predict whether a customer's review of a book sold on\nAmazon is good (rating > 3) or bad based on the text of the review. You\naccomplish it by training LogisticRegression learners with different\nhyperparameters and choosing the best model."),(0,r.kt)("h2",{id:"setup"},"Setup"),(0,r.kt)("p",null,"Import necessary Python libraries and get a spark session."),(0,r.kt)("h2",{id:"read-the-data"},"Read the data"),(0,r.kt)("p",null,"Download and read in the data."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'rawData = spark.read.parquet(\n    "wasbs://publicwasb@mmlspark.blob.core.windows.net/BookReviewsFromAmazon10K.parquet"\n)\nrawData.show(5)\n')),(0,r.kt)("h2",{id:"extract-features-and-process-data"},"Extract features and process data"),(0,r.kt)("p",null,"Real data is more complex than the above dataset. It's common\nfor a dataset to have features of multiple types, such as text, numeric, and\ncategorical. To illustrate how difficult it's to work with these\ndatasets, add two numerical features to the dataset: the ",(0,r.kt)("strong",{parentName:"p"},"word count")," of the review and the ",(0,r.kt)("strong",{parentName:"p"},"mean word length"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from pyspark.sql.functions import udf\nfrom pyspark.sql.types import *\n\n\ndef wordCount(s):\n    return len(s.split())\n\n\ndef wordLength(s):\n    import numpy as np\n\n    ss = [len(w) for w in s.split()]\n    return round(float(np.mean(ss)), 2)\n\n\nwordLengthUDF = udf(wordLength, DoubleType())\nwordCountUDF = udf(wordCount, IntegerType())\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.stages import UDFTransformer\n\nwordLength = "wordLength"\nwordCount = "wordCount"\nwordLengthTransformer = UDFTransformer(\n    inputCol="text", outputCol=wordLength, udf=wordLengthUDF\n)\nwordCountTransformer = UDFTransformer(\n    inputCol="text", outputCol=wordCount, udf=wordCountUDF\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.ml import Pipeline\n\ndata = (\n    Pipeline(stages=[wordLengthTransformer, wordCountTransformer])\n    .fit(rawData)\n    .transform(rawData)\n    .withColumn("label", rawData["rating"] > 3)\n    .drop("rating")\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"data.show(5)\n")),(0,r.kt)("h2",{id:"classify-using-pyspark"},"Classify using pyspark"),(0,r.kt)("p",null,"To choose the best LogisticRegression classifier using the ",(0,r.kt)("inlineCode",{parentName:"p"},"pyspark"),"\nlibrary, we need to ",(0,r.kt)("em",{parentName:"p"},"explicitly")," perform the following steps:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Process the features:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Tokenize the text column"),(0,r.kt)("li",{parentName:"ul"},"Hash the tokenized column into a vector using hashing"),(0,r.kt)("li",{parentName:"ul"},"Merge the numeric features with the vector"))),(0,r.kt)("li",{parentName:"ol"},"Process the label column: cast it into the proper type."),(0,r.kt)("li",{parentName:"ol"},"Train multiple LogisticRegression algorithms on the ",(0,r.kt)("inlineCode",{parentName:"li"},"train")," dataset\nwith different hyperparameters"),(0,r.kt)("li",{parentName:"ol"},"Compute the area under the ROC curve for each of the trained models\nand select the model with the highest metric as computed on the\n",(0,r.kt)("inlineCode",{parentName:"li"},"test")," dataset"),(0,r.kt)("li",{parentName:"ol"},"Evaluate the best model on the ",(0,r.kt)("inlineCode",{parentName:"li"},"validation")," set")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.ml.feature import Tokenizer, HashingTF\nfrom pyspark.ml.feature import VectorAssembler\n\n# Featurize text column\ntokenizer = Tokenizer(inputCol="text", outputCol="tokenizedText")\nnumFeatures = 10000\nhashingScheme = HashingTF(\n    inputCol="tokenizedText", outputCol="TextFeatures", numFeatures=numFeatures\n)\ntokenizedData = tokenizer.transform(data)\nfeaturizedData = hashingScheme.transform(tokenizedData)\n\n# Merge text and numeric features in one feature column\nfeatureColumnsArray = ["TextFeatures", "wordCount", "wordLength"]\nassembler = VectorAssembler(inputCols=featureColumnsArray, outputCol="features")\nassembledData = assembler.transform(featurizedData)\n\n# Select only columns of interest\n# Convert rating column from boolean to int\nprocessedData = assembledData.select("label", "features").withColumn(\n    "label", assembledData.label.cast(IntegerType())\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import LogisticRegression\n\n# Prepare data for learning\ntrain, test, validation = processedData.randomSplit([0.60, 0.20, 0.20], seed=123)\n\n# Train the models on the \'train\' data\nlrHyperParams = [0.05, 0.1, 0.2, 0.4]\nlogisticRegressions = [\n    LogisticRegression(regParam=hyperParam) for hyperParam in lrHyperParams\n]\nevaluator = BinaryClassificationEvaluator(\n    rawPredictionCol="rawPrediction", metricName="areaUnderROC"\n)\nmetrics = []\nmodels = []\n\n# Select the best model\nfor learner in logisticRegressions:\n    model = learner.fit(train)\n    models.append(model)\n    scoredData = model.transform(test)\n    metrics.append(evaluator.evaluate(scoredData))\nbestMetric = max(metrics)\nbestModel = models[metrics.index(bestMetric)]\n\n# Get AUC on the validation dataset\nscoredVal = bestModel.transform(validation)\nprint(evaluator.evaluate(scoredVal))\n')),(0,r.kt)("h2",{id:"classify-using-synapseml"},"Classify using SynapseML"),(0,r.kt)("p",null,"The steps needed with ",(0,r.kt)("inlineCode",{parentName:"p"},"synapseml")," are simpler:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"The ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"TrainClassifier"))," Estimator featurizes the data internally,\nas long as the columns selected in the ",(0,r.kt)("inlineCode",{parentName:"p"},"train"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"test"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"validation"),"\ndataset represent the features")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"The ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"FindBestModel"))," Estimator finds the best model from a pool of\ntrained models by finding the model that performs best on the ",(0,r.kt)("inlineCode",{parentName:"p"},"test"),"\ndataset given the specified metric")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"The ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"ComputeModelStatistics"))," Transformer computes the different\nmetrics on a scored dataset (in our case, the ",(0,r.kt)("inlineCode",{parentName:"p"},"validation")," dataset)\nat the same time"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from synapse.ml.train import TrainClassifier, ComputeModelStatistics\nfrom synapse.ml.automl import FindBestModel\n\n# Prepare data for learning\ntrain, test, validation = data.randomSplit([0.60, 0.20, 0.20], seed=123)\n\n# Train the models on the \'train\' data\nlrHyperParams = [0.05, 0.1, 0.2, 0.4]\nlogisticRegressions = [\n    LogisticRegression(regParam=hyperParam) for hyperParam in lrHyperParams\n]\nlrmodels = [\n    TrainClassifier(model=lrm, labelCol="label", numFeatures=10000).fit(train)\n    for lrm in logisticRegressions\n]\n\n# Select the best model\nbestModel = FindBestModel(evaluationMetric="AUC", models=lrmodels).fit(test)\n\n\n# Get AUC on the validation dataset\npredictions = bestModel.transform(validation)\nmetrics = ComputeModelStatistics().transform(predictions)\nprint(\n    "Best model\'s AUC on validation set = "\n    + "{0:.2f}%".format(metrics.first()["AUC"] * 100)\n)\n')))}d.isMDXComponent=!0}}]);