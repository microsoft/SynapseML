{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create audiobooks using neural Text to speech"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "389e4a78-19aa-4c3f-9b7a-92e81f088168",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Load libraries and add service information"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "f320d6af-b255-4cb5-b60b-da840760713e",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from synapse.ml.core.platform import *\n",
    "\n",
    "if running_on_synapse():\n",
    "    from notebookutils import mssparkutils\n",
    "\n",
    "# Fill this in with your Azure AI service information\n",
    "service_key = find_secret(\n",
    "    secret_name=\"ai-services-api-key\", keyvault=\"mmlspark-build-keys\"\n",
    ")  # Replace this line with a string like service_key = \"dddjnbdkw9329\"\n",
    "service_loc = \"eastus\"\n",
    "\n",
    "storage_container = \"audiobooks\"\n",
    "storage_key = find_secret(\n",
    "    secret_name=\"madtest-storage-key\", keyvault=\"mmlspark-build-keys\"\n",
    ")\n",
    "storage_account = \"anomalydetectiontest\""
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "ab422610-0438-4ca4-bd16-b45e90125294",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Attach the storage account to hold the audio files"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "10c83d0e-998f-4d72-a351-4ffab15f662c",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "spark_key_setting = f\"fs.azure.account.key.{storage_account}.blob.core.windows.net\"\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(spark_key_setting, storage_key)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "55b83038-e907-4101-a914-0a32825a9d03",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from os.path import exists, join\n",
    "\n",
    "mount_path = f\"wasbs://{storage_container}@{storage_account}.blob.core.windows.net/\"\n",
    "if running_on_synapse():\n",
    "    mount_dir = join(\"/synfs\", mssparkutils.env.getJobId(), storage_container)\n",
    "    if not exists(mount_dir):\n",
    "        mssparkutils.fs.mount(\n",
    "            mount_path, f\"/{storage_container}\", {\"accountKey\": storage_key}\n",
    "        )\n",
    "elif running_on_databricks():\n",
    "    if not exists(f\"/dbfs/mnt/{storage_container}\"):\n",
    "        dbutils.fs.mount(\n",
    "            source=mount_path,\n",
    "            mount_point=f\"/mnt/{storage_container}\",\n",
    "            extra_configs={spark_key_setting: storage_key},\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "625c7b1d-4034-4df2-b919-3775ac9c271c",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Read in text data"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "381c3af7-e0e8-4a29-ae88-467e86a0e717",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "@udf\n",
    "def make_audio_filename(part):\n",
    "    return f\"wasbs://{storage_container}@{storage_account}.blob.core.windows.net/alice_in_wonderland/part_{part}.wav\"\n",
    "\n",
    "\n",
    "df = (\n",
    "    spark.read.parquet(\n",
    "        \"wasbs://publicwasb@mmlspark.blob.core.windows.net/alice_in_wonderland.parquet\"\n",
    "    )\n",
    "    .repartition(10)\n",
    "    .withColumn(\"filename\", make_audio_filename(\"part\"))\n",
    ")\n",
    "\n",
    "display(df)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "56c8ebab-567f-4c1d-a2ea-1aeb5aefcf1e",
     "inputWidgets": {},
     "title": ""
    },
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Synthesize audio from text\n",
    "\n",
    "<div>\n",
    "<img src=\"https://marhamilresearch4.blob.core.windows.net/gutenberg-public/Notebook/NeuralTTS_hero.jpeg\" width=\"500\" />\n",
    "</div>"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "9fcb4305-a6d4-4f48-ac6f-cf4f863c7f5f",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from synapse.ml.services.speech import TextToSpeech\n",
    "\n",
    "tts = (\n",
    "    TextToSpeech()\n",
    "    .setSubscriptionKey(service_key)\n",
    "    .setTextCol(\"text\")\n",
    "    .setLocation(service_loc)\n",
    "    .setErrorCol(\"error\")\n",
    "    .setVoiceName(\"en-US-SteffanNeural\")\n",
    "    .setOutputFileCol(\"filename\")\n",
    ")\n",
    "\n",
    "audio = tts.transform(df).cache()\n",
    "display(audio)"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "2730c8cd-616a-4258-909d-912ea66d6446",
     "inputWidgets": {},
     "title": ""
    },
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Listen to an audio file"
   ],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "157a368a-d80b-4bf8-a5cb-c1f266be2f00",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "def get_audio_file(num):\n",
    "    if running_on_databricks():\n",
    "        return f\"/dbfs/mnt/{storage_container}/alice_in_wonderland/part_{num}.wav\"\n",
    "    else:\n",
    "        return join(mount_dir, f\"alice_in_wonderland/part_{num}.wav\")\n",
    "\n",
    "\n",
    "Audio(filename=get_audio_file(1))"
   ],
   "outputs": [],
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7a0ad60f-5511-42ba-9882-e93f474f85e9",
     "inputWidgets": {},
     "title": ""
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synapse_pyspark",
   "language": "Python",
   "display_name": "Synapse PySpark"
  },
  "language_info": {
   "name": "python"
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "save_output": true,
  "synapse_widget": {
   "version": "0.1",
   "state": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
