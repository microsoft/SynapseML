{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ONNX Inference on Spark\n",
    "\n",
    "In this example, you train a LightGBM model and convert the model to [ONNX](https://onnx.ai/) format. Once converted, you use the model to infer some testing data on Spark.\n",
    "\n",
    "This example uses the following Python packages and versions:\n",
    "\n",
    "- `onnxmltools==1.7.0`\n",
    "- `lightgbm==3.2.1`\n",
    "- `onnx==1.17.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the example data\n",
    "\n",
    "To load the example data, add the following code examples to cells in your notebook and then run the cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install lightgbm onnx==1.17.0 onnxmltools==1.7.0 protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .load(\n",
    "        \"wasbs://publicwasb@mmlspark.blob.core.windows.net/company_bankruptcy_prediction_data.csv\"\n",
    "    )\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The output should look similar to the following table, though the values and number of rows may differ:\n",
    "\n",
    "| Interest Coverage Ratio | Net Income Flag | Equity to Liability |\n",
    "| ----- | ----- | ----- |\n",
    "| 0.5641 | 1.0 | 0.0165 |\n",
    "| 0.5702 | 1.0 | 0.0208 |\n",
    "| 0.5673 | 1.0 | 0.0165 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use LightGBM to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from synapse.ml.lightgbm import LightGBMClassifier\n",
    "\n",
    "feature_cols = df.columns[1:]\n",
    "featurizer = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "train_data = featurizer.transform(df)[\"Bankrupt?\", \"features\"]\n",
    "\n",
    "model = (\n",
    "    LightGBMClassifier(featuresCol=\"features\", labelCol=\"Bankrupt?\")\n",
    "    .setEarlyStoppingRound(300)\n",
    "    .setLambdaL1(0.5)\n",
    "    .setNumIterations(1000)\n",
    "    .setNumThreads(-1)\n",
    "    .setMaxDeltaStep(0.5)\n",
    "    .setNumLeaves(31)\n",
    "    .setMaxDepth(-1)\n",
    "    .setBaggingFraction(0.7)\n",
    "    .setFeatureFraction(0.7)\n",
    "    .setBaggingFreq(2)\n",
    "    .setObjective(\"binary\")\n",
    "    .setIsUnbalance(True)\n",
    "    .setMinSumHessianInLeaf(20)\n",
    "    .setMinGainToSplit(0.01)\n",
    ")\n",
    "\n",
    "model = model.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Convert the model to ONNX format\n",
    "\n",
    "The following code exports the trained model to a LightGBM booster and then converts it to ONNX format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from synapse.ml.core.platform import running_on_binder\n",
    "\n",
    "if running_on_binder():\n",
    "    from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import Booster, LGBMClassifier\n",
    "\n",
    "\n",
    "def convertModel(lgbm_model: LGBMClassifier or Booster, input_size: int) -> bytes:\n",
    "    from onnxmltools.convert import convert_lightgbm\n",
    "    from onnxconverter_common.data_types import FloatTensorType\n",
    "\n",
    "    initial_types = [(\"input\", FloatTensorType([-1, input_size]))]\n",
    "    onnx_model = convert_lightgbm(\n",
    "        lgbm_model, initial_types=initial_types, target_opset=9\n",
    "    )\n",
    "    return onnx_model.SerializeToString()\n",
    "\n",
    "\n",
    "booster_model_str = model.getLightGBMBooster().modelStr().get()\n",
    "booster = lgb.Booster(model_str=booster_model_str)\n",
    "model_payload_ml = convertModel(booster, len(feature_cols))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conversion, load the ONNX payload into an `ONNXModel` and inspect the model inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapse.ml.onnx import ONNXModel\n",
    "\n",
    "onnx_ml = ONNXModel().setModelPayload(model_payload_ml)\n",
    "\n",
    "print(\"Model inputs:\" + str(onnx_ml.getModelInputs()))\n",
    "print(\"Model outputs:\" + str(onnx_ml.getModelOutputs()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the model input to the input dataframe's column name (FeedDict), and map the output dataframe's column names to the model outputs (FetchDict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_ml = (\n",
    "    onnx_ml.setDeviceType(\"CPU\")\n",
    "    .setFeedDict({\"input\": \"features\"})\n",
    "    .setFetchDict({\"probability\": \"probabilities\", \"prediction\": \"label\"})\n",
    "    .setMiniBatchSize(5000)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model for inference\n",
    "\n",
    "To perform inference with the model, the following code creates test data and transforms the data through the ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 1000 * 1000\n",
    "m = 95\n",
    "test = np.random.rand(n, m)\n",
    "testPdf = pd.DataFrame(test)\n",
    "cols = list(map(str, testPdf.columns))\n",
    "testDf = spark.createDataFrame(testPdf)\n",
    "testDf = testDf.union(testDf).repartition(200)\n",
    "testDf = (\n",
    "    VectorAssembler()\n",
    "    .setInputCols(cols)\n",
    "    .setOutputCol(\"features\")\n",
    "    .transform(testDf)\n",
    "    .drop(*cols)\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "display(onnx_ml.transform(testDf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look similar to the following table, though the values and number of rows may differ:\n",
    "\n",
    "| Index | Features | Prediction | Probability |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | `\"{\"type\":1,\"values\":[0.105...` | 0 | `\"{\"0\":0.835...` |\n",
    "| 2 | `\"{\"type\":1,\"values\":[0.814...` | 0 | `\"{\"0\":0.658...` |"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
