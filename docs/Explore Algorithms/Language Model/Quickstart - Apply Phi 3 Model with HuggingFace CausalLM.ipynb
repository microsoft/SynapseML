{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a355394-5b22-4c09-8d4f-9467a2fcfce4",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Apply Phi3 model with HuggingFace Causal ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa35ae52-6a9e-458d-91ee-ae3962ab5b68",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "![HuggingFace Logo](https://huggingface.co/front/assets/huggingface_logo-noborder.svg)\n",
    "\n",
    "**HuggingFace** is a popular open-source platform that develops computation tools for building application using machine learning. It is widely known for its Transformers library which contains open-source implementation of transformer models for text, image, and audio task.\n",
    "\n",
    "[**Phi 3**](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/) is a family of AI models developed by Microsoft, designed to redefine what is possible with small language models (SLMs). Phi-3 models are the most compatable and cost-effective SLMs, [outperforming models of the same size and even larger ones in language](https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/?msockid=26355e446adb6dfa06484f956b686c27), reasoning, coding, and math benchmarks. \n",
    "\n",
    "<img src=\"https://pub-66c8c8c5ae474e9a9161c92b21de2f08.r2.dev/2024/04/The-Phi-3-small-language-models-with-big-potential-1.jpg\" alt=\"Phi 3 model performance\" width=\"600\">\n",
    "\n",
    "To make it easier to scale up causal language model prediction on a large dataset, we have integrated [HuggingFace Causal LM](https://huggingface.co/docs/transformers/tasks/language_modeling) with SynapseML. This integration makes it easy to use the Apache Spark distributed computing framework to process large data on text generation tasks.\n",
    "\n",
    "This tutorial shows hot to apply [phi3 model](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3) at scale with no extra setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe974ccc-3243-4158-95f4-88764297807a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade transformers==4.48.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76b540-466f-4ab3-9aa9-da8de5517fc1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "chats = [\n",
    "    (1, \"fix grammar: helol mi friend\"),\n",
    "    (2, \"What is HuggingFace\"),\n",
    "    (3, \"translate to Spanish: hello\"),\n",
    "]\n",
    "\n",
    "chat_df = spark.createDataFrame(chats, [\"row_index\", \"content\"])\n",
    "chat_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0687e7-6609-4af4-a1a4-c098cb404374",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Define and Apply Phi3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ac535-e0e8-4947-8e18-2e57ecaef096",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "The following example demonstrates how to load the remote Phi 3 model from HuggingFace and apply it to chats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db55d9-b89d-420f-80e9-618041def698",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "run_control": {
     "frozen": false
    }
   },
   "outputs": [],
   "source": [
    "from synapse.ml.llm.HuggingFaceCausallmTransform import HuggingFaceCausalLM\n",
    "\n",
    "phi3_transformer = (\n",
    "    HuggingFaceCausalLM()\n",
    "    .setModelName(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "    .setInputCol(\"content\")\n",
    "    .setOutputCol(\"result\")\n",
    "    .setModelParam(max_new_tokens=1000)\n",
    "    .setModelConfig(local_files_only=False, trust_remote_code=True)\n",
    ")\n",
    "result_df = phi3_transformer.transform(chat_df).collect()\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c839ac6-f92e-4615-a0c3-977a96231cc6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Use local cache\n",
    "\n",
    "By caching the model, you can reduce initialization time. On Fabric, store the model in a Lakehouse and use setCachePath to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5edf1-35cb-45d6-b1dc-49a22a01484b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# azcopy copy \"https://mmlspark.blob.core.windows.net/huggingface/microsoft/Phi-3-mini-4k-instruct\" \"/lakehouse/default/Files/microsoft/\" --recursive=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52c891-3be2-48fe-87b3-648e299a794e",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# phi3_transformer = (\n",
    "#     HuggingFaceCausalLM()\n",
    "#     .setCachePath(\"/lakehouse/default/Files/microsoft/Phi-3-mini-4k-instruct\")\n",
    "#     .setInputCol(\"content\")\n",
    "#     .setOutputCol(\"result\")\n",
    "#     .setModelParam(max_new_tokens=1000)\n",
    "# )\n",
    "# result_df = phi3_transformer.transform(chat_df).collect()\n",
    "# display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2ff34-63d4-4ae4-a944-e568badbdb44",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Utilize GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc581bb-8af1-4a31-98b5-ce6127656572",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "To utilize GPU, passing device_map=\"cuda\", torch_dtype=\"auto\" to modelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a033b-45f0-4ee4-a3c2-26ab8511539e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "phi3_transformer = (\n",
    "    HuggingFaceCausalLM()\n",
    "    .setModelName(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "    .setInputCol(\"content\")\n",
    "    .setOutputCol(\"result\")\n",
    "    .setModelParam(max_new_tokens=1000)\n",
    "    .setModelConfig(\n",
    "        device_map=\"cuda\",\n",
    "        torch_dtype=\"auto\",\n",
    "        local_files_only=False,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    ")\n",
    "result_df = phi3_transformer.transform(chat_df).collect()\n",
    "display(result_df)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {},
   "lakehouse": {
    "default_lakehouse": "cf3f397e-6a87-43ab-b8e0-bb9342e11c7a",
    "default_lakehouse_name": "jessiwang_phi3",
    "default_lakehouse_workspace_id": "4751a5bb-6a44-4164-8b31-c3b6a4cf1f8d"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {
    "427b3314-b88a-4524-a9bf-35bc83b2678e": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "count",
        "binsNumber": 10,
        "categoryFieldKeys": [
         "1"
        ],
        "chartType": "bar",
        "evaluatesOverAllRecords": false,
        "isStacked": false,
        "seriesFieldKeys": [
         "1"
        ],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "1",
         "1": "fix grammar: helol mi friend",
         "2": "Hello, my friend."
        },
        {
         "0": "2",
         "1": "What is HuggingFace",
         "2": "HuggingFace is an open-source community and library for building and training NLP models. It provides a platform for sharing and collaborating on NLP models and tools, and it offers a wide range of pre-trained models and transformer architectures that can be used for various NLP tasks. The library is built on PyTorch and provides a simple API for training and deploying NLP models."
        },
        {
         "0": "3",
         "1": "translate to Spanish: hello",
         "2": "Hola"
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "row_index",
         "type": "bigint"
        },
        {
         "key": "1",
         "name": "content",
         "type": "string"
        },
        {
         "key": "2",
         "name": "result",
         "type": "string"
        }
       ],
       "truncated": false
      },
      "wranglerEntryContext": null
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
